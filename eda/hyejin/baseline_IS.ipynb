{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bddc33f7",
   "metadata": {},
   "source": [
    "# Impact Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f75a2",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed2e673d",
   "metadata": {
    "executionInfo": {
     "elapsed": 17477,
     "status": "ok",
     "timestamp": 1750055694374,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "ed2e673d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fbabc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33b56cda",
   "metadata": {
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1750055694696,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "33b56cda"
   },
   "outputs": [],
   "source": [
    "# 1. 데이터 준비 및 타겟 생성\n",
    "df1 = pd.read_csv(\"../../db/news_2023_2025_external.csv\")\n",
    "df2 = pd.read_csv(\"../../db/news_2023_2025_metadata.csv\")\n",
    "\n",
    "df = df1.merge(df2, on=\"news_id\")\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0pxVDlnCPrcz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1750062678645,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "0pxVDlnCPrcz",
    "outputId": "e90eeaa7-c03d-44e0-df9a-3fd70f90e681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13425 entries, 238 to 13748\n",
      "Data columns (total 38 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   news_id                     13425 non-null  object \n",
      " 1   d_minus_5_date_close        13425 non-null  float64\n",
      " 2   d_minus_5_date_volume       13425 non-null  float64\n",
      " 3   d_minus_5_date_foreign      13425 non-null  float64\n",
      " 4   d_minus_5_date_institution  13425 non-null  float64\n",
      " 5   d_minus_5_date_individual   13425 non-null  float64\n",
      " 6   d_minus_4_date_close        13425 non-null  float64\n",
      " 7   d_minus_4_date_volume       13425 non-null  float64\n",
      " 8   d_minus_4_date_foreign      13425 non-null  float64\n",
      " 9   d_minus_4_date_institution  13425 non-null  float64\n",
      " 10  d_minus_4_date_individual   13425 non-null  float64\n",
      " 11  d_minus_3_date_close        13425 non-null  float64\n",
      " 12  d_minus_3_date_volume       13425 non-null  float64\n",
      " 13  d_minus_3_date_foreign      13425 non-null  float64\n",
      " 14  d_minus_3_date_institution  13425 non-null  float64\n",
      " 15  d_minus_3_date_individual   13425 non-null  float64\n",
      " 16  d_minus_2_date_close        13425 non-null  float64\n",
      " 17  d_minus_2_date_volume       13425 non-null  float64\n",
      " 18  d_minus_2_date_foreign      13425 non-null  float64\n",
      " 19  d_minus_2_date_institution  13425 non-null  float64\n",
      " 20  d_minus_2_date_individual   13425 non-null  float64\n",
      " 21  d_minus_1_date_close        13425 non-null  int64  \n",
      " 22  d_minus_1_date_volume       13425 non-null  int64  \n",
      " 23  d_minus_1_date_foreign      13425 non-null  int64  \n",
      " 24  d_minus_1_date_institution  13425 non-null  int64  \n",
      " 25  d_minus_1_date_individual   13425 non-null  int64  \n",
      " 26  d_plus_1_date_close         13425 non-null  float64\n",
      " 27  d_plus_2_date_close         13425 non-null  float64\n",
      " 28  d_plus_3_date_close         13425 non-null  float64\n",
      " 29  d_plus_4_date_close         13425 non-null  float64\n",
      " 30  d_plus_5_date_close         13425 non-null  float64\n",
      " 31  fx                          13425 non-null  float64\n",
      " 32  bond10y                     13425 non-null  float64\n",
      " 33  base_rate                   13425 non-null  float64\n",
      " 34  summary                     13425 non-null  object \n",
      " 35  stock_list                  13425 non-null  object \n",
      " 36  industry_list               13425 non-null  object \n",
      " 37  impact_score                13425 non-null  float64\n",
      "dtypes: float64(29), int64(5), object(4)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3adbbfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07207201918697281"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.d_plus_2_date_close.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b76762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='d_plus_5_date_close', ylabel='Count'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(df.d_plus_5_date_close.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "196dab26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "news_id                                                           20241101_0137\n",
       "d_minus_5_date_close                                                       0.06\n",
       "d_minus_5_date_volume                                                      0.28\n",
       "d_minus_5_date_foreign                                                    -1.77\n",
       "d_minus_5_date_institution                                                 1.34\n",
       "d_minus_5_date_individual                                                 44.02\n",
       "d_minus_4_date_close                                                       0.02\n",
       "d_minus_4_date_volume                                                      0.22\n",
       "d_minus_4_date_foreign                                                     1.08\n",
       "d_minus_4_date_institution                                                -0.29\n",
       "d_minus_4_date_individual                                                -19.04\n",
       "d_minus_3_date_close                                                      -0.01\n",
       "d_minus_3_date_volume                                                      0.21\n",
       "d_minus_3_date_foreign                                                     1.07\n",
       "d_minus_3_date_institution                                                  0.1\n",
       "d_minus_3_date_individual                                                 -13.5\n",
       "d_minus_2_date_close                                                        0.0\n",
       "d_minus_2_date_volume                                                      0.45\n",
       "d_minus_2_date_foreign                                                    -0.58\n",
       "d_minus_2_date_institution                                                 0.57\n",
       "d_minus_2_date_individual                                                 15.88\n",
       "d_minus_1_date_close                                                          0\n",
       "d_minus_1_date_volume                                                         0\n",
       "d_minus_1_date_foreign                                                        0\n",
       "d_minus_1_date_institution                                                    0\n",
       "d_minus_1_date_individual                                                     0\n",
       "d_plus_1_date_close                                                        0.01\n",
       "d_plus_2_date_close                                                        0.03\n",
       "d_plus_3_date_close                                                        0.03\n",
       "d_plus_4_date_close                                                        0.03\n",
       "d_plus_5_date_close                                                        0.04\n",
       "fx                                                                       1379.3\n",
       "bond10y                                                                   2.939\n",
       "base_rate                                                                  3.25\n",
       "summary                       한종희 삼성전자 대표이사 부회장은 1일 수원 디지털시티에서 열린 삼성전자 창립 55...\n",
       "stock_list                                                             [\"삼성전자\"]\n",
       "industry_list                                                [\"통신 및 방송 장비 제조업\"]\n",
       "impact_score                                                           0.473692\n",
       "Name: 5274, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7652507",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1750055694854,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "f7652507"
   },
   "outputs": [],
   "source": [
    "# 2. 타겟 생성\n",
    "target_cols = ['d_plus_1_date_close', 'd_plus_2_date_close', 'd_plus_3_date_close', 'd_plus_4_date_close', 'd_plus_5_date_close']\n",
    "df['target'] = df[target_cols].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "122def94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = df[target_cols].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f50c7ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_targets = df[target_cols].values.tolist()  # → list of lists\n",
    "train_targets = np.array(train_targets)  # → (N, 5) numpy array\n",
    "\n",
    "baseline_mean = train_targets.mean(axis=0)  # shape: (5,)\n",
    "baseline_std = train_targets.std(axis=0)  # shape: (5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100fb712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0078573 , -0.0083497 , -0.00810895, -0.00799404, -0.00891119])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1c5fe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06588189, 0.07283064, 0.07710478, 0.08238087, 0.08863377])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ab84e",
   "metadata": {},
   "source": [
    "특성공학컬럼 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NGNbQmw5Wukk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1750055695183,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "NGNbQmw5Wukk",
    "outputId": "5096c797-9c37-4ae7-8b94-967c08e69366"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Unknown_Stock_For_Imputation' 'Unknown_Stock_For_Imputation'\n",
      " 'Unknown_Stock_For_Imputation' ... 'Unknown_Stock_For_Imputation'\n",
      " 'Unknown_Stock_For_Imputation' 'Unknown_Stock_For_Imputation']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'stock_code'] = df['stock_code'].fillna('Unknown_Stock_For_Imputation')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "def feature_engineer_stock_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    numeric_cols_to_convert = [col for col in df.columns if 'd_minus' in col and ('close' in col or 'volume' in col or 'foreign' in col or 'institution' in col or 'individual' in col) and df[col].dtype == 'int64']\n",
    "    for col in numeric_cols_to_convert:\n",
    "        df.loc[:, col] = df[col].astype(float)\n",
    "\n",
    "    if 'news_id' in df.columns:\n",
    "        try:\n",
    "            df.loc[:, 'date'] = pd.to_datetime(df['news_id'].str[:8], format='%Y%m%d', errors='coerce')\n",
    "        except Exception:\n",
    "            df.loc[:, 'date'] = pd.NaT\n",
    "    else:\n",
    "        df.loc[:, 'date'] = pd.NaT\n",
    "\n",
    "    if 'stock_list' in df.columns:\n",
    "        df.loc[:, 'stock_code'] = df['stock_list'].apply(\n",
    "            lambda x: x[0] if isinstance(x, list) and len(x) > 0 else np.nan\n",
    "        )\n",
    "        df.loc[:, 'stock_code'] = df['stock_code'].fillna('Unknown_Stock_For_Imputation')\n",
    "    else:\n",
    "        df.loc[:, 'stock_code'] = 'Unknown_Stock_For_Imputation'\n",
    "\n",
    "    # 일별 수익률 특성\n",
    "    daily_return_cols = []\n",
    "    for i in range(1, 5):\n",
    "        current_day_close = f'd_minus_{i}_date_close'\n",
    "        prev_day_close = f'd_minus_{i+1}_date_close'\n",
    "        new_col_name = f'd_minus_{i}_daily_return'\n",
    "\n",
    "        if current_day_close in df.columns and prev_day_close in df.columns:\n",
    "            df.loc[:, new_col_name] = (df[current_day_close] - df[prev_day_close]) / df[prev_day_close].replace(0, np.nan)\n",
    "            daily_return_cols.append(new_col_name)\n",
    "\n",
    "    # 이동 평균 특성\n",
    "    moving_average_cols = []\n",
    "    if all(col in df.columns for col in ['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close']):\n",
    "        df.loc[:, 'ma_3_d_minus_1'] = df[['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close']].mean(axis=1)\n",
    "        moving_average_cols.append('ma_3_d_minus_1')\n",
    "\n",
    "    if all(col in df.columns for col in ['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close', 'd_minus_4_date_close', 'd_minus_5_date_close']):\n",
    "        df.loc[:, 'ma_5_d_minus_1'] = df[['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close', 'd_minus_4_date_close', 'd_minus_5_date_close']].mean(axis=1)\n",
    "        moving_average_cols.append('ma_5_d_minus_1')\n",
    "\n",
    "    # 변동성 특성\n",
    "    volatility_cols = []\n",
    "    if daily_return_cols and len(daily_return_cols) >= 2:\n",
    "        df.loc[:, 'vol_5_d_minus_1'] = df[daily_return_cols].std(axis=1)\n",
    "        volatility_cols.append('vol_5_d_minus_1')\n",
    "\n",
    "    # 결측치 처리 \n",
    "    features_to_process_and_impute = daily_return_cols + moving_average_cols + volatility_cols\n",
    "\n",
    "    if not features_to_process_and_impute:\n",
    "        return df\n",
    "\n",
    "    # 퀀타일 계산 임시 데이터프레임\n",
    "    temp_df_for_quantile = df[features_to_process_and_impute].dropna()\n",
    "\n",
    "    for col in daily_return_cols:\n",
    "        if col in temp_df_for_quantile.columns and not temp_df_for_quantile[col].empty:\n",
    "            lower_bound = temp_df_for_quantile[col].quantile(0.01)\n",
    "            upper_bound = temp_df_for_quantile[col].quantile(0.99)\n",
    "            df.loc[:, col] = np.clip(df[col], lower_bound, upper_bound)\n",
    "\n",
    "    if 'vol_5_d_minus_1' in df.columns and 'vol_5_d_minus_1' in temp_df_for_quantile.columns and not temp_df_for_quantile['vol_5_d_minus_1'].empty:\n",
    "        upper_bound_vol = temp_df_for_quantile['vol_5_d_minus_1'].quantile(0.99)\n",
    "        df.loc[:, 'vol_5_d_minus_1'] = np.clip(df['vol_5_d_minus_1'], 0, upper_bound_vol)\n",
    "\n",
    "    # NaN 값 처리\n",
    "    if 'stock_code' in df.columns and 'date' in df.columns and not df['date'].isnull().all():\n",
    "        df_sorted = df.sort_values(by=['stock_code', 'date']).copy()\n",
    "\n",
    "        for col in features_to_process_and_impute:\n",
    "            if col in df_sorted.columns:\n",
    "                df_sorted.loc[:, col] = df_sorted.groupby('stock_code')[col].transform(\n",
    "                    lambda x: x.interpolate(method='linear', limit_direction='both', limit_area='inside')\n",
    "                )\n",
    "                df_sorted.loc[:, col] = df_sorted.groupby('stock_code')[col].transform(\n",
    "                    lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
    "                )\n",
    "                if df_sorted[col].isna().any():\n",
    "                    df_sorted.loc[:, col] = df_sorted[col].fillna(0)\n",
    "\n",
    "        df = df_sorted.loc[df.index].copy()\n",
    "    else:\n",
    "        for col in features_to_process_and_impute:\n",
    "            if col in df.columns and df[col].isna().any():\n",
    "                fill_value = df[col].mean()\n",
    "                if not pd.isna(fill_value):\n",
    "                    df.loc[:, col] = df[col].fillna(fill_value)\n",
    "                else:\n",
    "                    df.loc[:, col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "df = feature_engineer_stock_data(df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b3e09",
   "metadata": {
    "id": "cc5b3e09"
   },
   "source": [
    "피쳐 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aba360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13425 entries, 238 to 13748\n",
      "Data columns (total 48 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   news_id                     13425 non-null  object        \n",
      " 1   d_minus_5_date_close        13425 non-null  float64       \n",
      " 2   d_minus_5_date_volume       13425 non-null  float64       \n",
      " 3   d_minus_5_date_foreign      13425 non-null  float64       \n",
      " 4   d_minus_5_date_institution  13425 non-null  float64       \n",
      " 5   d_minus_5_date_individual   13425 non-null  float64       \n",
      " 6   d_minus_4_date_close        13425 non-null  float64       \n",
      " 7   d_minus_4_date_volume       13425 non-null  float64       \n",
      " 8   d_minus_4_date_foreign      13425 non-null  float64       \n",
      " 9   d_minus_4_date_institution  13425 non-null  float64       \n",
      " 10  d_minus_4_date_individual   13425 non-null  float64       \n",
      " 11  d_minus_3_date_close        13425 non-null  float64       \n",
      " 12  d_minus_3_date_volume       13425 non-null  float64       \n",
      " 13  d_minus_3_date_foreign      13425 non-null  float64       \n",
      " 14  d_minus_3_date_institution  13425 non-null  float64       \n",
      " 15  d_minus_3_date_individual   13425 non-null  float64       \n",
      " 16  d_minus_2_date_close        13425 non-null  float64       \n",
      " 17  d_minus_2_date_volume       13425 non-null  float64       \n",
      " 18  d_minus_2_date_foreign      13425 non-null  float64       \n",
      " 19  d_minus_2_date_institution  13425 non-null  float64       \n",
      " 20  d_minus_2_date_individual   13425 non-null  float64       \n",
      " 21  d_minus_1_date_close        13425 non-null  int64         \n",
      " 22  d_minus_1_date_volume       13425 non-null  int64         \n",
      " 23  d_minus_1_date_foreign      13425 non-null  int64         \n",
      " 24  d_minus_1_date_institution  13425 non-null  int64         \n",
      " 25  d_minus_1_date_individual   13425 non-null  int64         \n",
      " 26  d_plus_1_date_close         13425 non-null  float64       \n",
      " 27  d_plus_2_date_close         13425 non-null  float64       \n",
      " 28  d_plus_3_date_close         13425 non-null  float64       \n",
      " 29  d_plus_4_date_close         13425 non-null  float64       \n",
      " 30  d_plus_5_date_close         13425 non-null  float64       \n",
      " 31  fx                          13425 non-null  float64       \n",
      " 32  bond10y                     13425 non-null  float64       \n",
      " 33  base_rate                   13425 non-null  float64       \n",
      " 34  summary                     13425 non-null  object        \n",
      " 35  stock_list                  13425 non-null  object        \n",
      " 36  industry_list               13425 non-null  object        \n",
      " 37  impact_score                13425 non-null  float64       \n",
      " 38  target                      13425 non-null  object        \n",
      " 39  date                        13425 non-null  datetime64[ns]\n",
      " 40  stock_code                  13425 non-null  object        \n",
      " 41  d_minus_1_daily_return      13425 non-null  float64       \n",
      " 42  d_minus_2_daily_return      13425 non-null  float64       \n",
      " 43  d_minus_3_daily_return      13425 non-null  float64       \n",
      " 44  d_minus_4_daily_return      13425 non-null  float64       \n",
      " 45  ma_3_d_minus_1              13425 non-null  float64       \n",
      " 46  ma_5_d_minus_1              13425 non-null  float64       \n",
      " 47  vol_5_d_minus_1             13425 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(36), int64(5), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1c1a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1750055695491,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "35c1c1a4",
    "outputId": "63157edd-4be5-4afd-d87e-fb78e650e081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 external_cols 수: 35\n",
      "최종 external_cols 예시: ['fx', 'bond10y', 'base_rate', 'd_minus_5_date_volume', 'd_minus_4_date_volume', 'd_minus_3_date_volume', 'd_minus_2_date_volume', 'd_minus_1_date_volume', 'd_minus_5_date_foreign', 'd_minus_4_date_foreign', 'd_minus_3_date_foreign', 'd_minus_2_date_foreign', 'd_minus_1_date_foreign', 'd_minus_5_date_institution', 'd_minus_4_date_institution', 'd_minus_3_date_institution', 'd_minus_2_date_institution', 'd_minus_1_date_institution', 'd_minus_5_date_individual', 'd_minus_4_date_individual', 'd_minus_3_date_individual', 'd_minus_2_date_individual', 'd_minus_1_date_individual', 'd_minus_5_date_close', 'd_minus_4_date_close', 'd_minus_3_date_close', 'd_minus_2_date_close', 'd_minus_1_date_close', 'd_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return', 'ma_3_d_minus_1', 'ma_5_d_minus_1', 'vol_5_d_minus_1'] ...\n",
      "\n",
      "--- 훈련/검증 데이터 스케일링 시작 ---\n"
     ]
    }
   ],
   "source": [
    "# standard\n",
    "group_price_close = [\n",
    "    'd_minus_5_date_close', 'd_minus_4_date_close',\n",
    "    'd_minus_3_date_close', 'd_minus_2_date_close',\n",
    "    'd_minus_1_date_close'\n",
    "]\n",
    "\n",
    "# RobustScaler\n",
    "group_volume = [\n",
    "    'd_minus_5_date_volume', 'd_minus_4_date_volume',\n",
    "    'd_minus_3_date_volume', 'd_minus_2_date_volume',\n",
    "    'd_minus_1_date_volume'\n",
    "]\n",
    "\n",
    "# MinMaxScaler\n",
    "group_foreign = [\n",
    "    'd_minus_5_date_foreign', 'd_minus_4_date_foreign',\n",
    "    'd_minus_3_date_foreign', 'd_minus_2_date_foreign',\n",
    "    'd_minus_1_date_foreign'\n",
    "]\n",
    "\n",
    "# MinMaxScaler\n",
    "group_institution = [\n",
    "    'd_minus_5_date_institution', 'd_minus_4_date_institution',\n",
    "    'd_minus_3_date_institution', 'd_minus_2_date_institution',\n",
    "    'd_minus_1_date_institution'\n",
    "]\n",
    "\n",
    "# MinMaxScaler\n",
    "group_individual = [\n",
    "    'd_minus_5_date_individual', 'd_minus_4_date_individual',\n",
    "    'd_minus_3_date_individual', 'd_minus_2_date_individual',\n",
    "    'd_minus_1_date_individual'\n",
    "]\n",
    "\n",
    "# StandardScaler\n",
    "group_macro = ['fx', 'bond10y', 'base_rate']\n",
    "\n",
    "# RobustScaler\n",
    "daily_return_cols = ['d_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return']\n",
    "\n",
    "# StandardScaler\n",
    "moving_average_cols = ['ma_3_d_minus_1', 'ma_5_d_minus_1']\n",
    "\n",
    "# RobustScaler\n",
    "volatility_cols = ['vol_5_d_minus_1']\n",
    "\n",
    "\n",
    "groups = [\n",
    "    group_macro,\n",
    "    group_volume,\n",
    "    group_foreign,\n",
    "    group_institution,\n",
    "    group_individual,\n",
    "    group_price_close,     \n",
    "    daily_return_cols,     \n",
    "    moving_average_cols,  \n",
    "    volatility_cols     \n",
    "]\n",
    "\n",
    "scaler_choices = [\n",
    "    StandardScaler(), # group_macro\n",
    "    RobustScaler(),   # group_volume\n",
    "    MinMaxScaler(),   # group_foreign\n",
    "    MinMaxScaler(),   # group_institution\n",
    "    MinMaxScaler(),   # group_individual\n",
    "    StandardScaler(), # group_price_close \n",
    "    RobustScaler(),   # daily_return_cols\n",
    "    StandardScaler(), # moving_average_cols \n",
    "    RobustScaler()    # volatility_cols\n",
    "]\n",
    "\n",
    "external_cols = []\n",
    "for group in groups:\n",
    "    valid_group_cols = [col for col in group if col in df.columns]\n",
    "    external_cols.extend(valid_group_cols)\n",
    "\n",
    "\n",
    "# 3. 훈련/검증 분할 및 스케일링 \n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "fitted_scalers = {}\n",
    "\n",
    "for i, group in enumerate(groups):\n",
    "    scaler = scaler_choices[i]\n",
    "    group_in_train = [col for col in group if col in train_df.columns]\n",
    "    group_in_val = [col for col in group if col in val_df.columns]\n",
    "\n",
    "    if not group_in_train:\n",
    "        continue\n",
    "\n",
    "    scaler.fit(train_df[group_in_train])\n",
    "    fitted_scalers[i] = scaler\n",
    "\n",
    "    train_df.loc[:, group_in_train] = scaler.transform(train_df[group_in_train])\n",
    "    if group_in_val: # 검증 데이터에도 해당 컬럼이 있을 경우에만\n",
    "        val_df.loc[:, group_in_val] = scaler.transform(val_df[group_in_val])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "# 타겟 변수 스케일링 \n",
    "target_scaler = StandardScaler()\n",
    "train_targets_np = np.array(train_df['target'].tolist())\n",
    "val_targets_np = np.array(val_df['target'].tolist())\n",
    "\n",
    "target_scaler.fit(train_targets_np)\n",
    "\n",
    "train_df['target_scaled'] = target_scaler.transform(train_targets_np).tolist()\n",
    "val_df['target_scaled'] = target_scaler.transform(val_targets_np).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fp94muN-2FfR",
   "metadata": {
    "id": "fp94muN-2FfR"
   },
   "source": [
    "문장 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z7O6U1AI4wgR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283,
     "referenced_widgets": [
      "3b7d14897fa24011af6b6d099698bd1b",
      "fa9b53374d85472da0a1644e8f79f86f",
      "fd419b488eb445e782996e64ee5494be",
      "83382077d7cf4b8dbeb58a5d68adaf93",
      "836dc1e7bcfc4e0aa95c9faea66d3fa3",
      "5e6b30239d9b461ca351af04202f247e",
      "a3fe48525cb54d788e143e661376c95d",
      "c0ac2b64b88e46ad8bc8037e9fccbcf1",
      "fbdca1d6956a406bbc7549a193deb038",
      "2fef822f442d4f3d8e03814c7e496ce8",
      "21a8bcdd6597486db635aac5f2dd97ba",
      "7a32a4d2e0874adc8982b2000f9b5f22",
      "f2ef81b3e5e249f9a0478c1d381c73c0",
      "b5197080d49c4506b2051ff4985ddd80",
      "ae633c6a2c2748a995fe55cca1b52b93",
      "54dedc7ea78b4fca9cd4d4f3e524d1f6",
      "57db0ce6d1f14f9c93b3809f36b82a90",
      "7d9cb465e9d24422ad5074c4796ad935",
      "88ae59b895584037b599857bf9d0c0bc",
      "95ec754902be45159350b218ae3a1728",
      "086bd873c70444ccae24607d81ab90e6",
      "f528505a611042359507d3948d467209"
     ]
    },
    "executionInfo": {
     "elapsed": 52796,
     "status": "ok",
     "timestamp": 1750055748287,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "z7O6U1AI4wgR",
    "outputId": "d880bd40-bc48-44ef-bf6b-f0339b6eafbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\tensor\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--snunlp--KR-SBERT-V40K-klueNLI-augSTS. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 훈련 데이터 임베딩 생성 (10740개 뉴스)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 336/336 [00:26<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 검증 데이터 임베딩 생성 (2685개 뉴스)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 84/84 [00:06<00:00, 13.43it/s]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "model_emb = SentenceTransformer(\n",
    "    \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\",\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(f\"\\n훈련 데이터 임베딩 생성 ({len(train_df)}개 뉴스)\")\n",
    "train_summary_embedding = model_emb.encode(\n",
    "    train_df[\"summary\"].tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_tensor=True\n",
    ")\n",
    "train_df[\"embedding\"] = train_summary_embedding.cpu().numpy().tolist()\n",
    "\n",
    "print(f\"\\n검증 데이터 임베딩 생성 ({len(val_df)}개 뉴스)\")\n",
    "val_summary_embedding = model_emb.encode(\n",
    "    val_df[\"summary\"].tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_tensor=True\n",
    ")\n",
    "val_df[\"embedding\"] = val_summary_embedding.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V6MLhLbX7PRh",
   "metadata": {
    "id": "V6MLhLbX7PRh"
   },
   "source": [
    "데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tGGVffrd7MUI",
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1750055748952,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "tGGVffrd7MUI"
   },
   "outputs": [],
   "source": [
    "# Dataset 및 DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, external_cols):\n",
    "        self.embeddings = torch.tensor(df[\"embedding\"].tolist(), dtype=torch.float32)\n",
    "        self.external_features = torch.tensor(df[external_cols].values, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(df[\"target_scaled\"].tolist(), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.external_features[idx], self.targets[idx]\n",
    "\n",
    "train_dataset = CustomDataset(train_df, external_cols)\n",
    "val_dataset = CustomDataset(val_df, external_cols)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_ZsysAfu4z7v",
   "metadata": {
    "id": "_ZsysAfu4z7v"
   },
   "source": [
    "오토인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cachKDHJ42aY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10578,
     "status": "ok",
     "timestamp": 1750055759534,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "cachKDHJ42aY",
    "outputId": "98c6073e-8e52-48d5-f5c4-faa66a748c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 오토인코더 사전학습 시작\n",
      "[AE] Epoch 1 | Train Loss: 0.1634 | Val Loss: 0.1152\n",
      "[AE] Epoch 2 | Train Loss: 0.0975 | Val Loss: 0.0833\n",
      "[AE] Epoch 3 | Train Loss: 0.0759 | Val Loss: 0.0692\n",
      "[AE] Epoch 4 | Train Loss: 0.0648 | Val Loss: 0.0607\n",
      "[AE] Epoch 5 | Train Loss: 0.0577 | Val Loss: 0.0550\n",
      "[AE] Epoch 6 | Train Loss: 0.0526 | Val Loss: 0.0506\n",
      "[AE] Epoch 7 | Train Loss: 0.0486 | Val Loss: 0.0472\n",
      "[AE] Epoch 8 | Train Loss: 0.0455 | Val Loss: 0.0444\n",
      "[AE] Epoch 9 | Train Loss: 0.0429 | Val Loss: 0.0420\n",
      "[AE] Epoch 10 | Train Loss: 0.0407 | Val Loss: 0.0401\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(latent_dim * 2, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(latent_dim * 2, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "# 임베딩 차원\n",
    "embedding_dim = model_emb.get_sentence_embedding_dimension()\n",
    "latent_dim = 128 \n",
    "\n",
    "ae_model = Autoencoder(input_dim=embedding_dim, latent_dim=latent_dim).to(device)\n",
    "\n",
    "def freeze_module(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def train_autoencoder(model, train_loader, val_loader=None, epochs=10, device='cuda'):\n",
    "    ae_optimizer = torch.optim.AdamW(\n",
    "        list(model.encoder.parameters()) + list(model.decoder.parameters()),\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.encoder.train()\n",
    "    model.decoder.train()\n",
    "\n",
    "    print(\"\\n오토인코더 사전학습 시작\")\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_embedding, _, _ in train_loader: \n",
    "            embeddings = batch_embedding.to(device)\n",
    "\n",
    "            latent = model.encoder(embeddings)\n",
    "            reconstructed = model.decoder(latent)\n",
    "\n",
    "            loss = criterion(reconstructed, embeddings)\n",
    "            ae_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            ae_optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss = 0\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_batch_embedding, _, _ in val_loader: \n",
    "                    val_embeddings = val_batch_embedding.to(device)\n",
    "                    val_latent = model.encoder(val_embeddings)\n",
    "                    val_reconstructed = model.decoder(val_latent)\n",
    "                    val_loss += criterion(val_reconstructed, val_embeddings).item()\n",
    "            model.train() # 학습 모드로 전환\n",
    "            print(f\"[AE] Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "        else:\n",
    "            print(f\"[AE] Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    model.encoder.eval()\n",
    "    model.decoder.eval()\n",
    "    return model\n",
    "\n",
    "# 오토인코더 학습 \n",
    "ae_model = train_autoencoder(ae_model, train_loader, val_loader, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kNXmPUch5Xgv",
   "metadata": {
    "id": "kNXmPUch5Xgv"
   },
   "source": [
    "예측 모델 재구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qfJCXDgv5S30",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750055759550,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "qfJCXDgv5S30"
   },
   "outputs": [],
   "source": [
    "class ImportancePredictor(nn.Module):\n",
    "    def __init__(self, ae_encoder, external_feature_dim, fcl_hidden=1024, dropout=0.25): \n",
    "        super().__init__()\n",
    "        self.encoder = ae_encoder\n",
    "        encoder_output_dim = ae_encoder[-1].out_features if isinstance(ae_encoder[-1], nn.Linear) else latent_dim\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(encoder_output_dim + external_feature_dim, fcl_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden, fcl_hidden // 2),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 2),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 2, fcl_hidden // 4),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 4),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 4, fcl_hidden // 8), \n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 8),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 8, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, embedding, external):\n",
    "        latent = self.encoder(embedding)\n",
    "        combined = torch.cat([latent, external], dim=1)\n",
    "        return self.predictor(combined)\n",
    "\n",
    "# ImportancePredictor 초기화\n",
    "predictor = ImportancePredictor(\n",
    "    ae_encoder=ae_model.encoder,\n",
    "    external_feature_dim=len(external_cols) \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5NNbVAoF5bfg",
   "metadata": {
    "id": "5NNbVAoF5bfg"
   },
   "source": [
    "학습 및 검증 (프리징)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\2944849852.py:34: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 메인 예측기 학습 시작\n",
      "[Epoch 1] Train Loss: 0.4712 | Val Loss: 0.3768 | MAE: 0.05 | RMSE: 0.09 | R²: -0.0887 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.4898\n",
      "[Epoch 2] Train Loss: 0.4608 | Val Loss: 0.3690 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0712 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.4924\n",
      "[Epoch 3] Train Loss: 0.4498 | Val Loss: 0.3637 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0570 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.4956\n",
      "[Epoch 4] Train Loss: 0.4416 | Val Loss: 0.3597 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0480 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5038\n",
      "[Epoch 5] Train Loss: 0.4349 | Val Loss: 0.3578 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0429 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5004\n",
      "[Epoch 6] Train Loss: 0.4297 | Val Loss: 0.3535 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0319 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5032\n",
      "[Epoch 7] Train Loss: 0.4253 | Val Loss: 0.3528 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0327 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5061\n",
      "[Epoch 8] Train Loss: 0.4238 | Val Loss: 0.3530 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0306 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5082\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 9] Train Loss: 0.4207 | Val Loss: 0.3505 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0242 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5070\n",
      "[Epoch 10] Train Loss: 0.4170 | Val Loss: 0.3498 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0235 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5081\n",
      "[Epoch 11] Train Loss: 0.4123 | Val Loss: 0.3498 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0238 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5137\n",
      "[Epoch 12] Train Loss: 0.4091 | Val Loss: 0.3476 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0179 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5131\n",
      "[Epoch 13] Train Loss: 0.4044 | Val Loss: 0.3467 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0159 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5128\n",
      "[Epoch 14] Train Loss: 0.4001 | Val Loss: 0.3440 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0101 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5166\n",
      "[Epoch 15] Train Loss: 0.3957 | Val Loss: 0.3452 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0112 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5148\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 16] Train Loss: 0.3920 | Val Loss: 0.3439 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0082 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5118\n",
      "[Epoch 17] Train Loss: 0.3888 | Val Loss: 0.3426 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0061 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5199\n",
      "[Epoch 18] Train Loss: 0.3891 | Val Loss: 0.3424 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0049 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5177\n",
      "[Epoch 19] Train Loss: 0.3846 | Val Loss: 0.3413 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0033 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5210\n",
      "[Epoch 20] Train Loss: 0.3878 | Val Loss: 0.3410 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0030 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5190\n",
      "[Epoch 21] Train Loss: 0.3838 | Val Loss: 0.3411 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0021 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5214\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 22] Train Loss: 0.3835 | Val Loss: 0.3421 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0047 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5239\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 23] Train Loss: 0.3799 | Val Loss: 0.3396 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0014 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5216\n",
      "[Epoch 24] Train Loss: 0.3788 | Val Loss: 0.3405 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0004 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5236\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 25] Train Loss: 0.3775 | Val Loss: 0.3396 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0008 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5224\n",
      "[Epoch 26] Train Loss: 0.3790 | Val Loss: 0.3397 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0002 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5277\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 27] Train Loss: 0.3774 | Val Loss: 0.3390 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0016 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5233\n",
      "[Epoch 28] Train Loss: 0.3731 | Val Loss: 0.3390 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0017 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5286\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 29] Train Loss: 0.3719 | Val Loss: 0.3389 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0012 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5289\n",
      "[Epoch 30] Train Loss: 0.3702 | Val Loss: 0.3385 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0026 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5295\n",
      "[Epoch 31] Train Loss: 0.3689 | Val Loss: 0.3370 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0065 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5241\n",
      "[Epoch 32] Train Loss: 0.3686 | Val Loss: 0.3368 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0058 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5323\n",
      "[Epoch 33] Train Loss: 0.3667 | Val Loss: 0.3371 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0064 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5280\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 34] Train Loss: 0.3657 | Val Loss: 0.3374 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0054 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5292\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 35] Train Loss: 0.3658 | Val Loss: 0.3372 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0068 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5273\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 36] Train Loss: 0.3618 | Val Loss: 0.3355 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0091 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5286\n",
      "[Epoch 37] Train Loss: 0.3640 | Val Loss: 0.3362 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0092 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5300\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 38] Train Loss: 0.3624 | Val Loss: 0.3361 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0081 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5309\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 39] Train Loss: 0.3612 | Val Loss: 0.3362 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0089 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5265\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 40] Train Loss: 0.3607 | Val Loss: 0.3360 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0086 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5298\n",
      " -> 조기 종료 카운터: 4/15\n",
      "[Epoch 41] Train Loss: 0.3611 | Val Loss: 0.3354 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0121 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5268\n",
      "[Epoch 42] Train Loss: 0.3603 | Val Loss: 0.3351 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0119 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5283\n",
      "[Epoch 43] Train Loss: 0.3579 | Val Loss: 0.3350 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0110 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5323\n",
      "[Epoch 44] Train Loss: 0.3564 | Val Loss: 0.3345 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0128 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5283\n",
      "[Epoch 45] Train Loss: 0.3563 | Val Loss: 0.3344 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0137 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5351\n",
      "[Epoch 46] Train Loss: 0.3543 | Val Loss: 0.3340 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0128 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5366\n",
      "[Epoch 47] Train Loss: 0.3546 | Val Loss: 0.3334 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0163 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5345\n",
      "[Epoch 48] Train Loss: 0.3511 | Val Loss: 0.3336 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0163 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5321\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 49] Train Loss: 0.3512 | Val Loss: 0.3339 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0134 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5363\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 50] Train Loss: 0.3516 | Val Loss: 0.3331 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0144 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5351\n",
      "[Epoch 51] Train Loss: 0.3495 | Val Loss: 0.3335 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0151 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5352\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 52] Train Loss: 0.3502 | Val Loss: 0.3330 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0161 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5369\n",
      "[Epoch 53] Train Loss: 0.3495 | Val Loss: 0.3328 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0164 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5380\n",
      "[Epoch 54] Train Loss: 0.3480 | Val Loss: 0.3330 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0168 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5341\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 55] Train Loss: 0.3484 | Val Loss: 0.3331 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0165 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5377\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 56] Train Loss: 0.3477 | Val Loss: 0.3317 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0189 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5385\n",
      "[Epoch 57] Train Loss: 0.3479 | Val Loss: 0.3322 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0171 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5389\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 58] Train Loss: 0.3446 | Val Loss: 0.3321 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0185 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5368\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 59] Train Loss: 0.3458 | Val Loss: 0.3320 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0196 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5398\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 60] Train Loss: 0.3434 | Val Loss: 0.3316 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0188 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5409\n",
      "[Epoch 61] Train Loss: 0.3450 | Val Loss: 0.3314 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0200 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5421\n",
      "[Epoch 62] Train Loss: 0.3426 | Val Loss: 0.3313 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0203 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5389\n",
      "[Epoch 63] Train Loss: 0.3446 | Val Loss: 0.3316 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0195 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5385\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 64] Train Loss: 0.3411 | Val Loss: 0.3311 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0198 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5392\n",
      "[Epoch 65] Train Loss: 0.3416 | Val Loss: 0.3307 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0217 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5415\n",
      "[Epoch 66] Train Loss: 0.3406 | Val Loss: 0.3304 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0233 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5401\n",
      "[Epoch 67] Train Loss: 0.3401 | Val Loss: 0.3304 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0224 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5406\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 68] Train Loss: 0.3399 | Val Loss: 0.3300 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0228 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5418\n",
      "[Epoch 69] Train Loss: 0.3371 | Val Loss: 0.3301 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0240 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5442\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 70] Train Loss: 0.3385 | Val Loss: 0.3299 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0226 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5421\n",
      "[Epoch 71] Train Loss: 0.3377 | Val Loss: 0.3299 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0229 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5435\n",
      "[Epoch 72] Train Loss: 0.3362 | Val Loss: 0.3294 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0264 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5393\n",
      "[Epoch 73] Train Loss: 0.3362 | Val Loss: 0.3291 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0266 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5435\n",
      "[Epoch 74] Train Loss: 0.3353 | Val Loss: 0.3289 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0270 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5463\n",
      "[Epoch 75] Train Loss: 0.3355 | Val Loss: 0.3288 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0276 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5452\n",
      "[Epoch 76] Train Loss: 0.3331 | Val Loss: 0.3289 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0272 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5464\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 77] Train Loss: 0.3340 | Val Loss: 0.3288 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0276 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5441\n",
      "[Epoch 78] Train Loss: 0.3341 | Val Loss: 0.3286 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0274 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5455\n",
      "[Epoch 79] Train Loss: 0.3340 | Val Loss: 0.3290 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0266 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5455\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 80] Train Loss: 0.3323 | Val Loss: 0.3283 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0272 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5442\n",
      "[Epoch 81] Train Loss: 0.3332 | Val Loss: 0.3281 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0289 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5488\n",
      "[Epoch 82] Train Loss: 0.3322 | Val Loss: 0.3278 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0314 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5455\n",
      "[Epoch 83] Train Loss: 0.3299 | Val Loss: 0.3283 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0288 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5435\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 84] Train Loss: 0.3302 | Val Loss: 0.3276 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0305 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5472\n",
      "[Epoch 85] Train Loss: 0.3305 | Val Loss: 0.3276 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0302 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5460\n",
      "[Epoch 86] Train Loss: 0.3307 | Val Loss: 0.3275 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0305 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5441\n",
      "[Epoch 87] Train Loss: 0.3302 | Val Loss: 0.3274 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0297 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5460\n",
      "[Epoch 88] Train Loss: 0.3286 | Val Loss: 0.3274 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0307 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5499\n",
      "[Epoch 89] Train Loss: 0.3279 | Val Loss: 0.3270 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0325 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5462\n",
      "[Epoch 90] Train Loss: 0.3292 | Val Loss: 0.3272 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0326 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5458\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 91] Train Loss: 0.3282 | Val Loss: 0.3273 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0311 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5498\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 92] Train Loss: 0.3285 | Val Loss: 0.3267 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0336 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5473\n",
      "[Epoch 93] Train Loss: 0.3263 | Val Loss: 0.3268 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0329 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5456\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 94] Train Loss: 0.3243 | Val Loss: 0.3263 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0344 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5474\n",
      "[Epoch 95] Train Loss: 0.3274 | Val Loss: 0.3263 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0341 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5491\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 96] Train Loss: 0.3249 | Val Loss: 0.3259 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0336 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5550\n",
      "[Epoch 97] Train Loss: 0.3248 | Val Loss: 0.3262 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0350 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5480\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 98] Train Loss: 0.3244 | Val Loss: 0.3252 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0366 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5518\n",
      "[Epoch 99] Train Loss: 0.3256 | Val Loss: 0.3254 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0372 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5494\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 100] Train Loss: 0.3231 | Val Loss: 0.3251 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0375 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5502\n",
      "[Epoch 101] Train Loss: 0.3228 | Val Loss: 0.3254 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0371 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5467\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 102] Train Loss: 0.3225 | Val Loss: 0.3248 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0378 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5521\n",
      "[Epoch 103] Train Loss: 0.3215 | Val Loss: 0.3249 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0391 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5503\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 104] Train Loss: 0.3211 | Val Loss: 0.3255 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0373 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5465\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 105] Train Loss: 0.3213 | Val Loss: 0.3247 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0395 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5493\n",
      "[Epoch 106] Train Loss: 0.3203 | Val Loss: 0.3247 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0390 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5517\n",
      "[Epoch 107] Train Loss: 0.3210 | Val Loss: 0.3248 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0385 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5514\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 108] Train Loss: 0.3208 | Val Loss: 0.3244 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0418 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5538\n",
      "[Epoch 109] Train Loss: 0.3203 | Val Loss: 0.3243 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0396 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5531\n",
      "[Epoch 110] Train Loss: 0.3210 | Val Loss: 0.3243 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0418 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5496\n",
      "[Epoch 111] Train Loss: 0.3200 | Val Loss: 0.3242 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0406 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5519\n",
      "[Epoch 112] Train Loss: 0.3209 | Val Loss: 0.3237 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0417 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5572\n",
      "[Epoch 113] Train Loss: 0.3187 | Val Loss: 0.3240 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0404 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5523\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 114] Train Loss: 0.3172 | Val Loss: 0.3237 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0436 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5508\n",
      "[Epoch 115] Train Loss: 0.3168 | Val Loss: 0.3236 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0441 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5514\n",
      "[Epoch 116] Train Loss: 0.3174 | Val Loss: 0.3238 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0402 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5503\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 117] Train Loss: 0.3169 | Val Loss: 0.3232 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0432 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5576\n",
      "[Epoch 118] Train Loss: 0.3153 | Val Loss: 0.3229 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0445 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5540\n",
      "[Epoch 119] Train Loss: 0.3155 | Val Loss: 0.3231 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0437 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5540\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 120] Train Loss: 0.3166 | Val Loss: 0.3229 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0454 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5526\n",
      "[Epoch 121] Train Loss: 0.3145 | Val Loss: 0.3226 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0466 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5552\n",
      "[Epoch 122] Train Loss: 0.3140 | Val Loss: 0.3222 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0484 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5542\n",
      "[Epoch 123] Train Loss: 0.3132 | Val Loss: 0.3227 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0473 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5508\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 124] Train Loss: 0.3137 | Val Loss: 0.3226 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0467 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5569\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 125] Train Loss: 0.3139 | Val Loss: 0.3223 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0450 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5574\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 126] Train Loss: 0.3127 | Val Loss: 0.3223 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0462 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5570\n",
      " -> 조기 종료 카운터: 4/15\n",
      "[Epoch 127] Train Loss: 0.3131 | Val Loss: 0.3221 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0484 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5543\n",
      "[Epoch 128] Train Loss: 0.3125 | Val Loss: 0.3218 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0493 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5587\n",
      "[Epoch 129] Train Loss: 0.3129 | Val Loss: 0.3222 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0476 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5565\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 130] Train Loss: 0.3137 | Val Loss: 0.3218 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0467 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5579\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 131] Train Loss: 0.3118 | Val Loss: 0.3220 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0474 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5578\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 132] Train Loss: 0.3122 | Val Loss: 0.3213 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0501 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5572\n",
      "[Epoch 133] Train Loss: 0.3125 | Val Loss: 0.3216 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0489 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5560\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 134] Train Loss: 0.3104 | Val Loss: 0.3215 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0498 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5554\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 135] Train Loss: 0.3106 | Val Loss: 0.3218 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0489 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5562\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 136] Train Loss: 0.3090 | Val Loss: 0.3208 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0516 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5552\n",
      "[Epoch 137] Train Loss: 0.3097 | Val Loss: 0.3216 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0495 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5588\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 138] Train Loss: 0.3095 | Val Loss: 0.3211 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0514 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5581\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 139] Train Loss: 0.3107 | Val Loss: 0.3211 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0508 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5617\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 140] Train Loss: 0.3093 | Val Loss: 0.3211 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0535 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5542\n",
      " -> 조기 종료 카운터: 4/15\n",
      "[Epoch 141] Train Loss: 0.3082 | Val Loss: 0.3205 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0525 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5613\n",
      "[Epoch 142] Train Loss: 0.3089 | Val Loss: 0.3210 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0521 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5578\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 143] Train Loss: 0.3100 | Val Loss: 0.3210 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0514 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5587\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 144] Train Loss: 0.3077 | Val Loss: 0.3204 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0533 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5596\n",
      "[Epoch 145] Train Loss: 0.3081 | Val Loss: 0.3203 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0532 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5616\n",
      "[Epoch 146] Train Loss: 0.3073 | Val Loss: 0.3204 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0533 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5606\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 147] Train Loss: 0.3082 | Val Loss: 0.3205 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0533 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5584\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 148] Train Loss: 0.3055 | Val Loss: 0.3202 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0525 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5637\n",
      "[Epoch 149] Train Loss: 0.3068 | Val Loss: 0.3202 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0535 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5636\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 150] Train Loss: 0.3068 | Val Loss: 0.3200 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0551 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5622\n",
      "최적 모델: Epoch 150 | MAE: 0.05 | R²: 0.0551\n"
     ]
    }
   ],
   "source": [
    "def train_predictor(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    target_scaler,\n",
    "    device='cuda',\n",
    "    epochs=150, \n",
    "    patience=15, \n",
    "    max_grad_norm=1.0\n",
    "):\n",
    "    # 프리징 초기화\n",
    "    freeze_module(model.encoder)  \n",
    "    model.encoder.eval()  \n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.predictor.parameters(), \n",
    "        lr=5e-6,\n",
    "        weight_decay=1e-6\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        'min',\n",
    "        patience=5, \n",
    "        factor=0.5\n",
    "    )\n",
    "    criterion = nn.HuberLoss() \n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    print(\"메인 예측기 학습 시작\")\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # --------- 훈련 단계 ---------\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        for batch_embedding, batch_external, batch_targets in train_loader:\n",
    "            embeddings = batch_embedding.to(device)\n",
    "            external_features = batch_external.to(device)\n",
    "            targets = batch_targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "                preds = model(embeddings, external_features)\n",
    "                loss = criterion(preds, targets)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.predictor.parameters(),  \n",
    "                max_grad_norm\n",
    "            )\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        # --------- 검증 단계 ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_embedding, batch_external, batch_targets in val_loader:\n",
    "                embeddings = batch_embedding.to(device)\n",
    "                external_features = batch_external.to(device)\n",
    "                targets = batch_targets.to(device)\n",
    "\n",
    "                with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "                    preds = model(embeddings, external_features)\n",
    "                    loss = criterion(preds, targets)\n",
    "                    total_val_loss += loss.item()\n",
    "                    all_preds.append(preds.cpu())\n",
    "                    all_targets.append(targets.cpu())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "        all_preds_np = torch.cat(all_preds).numpy()\n",
    "        all_targets_np = torch.cat(all_targets).numpy()\n",
    "        preds_inv = target_scaler.inverse_transform(all_preds_np)\n",
    "        targets_inv = target_scaler.inverse_transform(all_targets_np)\n",
    "\n",
    "        mae = nn.L1Loss()(torch.tensor(preds_inv), torch.tensor(targets_inv)).item()\n",
    "        rmse = torch.sqrt(nn.MSELoss()(torch.tensor(preds_inv), torch.tensor(targets_inv))).item()\n",
    "        r2 = r2_score(targets_inv, preds_inv)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | MAE: {mae:.2f} | RMSE: {rmse:.2f} | R²: {r2:.4f} | \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        direction_match = (np.sign(preds_inv) == np.sign(targets_inv))\n",
    "        directional_accuracy = np.mean(direction_match)\n",
    "        print(f\"Directional Accuracy: {directional_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # --------- 조기 종료 ---------\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_epoch = epoch + 1\n",
    "            best_mae = mae\n",
    "            best_r2 = r2\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\" -> 조기 종료 카운터: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(f\" -> epoch {epoch+1}에서 조기 종료!\")\n",
    "                break\n",
    "\n",
    "    print(f\"최적 모델: Epoch {best_epoch} | MAE: {best_mae:.2f} | R²: {best_r2:.4f}\")\n",
    "    return model\n",
    "\n",
    "# 최종 예측기 학습 실행\n",
    "trained_predictor = train_predictor(\n",
    "    predictor,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    target_scaler,\n",
    "    device=device,\n",
    "    epochs=150, \n",
    "    patience=15 \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29815a1b",
   "metadata": {},
   "source": [
    "모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba18dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch.onnx\n",
    "\n",
    "# 입력 특성별 스케일러 \n",
    "for idx, scaler in fitted_scalers.items():\n",
    "    joblib.dump(scaler, f\"scaler_group_{idx}.joblib\")\n",
    "\n",
    "# 타겟 스케일러 \n",
    "joblib.dump(target_scaler, \"target_scaler.joblib\")\n",
    "\n",
    "dummy_embedding = torch.randn(1, embedding_dim, device=device)\n",
    "\n",
    "# encoder만 ONNX로 저장\n",
    "torch.onnx.export(\n",
    "    ae_model.encoder,\n",
    "    dummy_embedding,\n",
    "    \"ae_encoder.onnx\",\n",
    "    input_names=[\"embedding\"],\n",
    "    output_names=[\"latent\"],\n",
    "    dynamic_axes={\"embedding\": {0: \"batch_size\"}, \"latent\": {0: \"batch_size\"}},\n",
    "    opset_version=17\n",
    ")\n",
    "\n",
    "# 외부 피처 차원 정보\n",
    "external_feature_dim = len(external_cols)\n",
    "dummy_external = torch.randn(1, external_feature_dim, device=device)\n",
    "\n",
    "# predictor 전체 ONNX로 저장\n",
    "torch.onnx.export(\n",
    "    predictor,\n",
    "    (dummy_embedding, dummy_external),\n",
    "    \"predictor.onnx\",\n",
    "    input_names=[\"embedding\", \"external\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"embedding\": {0: \"batch_size\"},\n",
    "        \"external\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=17\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c174f297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13425 entries, 238 to 13748\n",
      "Data columns (total 48 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   news_id                     13425 non-null  object        \n",
      " 1   d_minus_5_date_close        13425 non-null  float64       \n",
      " 2   d_minus_5_date_volume       13425 non-null  float64       \n",
      " 3   d_minus_5_date_foreign      13425 non-null  float64       \n",
      " 4   d_minus_5_date_institution  13425 non-null  float64       \n",
      " 5   d_minus_5_date_individual   13425 non-null  float64       \n",
      " 6   d_minus_4_date_close        13425 non-null  float64       \n",
      " 7   d_minus_4_date_volume       13425 non-null  float64       \n",
      " 8   d_minus_4_date_foreign      13425 non-null  float64       \n",
      " 9   d_minus_4_date_institution  13425 non-null  float64       \n",
      " 10  d_minus_4_date_individual   13425 non-null  float64       \n",
      " 11  d_minus_3_date_close        13425 non-null  float64       \n",
      " 12  d_minus_3_date_volume       13425 non-null  float64       \n",
      " 13  d_minus_3_date_foreign      13425 non-null  float64       \n",
      " 14  d_minus_3_date_institution  13425 non-null  float64       \n",
      " 15  d_minus_3_date_individual   13425 non-null  float64       \n",
      " 16  d_minus_2_date_close        13425 non-null  float64       \n",
      " 17  d_minus_2_date_volume       13425 non-null  float64       \n",
      " 18  d_minus_2_date_foreign      13425 non-null  float64       \n",
      " 19  d_minus_2_date_institution  13425 non-null  float64       \n",
      " 20  d_minus_2_date_individual   13425 non-null  float64       \n",
      " 21  d_minus_1_date_close        13425 non-null  int64         \n",
      " 22  d_minus_1_date_volume       13425 non-null  int64         \n",
      " 23  d_minus_1_date_foreign      13425 non-null  int64         \n",
      " 24  d_minus_1_date_institution  13425 non-null  int64         \n",
      " 25  d_minus_1_date_individual   13425 non-null  int64         \n",
      " 26  d_plus_1_date_close         13425 non-null  float64       \n",
      " 27  d_plus_2_date_close         13425 non-null  float64       \n",
      " 28  d_plus_3_date_close         13425 non-null  float64       \n",
      " 29  d_plus_4_date_close         13425 non-null  float64       \n",
      " 30  d_plus_5_date_close         13425 non-null  float64       \n",
      " 31  fx                          13425 non-null  float64       \n",
      " 32  bond10y                     13425 non-null  float64       \n",
      " 33  base_rate                   13425 non-null  float64       \n",
      " 34  summary                     13425 non-null  object        \n",
      " 35  stock_list                  13425 non-null  object        \n",
      " 36  industry_list               13425 non-null  object        \n",
      " 37  impact_score                13425 non-null  float64       \n",
      " 38  target                      13425 non-null  object        \n",
      " 39  date                        13425 non-null  datetime64[ns]\n",
      " 40  stock_code                  13425 non-null  object        \n",
      " 41  d_minus_1_daily_return      13425 non-null  float64       \n",
      " 42  d_minus_2_daily_return      13425 non-null  float64       \n",
      " 43  d_minus_3_daily_return      13425 non-null  float64       \n",
      " 44  d_minus_4_daily_return      13425 non-null  float64       \n",
      " 45  ma_3_d_minus_1              13425 non-null  float64       \n",
      " 46  ma_5_d_minus_1              13425 non-null  float64       \n",
      " 47  vol_5_d_minus_1             13425 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(36), int64(5), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a373b0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238           [0.01, 0.03, 0.03, 0.03, 0.05]\n",
       "239      [-0.05, -0.03, -0.09, -0.02, -0.05]\n",
       "240         [0.02, 0.03, 0.02, -0.01, -0.01]\n",
       "241        [-0.0, 0.03, -0.01, -0.04, -0.04]\n",
       "242           [0.01, 0.04, 0.03, 0.01, 0.02]\n",
       "                        ...                 \n",
       "13744         [0.02, 0.03, 0.05, 0.05, 0.05]\n",
       "13745    [-0.01, -0.03, -0.04, -0.05, -0.06]\n",
       "13746     [-0.4, -0.33, -0.33, -0.38, -0.49]\n",
       "13747         [0.02, 0.03, 0.05, 0.05, 0.05]\n",
       "13748         [0.03, 0.03, 0.04, 0.03, 0.06]\n",
       "Name: target, Length: 13425, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1Uv-AoINxSsdYMxwsFNvlD3kVf3MDoD3x",
     "timestamp": 1750053685734
    },
    {
     "file_id": "1DZR9Z2etxsfpzXCWCfFdFtoJ0_ko4x9E",
     "timestamp": 1749971008887
    },
    {
     "file_id": "1484BZ7aMomAsmNClOj3Gs2iVwH8B_wFk",
     "timestamp": 1749811125422
    }
   ]
  },
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "086bd873c70444ccae24607d81ab90e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21a8bcdd6597486db635aac5f2dd97ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fef822f442d4f3d8e03814c7e496ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b7d14897fa24011af6b6d099698bd1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa9b53374d85472da0a1644e8f79f86f",
       "IPY_MODEL_fd419b488eb445e782996e64ee5494be",
       "IPY_MODEL_83382077d7cf4b8dbeb58a5d68adaf93"
      ],
      "layout": "IPY_MODEL_836dc1e7bcfc4e0aa95c9faea66d3fa3"
     }
    },
    "54dedc7ea78b4fca9cd4d4f3e524d1f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57db0ce6d1f14f9c93b3809f36b82a90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e6b30239d9b461ca351af04202f247e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a32a4d2e0874adc8982b2000f9b5f22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2ef81b3e5e249f9a0478c1d381c73c0",
       "IPY_MODEL_b5197080d49c4506b2051ff4985ddd80",
       "IPY_MODEL_ae633c6a2c2748a995fe55cca1b52b93"
      ],
      "layout": "IPY_MODEL_54dedc7ea78b4fca9cd4d4f3e524d1f6"
     }
    },
    "7d9cb465e9d24422ad5074c4796ad935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83382077d7cf4b8dbeb58a5d68adaf93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fef822f442d4f3d8e03814c7e496ce8",
      "placeholder": "​",
      "style": "IPY_MODEL_21a8bcdd6597486db635aac5f2dd97ba",
      "value": " 336/336 [00:37&lt;00:00, 14.71it/s]"
     }
    },
    "836dc1e7bcfc4e0aa95c9faea66d3fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ae59b895584037b599857bf9d0c0bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95ec754902be45159350b218ae3a1728": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a3fe48525cb54d788e143e661376c95d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae633c6a2c2748a995fe55cca1b52b93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_086bd873c70444ccae24607d81ab90e6",
      "placeholder": "​",
      "style": "IPY_MODEL_f528505a611042359507d3948d467209",
      "value": " 84/84 [00:09&lt;00:00, 12.67it/s]"
     }
    },
    "b5197080d49c4506b2051ff4985ddd80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88ae59b895584037b599857bf9d0c0bc",
      "max": 84,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95ec754902be45159350b218ae3a1728",
      "value": 84
     }
    },
    "c0ac2b64b88e46ad8bc8037e9fccbcf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2ef81b3e5e249f9a0478c1d381c73c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57db0ce6d1f14f9c93b3809f36b82a90",
      "placeholder": "​",
      "style": "IPY_MODEL_7d9cb465e9d24422ad5074c4796ad935",
      "value": "Batches: 100%"
     }
    },
    "f528505a611042359507d3948d467209": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa9b53374d85472da0a1644e8f79f86f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e6b30239d9b461ca351af04202f247e",
      "placeholder": "​",
      "style": "IPY_MODEL_a3fe48525cb54d788e143e661376c95d",
      "value": "Batches: 100%"
     }
    },
    "fbdca1d6956a406bbc7549a193deb038": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd419b488eb445e782996e64ee5494be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0ac2b64b88e46ad8bc8037e9fccbcf1",
      "max": 336,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbdca1d6956a406bbc7549a193deb038",
      "value": 336
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
