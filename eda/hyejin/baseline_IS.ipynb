{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bddc33f7",
   "metadata": {},
   "source": [
    "# Impact Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00f75a2",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2e673d",
   "metadata": {
    "executionInfo": {
     "elapsed": 17477,
     "status": "ok",
     "timestamp": 1750055694374,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "ed2e673d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\tensor\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fbabc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33b56cda",
   "metadata": {
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1750055694696,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "33b56cda"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../db/news_2023_2025_metadata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m df1\u001b[38;5;241m.\u001b[39mmerge(df2, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m df\u001b[38;5;241m.\u001b[39mreplace([\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39minf, \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf], np\u001b[38;5;241m.\u001b[39mnan, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      8\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. 데이터 준비 및 타겟 생성\n",
    "df1 = pd.read_csv(\"../../db/news_2023_2025_external.csv\")\n",
    "df2 = pd.read_csv(\"../../db/news_2023_2025_metadata.csv\")\n",
    "\n",
    "df = df1.merge(df2, on=\"news_id\")\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0pxVDlnCPrcz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1750062678645,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "0pxVDlnCPrcz",
    "outputId": "e90eeaa7-c03d-44e0-df9a-3fd70f90e681"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13425 entries, 238 to 13748\n",
      "Data columns (total 38 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   news_id                     13425 non-null  object \n",
      " 1   d_minus_5_date_close        13425 non-null  float64\n",
      " 2   d_minus_5_date_volume       13425 non-null  float64\n",
      " 3   d_minus_5_date_foreign      13425 non-null  float64\n",
      " 4   d_minus_5_date_institution  13425 non-null  float64\n",
      " 5   d_minus_5_date_individual   13425 non-null  float64\n",
      " 6   d_minus_4_date_close        13425 non-null  float64\n",
      " 7   d_minus_4_date_volume       13425 non-null  float64\n",
      " 8   d_minus_4_date_foreign      13425 non-null  float64\n",
      " 9   d_minus_4_date_institution  13425 non-null  float64\n",
      " 10  d_minus_4_date_individual   13425 non-null  float64\n",
      " 11  d_minus_3_date_close        13425 non-null  float64\n",
      " 12  d_minus_3_date_volume       13425 non-null  float64\n",
      " 13  d_minus_3_date_foreign      13425 non-null  float64\n",
      " 14  d_minus_3_date_institution  13425 non-null  float64\n",
      " 15  d_minus_3_date_individual   13425 non-null  float64\n",
      " 16  d_minus_2_date_close        13425 non-null  float64\n",
      " 17  d_minus_2_date_volume       13425 non-null  float64\n",
      " 18  d_minus_2_date_foreign      13425 non-null  float64\n",
      " 19  d_minus_2_date_institution  13425 non-null  float64\n",
      " 20  d_minus_2_date_individual   13425 non-null  float64\n",
      " 21  d_minus_1_date_close        13425 non-null  int64  \n",
      " 22  d_minus_1_date_volume       13425 non-null  int64  \n",
      " 23  d_minus_1_date_foreign      13425 non-null  int64  \n",
      " 24  d_minus_1_date_institution  13425 non-null  int64  \n",
      " 25  d_minus_1_date_individual   13425 non-null  int64  \n",
      " 26  d_plus_1_date_close         13425 non-null  float64\n",
      " 27  d_plus_2_date_close         13425 non-null  float64\n",
      " 28  d_plus_3_date_close         13425 non-null  float64\n",
      " 29  d_plus_4_date_close         13425 non-null  float64\n",
      " 30  d_plus_5_date_close         13425 non-null  float64\n",
      " 31  fx                          13425 non-null  float64\n",
      " 32  bond10y                     13425 non-null  float64\n",
      " 33  base_rate                   13425 non-null  float64\n",
      " 34  summary                     13425 non-null  object \n",
      " 35  stock_list                  13425 non-null  object \n",
      " 36  industry_list               13425 non-null  object \n",
      " 37  impact_score                13425 non-null  float64\n",
      "dtypes: float64(29), int64(5), object(4)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7652507",
   "metadata": {
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1750055694854,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "f7652507"
   },
   "outputs": [],
   "source": [
    "# 2. 타겟 생성\n",
    "target_cols = ['d_plus_1_date_close', 'd_plus_2_date_close', 'd_plus_3_date_close', 'd_plus_4_date_close', 'd_plus_5_date_close']\n",
    "df['target'] = df[target_cols].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122def94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets = df[target_cols].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f50c7ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_targets = df[target_cols].values.tolist()  # → list of lists\n",
    "train_targets = np.array(train_targets)  # → (N, 5) numpy array\n",
    "\n",
    "baseline_mean = train_targets.mean(axis=0)  # shape: (5,)\n",
    "baseline_std = train_targets.std(axis=0)  # shape: (5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "100fb712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0078573 , -0.0083497 , -0.00810895, -0.00799404, -0.00891119])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1c5fe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06588189, 0.07283064, 0.07710478, 0.08238087, 0.08863377])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ab84e",
   "metadata": {},
   "source": [
    "특성공학컬럼 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NGNbQmw5Wukk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 332,
     "status": "ok",
     "timestamp": 1750055695183,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "NGNbQmw5Wukk",
    "outputId": "5096c797-9c37-4ae7-8b94-967c08e69366"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:21: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['Unknown_Stock_For_Imputation' 'Unknown_Stock_For_Imputation'\n",
      " 'Unknown_Stock_For_Imputation' ... 'Unknown_Stock_For_Imputation'\n",
      " 'Unknown_Stock_For_Imputation' 'Unknown_Stock_For_Imputation']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, 'stock_code'] = df['stock_code'].fillna('Unknown_Stock_For_Imputation')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\3736084660.py:81: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  lambda x: x.fillna(method='ffill').fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "def feature_engineer_stock_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # 관련 숫자형 컬럼들을 float으로 변환\n",
    "    numeric_cols_to_convert = [col for col in df.columns if 'd_minus' in col and ('close' in col or 'volume' in col or 'foreign' in col or 'institution' in col or 'individual' in col) and df[col].dtype == 'int64']\n",
    "    for col in numeric_cols_to_convert:\n",
    "        df.loc[:, col] = df[col].astype(float)\n",
    "\n",
    "    # 'news_id'에서 'date' 컬럼 생성\n",
    "    if 'news_id' in df.columns:\n",
    "        try:\n",
    "            df.loc[:, 'date'] = pd.to_datetime(df['news_id'].str[:8], format='%Y%m%d', errors='coerce')\n",
    "        except Exception:\n",
    "            df.loc[:, 'date'] = pd.NaT\n",
    "    else:\n",
    "        df.loc[:, 'date'] = pd.NaT\n",
    "\n",
    "    # 'stock_list'에서 'stock_code' 컬럼 생성\n",
    "    if 'stock_list' in df.columns:\n",
    "        df.loc[:, 'stock_code'] = df['stock_list'].apply(\n",
    "            lambda x: x[0] if isinstance(x, list) and len(x) > 0 else np.nan\n",
    "        )\n",
    "        df.loc[:, 'stock_code'] = df['stock_code'].fillna('Unknown_Stock_For_Imputation')\n",
    "    else:\n",
    "        df.loc[:, 'stock_code'] = 'Unknown_Stock_For_Imputation'\n",
    "\n",
    "    # 1.1. 일별 수익률 특성 추가\n",
    "    daily_return_cols = []\n",
    "    for i in range(1, 5):\n",
    "        current_day_close = f'd_minus_{i}_date_close'\n",
    "        prev_day_close = f'd_minus_{i+1}_date_close'\n",
    "        new_col_name = f'd_minus_{i}_daily_return'\n",
    "\n",
    "        if current_day_close in df.columns and prev_day_close in df.columns:\n",
    "            df.loc[:, new_col_name] = (df[current_day_close] - df[prev_day_close]) / df[prev_day_close].replace(0, np.nan)\n",
    "            daily_return_cols.append(new_col_name)\n",
    "\n",
    "    # 1.2. 이동 평균 특성 추가\n",
    "    moving_average_cols = []\n",
    "    if all(col in df.columns for col in ['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close']):\n",
    "        df.loc[:, 'ma_3_d_minus_1'] = df[['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close']].mean(axis=1)\n",
    "        moving_average_cols.append('ma_3_d_minus_1')\n",
    "\n",
    "    if all(col in df.columns for col in ['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close', 'd_minus_4_date_close', 'd_minus_5_date_close']):\n",
    "        df.loc[:, 'ma_5_d_minus_1'] = df[['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close', 'd_minus_4_date_close', 'd_minus_5_date_close']].mean(axis=1)\n",
    "        moving_average_cols.append('ma_5_d_minus_1')\n",
    "\n",
    "    # 1.3. 변동성 특성 추가\n",
    "    volatility_cols = []\n",
    "    if daily_return_cols and len(daily_return_cols) >= 2:\n",
    "        df.loc[:, 'vol_5_d_minus_1'] = df[daily_return_cols].std(axis=1)\n",
    "        volatility_cols.append('vol_5_d_minus_1')\n",
    "\n",
    "    # 특성 이상치 및 결측치(NaN) 처리 \n",
    "    features_to_process_and_impute = daily_return_cols + moving_average_cols + volatility_cols\n",
    "\n",
    "    if not features_to_process_and_impute:\n",
    "        return df\n",
    "\n",
    "    # 퀀타일 계산을 위한 임시 데이터프레임 생성\n",
    "    temp_df_for_quantile = df[features_to_process_and_impute].dropna()\n",
    "\n",
    "    for col in daily_return_cols:\n",
    "        if col in temp_df_for_quantile.columns and not temp_df_for_quantile[col].empty:\n",
    "            lower_bound = temp_df_for_quantile[col].quantile(0.01)\n",
    "            upper_bound = temp_df_for_quantile[col].quantile(0.99)\n",
    "            df.loc[:, col] = np.clip(df[col], lower_bound, upper_bound)\n",
    "\n",
    "    if 'vol_5_d_minus_1' in df.columns and 'vol_5_d_minus_1' in temp_df_for_quantile.columns and not temp_df_for_quantile['vol_5_d_minus_1'].empty:\n",
    "        upper_bound_vol = temp_df_for_quantile['vol_5_d_minus_1'].quantile(0.99)\n",
    "        df.loc[:, 'vol_5_d_minus_1'] = np.clip(df['vol_5_d_minus_1'], 0, upper_bound_vol)\n",
    "\n",
    "    # NaN 값 처리: 그룹별 interpolate()를 사용하여 결측치 채우기\n",
    "    if 'stock_code' in df.columns and 'date' in df.columns and not df['date'].isnull().all():\n",
    "        df_sorted = df.sort_values(by=['stock_code', 'date']).copy()\n",
    "\n",
    "        for col in features_to_process_and_impute:\n",
    "            if col in df_sorted.columns:\n",
    "                df_sorted.loc[:, col] = df_sorted.groupby('stock_code')[col].transform(\n",
    "                    lambda x: x.interpolate(method='linear', limit_direction='both', limit_area='inside')\n",
    "                )\n",
    "                df_sorted.loc[:, col] = df_sorted.groupby('stock_code')[col].transform(\n",
    "                    lambda x: x.fillna(method='ffill').fillna(method='bfill')\n",
    "                )\n",
    "                if df_sorted[col].isna().any():\n",
    "                    df_sorted.loc[:, col] = df_sorted[col].fillna(0)\n",
    "\n",
    "        df = df_sorted.loc[df.index].copy()\n",
    "    else:\n",
    "        for col in features_to_process_and_impute:\n",
    "            if col in df.columns and df[col].isna().any():\n",
    "                fill_value = df[col].mean()\n",
    "                if not pd.isna(fill_value):\n",
    "                    df.loc[:, col] = df[col].fillna(fill_value)\n",
    "                else:\n",
    "                    df.loc[:, col] = df[col].fillna(0)\n",
    "    return df\n",
    "\n",
    "df = feature_engineer_stock_data(df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b3e09",
   "metadata": {
    "id": "cc5b3e09"
   },
   "source": [
    "피쳐 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aba360d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13425 entries, 238 to 13748\n",
      "Data columns (total 48 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   news_id                     13425 non-null  object        \n",
      " 1   d_minus_5_date_close        13425 non-null  float64       \n",
      " 2   d_minus_5_date_volume       13425 non-null  float64       \n",
      " 3   d_minus_5_date_foreign      13425 non-null  float64       \n",
      " 4   d_minus_5_date_institution  13425 non-null  float64       \n",
      " 5   d_minus_5_date_individual   13425 non-null  float64       \n",
      " 6   d_minus_4_date_close        13425 non-null  float64       \n",
      " 7   d_minus_4_date_volume       13425 non-null  float64       \n",
      " 8   d_minus_4_date_foreign      13425 non-null  float64       \n",
      " 9   d_minus_4_date_institution  13425 non-null  float64       \n",
      " 10  d_minus_4_date_individual   13425 non-null  float64       \n",
      " 11  d_minus_3_date_close        13425 non-null  float64       \n",
      " 12  d_minus_3_date_volume       13425 non-null  float64       \n",
      " 13  d_minus_3_date_foreign      13425 non-null  float64       \n",
      " 14  d_minus_3_date_institution  13425 non-null  float64       \n",
      " 15  d_minus_3_date_individual   13425 non-null  float64       \n",
      " 16  d_minus_2_date_close        13425 non-null  float64       \n",
      " 17  d_minus_2_date_volume       13425 non-null  float64       \n",
      " 18  d_minus_2_date_foreign      13425 non-null  float64       \n",
      " 19  d_minus_2_date_institution  13425 non-null  float64       \n",
      " 20  d_minus_2_date_individual   13425 non-null  float64       \n",
      " 21  d_minus_1_date_close        13425 non-null  int64         \n",
      " 22  d_minus_1_date_volume       13425 non-null  int64         \n",
      " 23  d_minus_1_date_foreign      13425 non-null  int64         \n",
      " 24  d_minus_1_date_institution  13425 non-null  int64         \n",
      " 25  d_minus_1_date_individual   13425 non-null  int64         \n",
      " 26  d_plus_1_date_close         13425 non-null  float64       \n",
      " 27  d_plus_2_date_close         13425 non-null  float64       \n",
      " 28  d_plus_3_date_close         13425 non-null  float64       \n",
      " 29  d_plus_4_date_close         13425 non-null  float64       \n",
      " 30  d_plus_5_date_close         13425 non-null  float64       \n",
      " 31  fx                          13425 non-null  float64       \n",
      " 32  bond10y                     13425 non-null  float64       \n",
      " 33  base_rate                   13425 non-null  float64       \n",
      " 34  summary                     13425 non-null  object        \n",
      " 35  stock_list                  13425 non-null  object        \n",
      " 36  industry_list               13425 non-null  object        \n",
      " 37  impact_score                13425 non-null  float64       \n",
      " 38  target                      13425 non-null  object        \n",
      " 39  date                        13425 non-null  datetime64[ns]\n",
      " 40  stock_code                  13425 non-null  object        \n",
      " 41  d_minus_1_daily_return      13425 non-null  float64       \n",
      " 42  d_minus_2_daily_return      13425 non-null  float64       \n",
      " 43  d_minus_3_daily_return      13425 non-null  float64       \n",
      " 44  d_minus_4_daily_return      13425 non-null  float64       \n",
      " 45  ma_3_d_minus_1              13425 non-null  float64       \n",
      " 46  ma_5_d_minus_1              13425 non-null  float64       \n",
      " 47  vol_5_d_minus_1             13425 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(36), int64(5), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c1c1a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1750055695491,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "35c1c1a4",
    "outputId": "63157edd-4be5-4afd-d87e-fb78e650e081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 external_cols 수: 35\n",
      "최종 external_cols 예시: ['fx', 'bond10y', 'base_rate', 'd_minus_5_date_volume', 'd_minus_4_date_volume', 'd_minus_3_date_volume', 'd_minus_2_date_volume', 'd_minus_1_date_volume', 'd_minus_5_date_foreign', 'd_minus_4_date_foreign', 'd_minus_3_date_foreign', 'd_minus_2_date_foreign', 'd_minus_1_date_foreign', 'd_minus_5_date_institution', 'd_minus_4_date_institution', 'd_minus_3_date_institution', 'd_minus_2_date_institution', 'd_minus_1_date_institution', 'd_minus_5_date_individual', 'd_minus_4_date_individual', 'd_minus_3_date_individual', 'd_minus_2_date_individual', 'd_minus_1_date_individual', 'd_minus_5_date_close', 'd_minus_4_date_close', 'd_minus_3_date_close', 'd_minus_2_date_close', 'd_minus_1_date_close', 'd_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return', 'ma_3_d_minus_1', 'ma_5_d_minus_1', 'vol_5_d_minus_1'] ...\n",
      "\n",
      "--- 훈련/검증 데이터 스케일링 시작 ---\n"
     ]
    }
   ],
   "source": [
    "# standard\n",
    "group_price_close = [\n",
    "    'd_minus_5_date_close', 'd_minus_4_date_close',\n",
    "    'd_minus_3_date_close', 'd_minus_2_date_close',\n",
    "    'd_minus_1_date_close'\n",
    "]\n",
    "\n",
    "# RobustScaler\n",
    "group_volume = [\n",
    "    'd_minus_5_date_volume', 'd_minus_4_date_volume',\n",
    "    'd_minus_3_date_volume', 'd_minus_2_date_volume',\n",
    "    'd_minus_1_date_volume'\n",
    "]\n",
    "\n",
    "# MinMaxScaler\n",
    "group_foreign = [\n",
    "    'd_minus_5_date_foreign', 'd_minus_4_date_foreign',\n",
    "    'd_minus_3_date_foreign', 'd_minus_2_date_foreign',\n",
    "    'd_minus_1_date_foreign'\n",
    "]\n",
    "\n",
    "# MinMaxScaler\n",
    "group_institution = [\n",
    "    'd_minus_5_date_institution', 'd_minus_4_date_institution',\n",
    "    'd_minus_3_date_institution', 'd_minus_2_date_institution',\n",
    "    'd_minus_1_date_institution'\n",
    "]\n",
    "\n",
    "# MinMaxScaler\n",
    "group_individual = [\n",
    "    'd_minus_5_date_individual', 'd_minus_4_date_individual',\n",
    "    'd_minus_3_date_individual', 'd_minus_2_date_individual',\n",
    "    'd_minus_1_date_individual'\n",
    "]\n",
    "\n",
    "# StandardScaler\n",
    "group_macro = ['fx', 'bond10y', 'base_rate']\n",
    "\n",
    "# RobustScaler\n",
    "daily_return_cols = ['d_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return']\n",
    "\n",
    "# StandardScaler\n",
    "moving_average_cols = ['ma_3_d_minus_1', 'ma_5_d_minus_1']\n",
    "\n",
    "# RobustScaler\n",
    "volatility_cols = ['vol_5_d_minus_1']\n",
    "\n",
    "\n",
    "groups = [\n",
    "    group_macro,\n",
    "    group_volume,\n",
    "    group_foreign,\n",
    "    group_institution,\n",
    "    group_individual,\n",
    "    group_price_close,     # 기존 종가 데이터\n",
    "    daily_return_cols,     # 수익률 특성\n",
    "    moving_average_cols,   # 이동 평균 특성\n",
    "    volatility_cols        # 변동성 특성\n",
    "]\n",
    "\n",
    "scaler_choices = [\n",
    "    StandardScaler(), # group_macro\n",
    "    RobustScaler(),   # group_volume\n",
    "    MinMaxScaler(),   # group_foreign\n",
    "    MinMaxScaler(),   # group_institution\n",
    "    MinMaxScaler(),   # group_individual\n",
    "    StandardScaler(), # group_price_close \n",
    "    RobustScaler(),   # daily_return_cols\n",
    "    StandardScaler(), # moving_average_cols \n",
    "    RobustScaler()    # volatility_cols\n",
    "]\n",
    "\n",
    "external_cols = []\n",
    "for group in groups:\n",
    "    # 그룹 내 컬럼이 실제로 DataFrame에 존재하는지 다시 확인 \n",
    "    valid_group_cols = [col for col in group if col in df.columns]\n",
    "    external_cols.extend(valid_group_cols)\n",
    "\n",
    "\n",
    "# 3. 훈련/검증 분할 및 스케일링 \n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "fitted_scalers = {}\n",
    "\n",
    "print(\"\\n--- 훈련/검증 데이터 스케일링 시작 ---\")\n",
    "for i, group in enumerate(groups):\n",
    "    scaler = scaler_choices[i]\n",
    "    # 해당 그룹의 모든 컬럼이 train_df에 있는지 확인하고 유효한 컬럼만 사용\n",
    "    group_in_train = [col for col in group if col in train_df.columns]\n",
    "    group_in_val = [col for col in group if col in val_df.columns]\n",
    "\n",
    "    if not group_in_train:\n",
    "        continue # 이 그룹 스케일링 건너뛰기\n",
    "\n",
    "    scaler.fit(train_df[group_in_train])\n",
    "    fitted_scalers[i] = scaler\n",
    "\n",
    "    train_df.loc[:, group_in_train] = scaler.transform(train_df[group_in_train])\n",
    "    if group_in_val: # 검증 데이터에도 해당 컬럼이 있을 경우에만 변환\n",
    "        val_df.loc[:, group_in_val] = scaler.transform(val_df[group_in_val])\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "# 타겟 변수 스케일링 \n",
    "target_scaler = StandardScaler()\n",
    "train_targets_np = np.array(train_df['target'].tolist())\n",
    "val_targets_np = np.array(val_df['target'].tolist())\n",
    "\n",
    "target_scaler.fit(train_targets_np)\n",
    "\n",
    "train_df['target_scaled'] = target_scaler.transform(train_targets_np).tolist()\n",
    "val_df['target_scaled'] = target_scaler.transform(val_targets_np).tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fp94muN-2FfR",
   "metadata": {
    "id": "fp94muN-2FfR"
   },
   "source": [
    "문장 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "z7O6U1AI4wgR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283,
     "referenced_widgets": [
      "3b7d14897fa24011af6b6d099698bd1b",
      "fa9b53374d85472da0a1644e8f79f86f",
      "fd419b488eb445e782996e64ee5494be",
      "83382077d7cf4b8dbeb58a5d68adaf93",
      "836dc1e7bcfc4e0aa95c9faea66d3fa3",
      "5e6b30239d9b461ca351af04202f247e",
      "a3fe48525cb54d788e143e661376c95d",
      "c0ac2b64b88e46ad8bc8037e9fccbcf1",
      "fbdca1d6956a406bbc7549a193deb038",
      "2fef822f442d4f3d8e03814c7e496ce8",
      "21a8bcdd6597486db635aac5f2dd97ba",
      "7a32a4d2e0874adc8982b2000f9b5f22",
      "f2ef81b3e5e249f9a0478c1d381c73c0",
      "b5197080d49c4506b2051ff4985ddd80",
      "ae633c6a2c2748a995fe55cca1b52b93",
      "54dedc7ea78b4fca9cd4d4f3e524d1f6",
      "57db0ce6d1f14f9c93b3809f36b82a90",
      "7d9cb465e9d24422ad5074c4796ad935",
      "88ae59b895584037b599857bf9d0c0bc",
      "95ec754902be45159350b218ae3a1728",
      "086bd873c70444ccae24607d81ab90e6",
      "f528505a611042359507d3948d467209"
     ]
    },
    "executionInfo": {
     "elapsed": 52796,
     "status": "ok",
     "timestamp": 1750055748287,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "z7O6U1AI4wgR",
    "outputId": "d880bd40-bc48-44ef-bf6b-f0339b6eafbf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\tensor\\lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\user\\.cache\\huggingface\\hub\\models--snunlp--KR-SBERT-V40K-klueNLI-augSTS. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 훈련 데이터 임베딩 생성 (10740개 뉴스)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 336/336 [00:26<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 검증 데이터 임베딩 생성 (2685개 뉴스)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 84/84 [00:06<00:00, 13.43it/s]\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# 임베딩 모델 초기화\n",
    "model_emb = SentenceTransformer(\n",
    "    \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\",\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "print(f\"\\n▶ 훈련 데이터 임베딩 생성 ({len(train_df)}개 뉴스)\")\n",
    "train_summary_embedding = model_emb.encode(\n",
    "    train_df[\"summary\"].tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_tensor=True\n",
    ")\n",
    "train_df[\"embedding\"] = train_summary_embedding.cpu().numpy().tolist()\n",
    "\n",
    "print(f\"\\n▶ 검증 데이터 임베딩 생성 ({len(val_df)}개 뉴스)\")\n",
    "val_summary_embedding = model_emb.encode(\n",
    "    val_df[\"summary\"].tolist(),\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_tensor=True\n",
    ")\n",
    "val_df[\"embedding\"] = val_summary_embedding.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V6MLhLbX7PRh",
   "metadata": {
    "id": "V6MLhLbX7PRh"
   },
   "source": [
    "데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tGGVffrd7MUI",
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1750055748952,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "tGGVffrd7MUI"
   },
   "outputs": [],
   "source": [
    "# 5. Dataset 및 DataLoader\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, external_cols):\n",
    "        self.embeddings = torch.tensor(df[\"embedding\"].tolist(), dtype=torch.float32)\n",
    "        self.external_features = torch.tensor(df[external_cols].values, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(df[\"target_scaled\"].tolist(), dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.external_features[idx], self.targets[idx]\n",
    "\n",
    "train_dataset = CustomDataset(train_df, external_cols)\n",
    "val_dataset = CustomDataset(val_df, external_cols)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_ZsysAfu4z7v",
   "metadata": {
    "id": "_ZsysAfu4z7v"
   },
   "source": [
    "오토인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cachKDHJ42aY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10578,
     "status": "ok",
     "timestamp": 1750055759534,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "cachKDHJ42aY",
    "outputId": "98c6073e-8e52-48d5-f5c4-faa66a748c16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 오토인코더 사전학습 시작\n",
      "[AE] Epoch 1 | Train Loss: 0.1634 | Val Loss: 0.1152\n",
      "[AE] Epoch 2 | Train Loss: 0.0975 | Val Loss: 0.0833\n",
      "[AE] Epoch 3 | Train Loss: 0.0759 | Val Loss: 0.0692\n",
      "[AE] Epoch 4 | Train Loss: 0.0648 | Val Loss: 0.0607\n",
      "[AE] Epoch 5 | Train Loss: 0.0577 | Val Loss: 0.0550\n",
      "[AE] Epoch 6 | Train Loss: 0.0526 | Val Loss: 0.0506\n",
      "[AE] Epoch 7 | Train Loss: 0.0486 | Val Loss: 0.0472\n",
      "[AE] Epoch 8 | Train Loss: 0.0455 | Val Loss: 0.0444\n",
      "[AE] Epoch 9 | Train Loss: 0.0429 | Val Loss: 0.0420\n",
      "[AE] Epoch 10 | Train Loss: 0.0407 | Val Loss: 0.0401\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        # self.bert는 이 AE 모델의 입력으로 직접 사용되지 않음.\n",
    "        # 외부에서 생성된 임베딩을 받는 구조로 변경\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(latent_dim * 2, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(latent_dim * 2, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "# 임베딩 차원 (SentenceTransformer 출력 차원)\n",
    "embedding_dim = model_emb.get_sentence_embedding_dimension()\n",
    "latent_dim = 128 \n",
    "\n",
    "ae_model = Autoencoder(input_dim=embedding_dim, latent_dim=latent_dim).to(device)\n",
    "\n",
    "def freeze_module(module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def train_autoencoder(model, train_loader, val_loader=None, epochs=10, device='cuda'):\n",
    "    ae_optimizer = torch.optim.AdamW(\n",
    "        list(model.encoder.parameters()) + list(model.decoder.parameters()),\n",
    "        lr=1e-4,\n",
    "        weight_decay=1e-5\n",
    "    )\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    model.encoder.train()\n",
    "    model.decoder.train()\n",
    "\n",
    "    print(\"\\n▶ 오토인코더 사전학습 시작\")\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch_embedding, _, _ in train_loader: # DataLoader에서 임베딩만 사용\n",
    "            embeddings = batch_embedding.to(device)\n",
    "\n",
    "            latent = model.encoder(embeddings)\n",
    "            reconstructed = model.decoder(latent)\n",
    "\n",
    "            loss = criterion(reconstructed, embeddings)\n",
    "            ae_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            ae_optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        val_loss = 0\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_batch_embedding, _, _ in val_loader: # DataLoader에서 임베딩만 사용\n",
    "                    val_embeddings = val_batch_embedding.to(device)\n",
    "                    val_latent = model.encoder(val_embeddings)\n",
    "                    val_reconstructed = model.decoder(val_latent)\n",
    "                    val_loss += criterion(val_reconstructed, val_embeddings).item()\n",
    "            model.train() # 다시 학습 모드로 전환\n",
    "            print(f\"[AE] Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")\n",
    "        else:\n",
    "            print(f\"[AE] Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    model.encoder.eval()\n",
    "    model.decoder.eval()\n",
    "    return model\n",
    "\n",
    "# 오토인코더 학습 (여기서는 임베딩만 사용)\n",
    "ae_model = train_autoencoder(ae_model, train_loader, val_loader, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kNXmPUch5Xgv",
   "metadata": {
    "id": "kNXmPUch5Xgv"
   },
   "source": [
    "예측 모델 재구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "qfJCXDgv5S30",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750055759550,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "qfJCXDgv5S30"
   },
   "outputs": [],
   "source": [
    "class ImportancePredictor(nn.Module):\n",
    "    def __init__(self, ae_encoder, external_feature_dim, fcl_hidden=1024, dropout=0.25):  # hidden 크기 조금 키워도 좋아용\n",
    "        super().__init__()\n",
    "        self.encoder = ae_encoder\n",
    "        encoder_output_dim = ae_encoder[-1].out_features if isinstance(ae_encoder[-1], nn.Linear) else latent_dim\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(encoder_output_dim + external_feature_dim, fcl_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden, fcl_hidden // 2),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 2),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 2, fcl_hidden // 4),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 4),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 4, fcl_hidden // 8), \n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 8),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 8, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, embedding, external):\n",
    "        latent = self.encoder(embedding)\n",
    "        combined = torch.cat([latent, external], dim=1)\n",
    "        return self.predictor(combined)\n",
    "\n",
    "# ImportancePredictor 초기화\n",
    "predictor = ImportancePredictor(\n",
    "    ae_encoder=ae_model.encoder,\n",
    "    external_feature_dim=len(external_cols) \n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5NNbVAoF5bfg",
   "metadata": {
    "id": "5NNbVAoF5bfg"
   },
   "source": [
    "학습 및 검증 (프리징)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1302711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10688\\2944849852.py:34: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "▶ 메인 예측기 학습 시작\n",
      "[Epoch 1] Train Loss: 0.4712 | Val Loss: 0.3768 | MAE: 0.05 | RMSE: 0.09 | R²: -0.0887 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.4898\n",
      "[Epoch 2] Train Loss: 0.4608 | Val Loss: 0.3690 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0712 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.4924\n",
      "[Epoch 3] Train Loss: 0.4498 | Val Loss: 0.3637 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0570 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.4956\n",
      "[Epoch 4] Train Loss: 0.4416 | Val Loss: 0.3597 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0480 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5038\n",
      "[Epoch 5] Train Loss: 0.4349 | Val Loss: 0.3578 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0429 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5004\n",
      "[Epoch 6] Train Loss: 0.4297 | Val Loss: 0.3535 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0319 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5032\n",
      "[Epoch 7] Train Loss: 0.4253 | Val Loss: 0.3528 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0327 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5061\n",
      "[Epoch 8] Train Loss: 0.4238 | Val Loss: 0.3530 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0306 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5082\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 9] Train Loss: 0.4207 | Val Loss: 0.3505 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0242 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5070\n",
      "[Epoch 10] Train Loss: 0.4170 | Val Loss: 0.3498 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0235 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5081\n",
      "[Epoch 11] Train Loss: 0.4123 | Val Loss: 0.3498 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0238 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5137\n",
      "[Epoch 12] Train Loss: 0.4091 | Val Loss: 0.3476 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0179 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5131\n",
      "[Epoch 13] Train Loss: 0.4044 | Val Loss: 0.3467 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0159 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5128\n",
      "[Epoch 14] Train Loss: 0.4001 | Val Loss: 0.3440 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0101 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5166\n",
      "[Epoch 15] Train Loss: 0.3957 | Val Loss: 0.3452 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0112 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5148\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 16] Train Loss: 0.3920 | Val Loss: 0.3439 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0082 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5118\n",
      "[Epoch 17] Train Loss: 0.3888 | Val Loss: 0.3426 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0061 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5199\n",
      "[Epoch 18] Train Loss: 0.3891 | Val Loss: 0.3424 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0049 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5177\n",
      "[Epoch 19] Train Loss: 0.3846 | Val Loss: 0.3413 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0033 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5210\n",
      "[Epoch 20] Train Loss: 0.3878 | Val Loss: 0.3410 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0030 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5190\n",
      "[Epoch 21] Train Loss: 0.3838 | Val Loss: 0.3411 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0021 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5214\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 22] Train Loss: 0.3835 | Val Loss: 0.3421 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0047 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5239\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 23] Train Loss: 0.3799 | Val Loss: 0.3396 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0014 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5216\n",
      "[Epoch 24] Train Loss: 0.3788 | Val Loss: 0.3405 | MAE: 0.05 | RMSE: 0.08 | R²: -0.0004 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5236\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 25] Train Loss: 0.3775 | Val Loss: 0.3396 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0008 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5224\n",
      "[Epoch 26] Train Loss: 0.3790 | Val Loss: 0.3397 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0002 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5277\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 27] Train Loss: 0.3774 | Val Loss: 0.3390 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0016 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5233\n",
      "[Epoch 28] Train Loss: 0.3731 | Val Loss: 0.3390 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0017 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5286\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 29] Train Loss: 0.3719 | Val Loss: 0.3389 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0012 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5289\n",
      "[Epoch 30] Train Loss: 0.3702 | Val Loss: 0.3385 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0026 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5295\n",
      "[Epoch 31] Train Loss: 0.3689 | Val Loss: 0.3370 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0065 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5241\n",
      "[Epoch 32] Train Loss: 0.3686 | Val Loss: 0.3368 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0058 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5323\n",
      "[Epoch 33] Train Loss: 0.3667 | Val Loss: 0.3371 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0064 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5280\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 34] Train Loss: 0.3657 | Val Loss: 0.3374 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0054 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5292\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 35] Train Loss: 0.3658 | Val Loss: 0.3372 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0068 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5273\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 36] Train Loss: 0.3618 | Val Loss: 0.3355 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0091 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5286\n",
      "[Epoch 37] Train Loss: 0.3640 | Val Loss: 0.3362 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0092 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5300\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 38] Train Loss: 0.3624 | Val Loss: 0.3361 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0081 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5309\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 39] Train Loss: 0.3612 | Val Loss: 0.3362 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0089 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5265\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 40] Train Loss: 0.3607 | Val Loss: 0.3360 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0086 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5298\n",
      " -> 조기 종료 카운터: 4/15\n",
      "[Epoch 41] Train Loss: 0.3611 | Val Loss: 0.3354 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0121 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5268\n",
      "[Epoch 42] Train Loss: 0.3603 | Val Loss: 0.3351 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0119 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5283\n",
      "[Epoch 43] Train Loss: 0.3579 | Val Loss: 0.3350 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0110 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5323\n",
      "[Epoch 44] Train Loss: 0.3564 | Val Loss: 0.3345 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0128 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5283\n",
      "[Epoch 45] Train Loss: 0.3563 | Val Loss: 0.3344 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0137 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5351\n",
      "[Epoch 46] Train Loss: 0.3543 | Val Loss: 0.3340 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0128 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5366\n",
      "[Epoch 47] Train Loss: 0.3546 | Val Loss: 0.3334 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0163 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5345\n",
      "[Epoch 48] Train Loss: 0.3511 | Val Loss: 0.3336 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0163 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5321\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 49] Train Loss: 0.3512 | Val Loss: 0.3339 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0134 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5363\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 50] Train Loss: 0.3516 | Val Loss: 0.3331 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0144 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5351\n",
      "[Epoch 51] Train Loss: 0.3495 | Val Loss: 0.3335 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0151 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5352\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 52] Train Loss: 0.3502 | Val Loss: 0.3330 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0161 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5369\n",
      "[Epoch 53] Train Loss: 0.3495 | Val Loss: 0.3328 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0164 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5380\n",
      "[Epoch 54] Train Loss: 0.3480 | Val Loss: 0.3330 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0168 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5341\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 55] Train Loss: 0.3484 | Val Loss: 0.3331 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0165 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5377\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 56] Train Loss: 0.3477 | Val Loss: 0.3317 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0189 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5385\n",
      "[Epoch 57] Train Loss: 0.3479 | Val Loss: 0.3322 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0171 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5389\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 58] Train Loss: 0.3446 | Val Loss: 0.3321 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0185 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5368\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 59] Train Loss: 0.3458 | Val Loss: 0.3320 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0196 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5398\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 60] Train Loss: 0.3434 | Val Loss: 0.3316 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0188 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5409\n",
      "[Epoch 61] Train Loss: 0.3450 | Val Loss: 0.3314 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0200 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5421\n",
      "[Epoch 62] Train Loss: 0.3426 | Val Loss: 0.3313 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0203 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5389\n",
      "[Epoch 63] Train Loss: 0.3446 | Val Loss: 0.3316 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0195 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5385\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 64] Train Loss: 0.3411 | Val Loss: 0.3311 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0198 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5392\n",
      "[Epoch 65] Train Loss: 0.3416 | Val Loss: 0.3307 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0217 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5415\n",
      "[Epoch 66] Train Loss: 0.3406 | Val Loss: 0.3304 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0233 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5401\n",
      "[Epoch 67] Train Loss: 0.3401 | Val Loss: 0.3304 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0224 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5406\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 68] Train Loss: 0.3399 | Val Loss: 0.3300 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0228 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5418\n",
      "[Epoch 69] Train Loss: 0.3371 | Val Loss: 0.3301 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0240 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5442\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 70] Train Loss: 0.3385 | Val Loss: 0.3299 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0226 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5421\n",
      "[Epoch 71] Train Loss: 0.3377 | Val Loss: 0.3299 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0229 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5435\n",
      "[Epoch 72] Train Loss: 0.3362 | Val Loss: 0.3294 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0264 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5393\n",
      "[Epoch 73] Train Loss: 0.3362 | Val Loss: 0.3291 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0266 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5435\n",
      "[Epoch 74] Train Loss: 0.3353 | Val Loss: 0.3289 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0270 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5463\n",
      "[Epoch 75] Train Loss: 0.3355 | Val Loss: 0.3288 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0276 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5452\n",
      "[Epoch 76] Train Loss: 0.3331 | Val Loss: 0.3289 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0272 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5464\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 77] Train Loss: 0.3340 | Val Loss: 0.3288 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0276 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5441\n",
      "[Epoch 78] Train Loss: 0.3341 | Val Loss: 0.3286 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0274 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5455\n",
      "[Epoch 79] Train Loss: 0.3340 | Val Loss: 0.3290 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0266 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5455\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 80] Train Loss: 0.3323 | Val Loss: 0.3283 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0272 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5442\n",
      "[Epoch 81] Train Loss: 0.3332 | Val Loss: 0.3281 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0289 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5488\n",
      "[Epoch 82] Train Loss: 0.3322 | Val Loss: 0.3278 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0314 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5455\n",
      "[Epoch 83] Train Loss: 0.3299 | Val Loss: 0.3283 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0288 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5435\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 84] Train Loss: 0.3302 | Val Loss: 0.3276 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0305 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5472\n",
      "[Epoch 85] Train Loss: 0.3305 | Val Loss: 0.3276 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0302 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5460\n",
      "[Epoch 86] Train Loss: 0.3307 | Val Loss: 0.3275 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0305 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5441\n",
      "[Epoch 87] Train Loss: 0.3302 | Val Loss: 0.3274 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0297 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5460\n",
      "[Epoch 88] Train Loss: 0.3286 | Val Loss: 0.3274 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0307 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5499\n",
      "[Epoch 89] Train Loss: 0.3279 | Val Loss: 0.3270 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0325 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5462\n",
      "[Epoch 90] Train Loss: 0.3292 | Val Loss: 0.3272 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0326 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5458\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 91] Train Loss: 0.3282 | Val Loss: 0.3273 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0311 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5498\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 92] Train Loss: 0.3285 | Val Loss: 0.3267 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0336 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5473\n",
      "[Epoch 93] Train Loss: 0.3263 | Val Loss: 0.3268 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0329 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5456\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 94] Train Loss: 0.3243 | Val Loss: 0.3263 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0344 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5474\n",
      "[Epoch 95] Train Loss: 0.3274 | Val Loss: 0.3263 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0341 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5491\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 96] Train Loss: 0.3249 | Val Loss: 0.3259 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0336 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5550\n",
      "[Epoch 97] Train Loss: 0.3248 | Val Loss: 0.3262 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0350 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5480\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 98] Train Loss: 0.3244 | Val Loss: 0.3252 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0366 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5518\n",
      "[Epoch 99] Train Loss: 0.3256 | Val Loss: 0.3254 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0372 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5494\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 100] Train Loss: 0.3231 | Val Loss: 0.3251 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0375 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5502\n",
      "[Epoch 101] Train Loss: 0.3228 | Val Loss: 0.3254 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0371 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5467\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 102] Train Loss: 0.3225 | Val Loss: 0.3248 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0378 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5521\n",
      "[Epoch 103] Train Loss: 0.3215 | Val Loss: 0.3249 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0391 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5503\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 104] Train Loss: 0.3211 | Val Loss: 0.3255 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0373 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5465\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 105] Train Loss: 0.3213 | Val Loss: 0.3247 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0395 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5493\n",
      "[Epoch 106] Train Loss: 0.3203 | Val Loss: 0.3247 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0390 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5517\n",
      "[Epoch 107] Train Loss: 0.3210 | Val Loss: 0.3248 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0385 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5514\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 108] Train Loss: 0.3208 | Val Loss: 0.3244 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0418 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5538\n",
      "[Epoch 109] Train Loss: 0.3203 | Val Loss: 0.3243 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0396 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5531\n",
      "[Epoch 110] Train Loss: 0.3210 | Val Loss: 0.3243 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0418 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5496\n",
      "[Epoch 111] Train Loss: 0.3200 | Val Loss: 0.3242 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0406 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5519\n",
      "[Epoch 112] Train Loss: 0.3209 | Val Loss: 0.3237 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0417 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5572\n",
      "[Epoch 113] Train Loss: 0.3187 | Val Loss: 0.3240 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0404 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5523\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 114] Train Loss: 0.3172 | Val Loss: 0.3237 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0436 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5508\n",
      "[Epoch 115] Train Loss: 0.3168 | Val Loss: 0.3236 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0441 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5514\n",
      "[Epoch 116] Train Loss: 0.3174 | Val Loss: 0.3238 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0402 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5503\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 117] Train Loss: 0.3169 | Val Loss: 0.3232 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0432 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5576\n",
      "[Epoch 118] Train Loss: 0.3153 | Val Loss: 0.3229 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0445 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5540\n",
      "[Epoch 119] Train Loss: 0.3155 | Val Loss: 0.3231 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0437 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5540\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 120] Train Loss: 0.3166 | Val Loss: 0.3229 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0454 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5526\n",
      "[Epoch 121] Train Loss: 0.3145 | Val Loss: 0.3226 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0466 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5552\n",
      "[Epoch 122] Train Loss: 0.3140 | Val Loss: 0.3222 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0484 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5542\n",
      "[Epoch 123] Train Loss: 0.3132 | Val Loss: 0.3227 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0473 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5508\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 124] Train Loss: 0.3137 | Val Loss: 0.3226 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0467 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5569\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 125] Train Loss: 0.3139 | Val Loss: 0.3223 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0450 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5574\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 126] Train Loss: 0.3127 | Val Loss: 0.3223 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0462 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5570\n",
      " -> 조기 종료 카운터: 4/15\n",
      "[Epoch 127] Train Loss: 0.3131 | Val Loss: 0.3221 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0484 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5543\n",
      "[Epoch 128] Train Loss: 0.3125 | Val Loss: 0.3218 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0493 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5587\n",
      "[Epoch 129] Train Loss: 0.3129 | Val Loss: 0.3222 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0476 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5565\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 130] Train Loss: 0.3137 | Val Loss: 0.3218 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0467 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5579\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 131] Train Loss: 0.3118 | Val Loss: 0.3220 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0474 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5578\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 132] Train Loss: 0.3122 | Val Loss: 0.3213 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0501 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5572\n",
      "[Epoch 133] Train Loss: 0.3125 | Val Loss: 0.3216 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0489 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5560\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 134] Train Loss: 0.3104 | Val Loss: 0.3215 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0498 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5554\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 135] Train Loss: 0.3106 | Val Loss: 0.3218 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0489 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5562\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 136] Train Loss: 0.3090 | Val Loss: 0.3208 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0516 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5552\n",
      "[Epoch 137] Train Loss: 0.3097 | Val Loss: 0.3216 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0495 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5588\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 138] Train Loss: 0.3095 | Val Loss: 0.3211 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0514 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5581\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 139] Train Loss: 0.3107 | Val Loss: 0.3211 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0508 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5617\n",
      " -> 조기 종료 카운터: 3/15\n",
      "[Epoch 140] Train Loss: 0.3093 | Val Loss: 0.3211 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0535 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5542\n",
      " -> 조기 종료 카운터: 4/15\n",
      "[Epoch 141] Train Loss: 0.3082 | Val Loss: 0.3205 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0525 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5613\n",
      "[Epoch 142] Train Loss: 0.3089 | Val Loss: 0.3210 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0521 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5578\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 143] Train Loss: 0.3100 | Val Loss: 0.3210 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0514 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5587\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 144] Train Loss: 0.3077 | Val Loss: 0.3204 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0533 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5596\n",
      "[Epoch 145] Train Loss: 0.3081 | Val Loss: 0.3203 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0532 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5616\n",
      "[Epoch 146] Train Loss: 0.3073 | Val Loss: 0.3204 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0533 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5606\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 147] Train Loss: 0.3082 | Val Loss: 0.3205 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0533 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5584\n",
      " -> 조기 종료 카운터: 2/15\n",
      "[Epoch 148] Train Loss: 0.3055 | Val Loss: 0.3202 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0525 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5637\n",
      "[Epoch 149] Train Loss: 0.3068 | Val Loss: 0.3202 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0535 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5636\n",
      " -> 조기 종료 카운터: 1/15\n",
      "[Epoch 150] Train Loss: 0.3068 | Val Loss: 0.3200 | MAE: 0.05 | RMSE: 0.08 | R²: 0.0551 | LR: 5.00e-06\n",
      "Directional Accuracy: 0.5622\n",
      "최적 모델: Epoch 150 | MAE: 0.05 | R²: 0.0551\n"
     ]
    }
   ],
   "source": [
    "def train_predictor(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    target_scaler,\n",
    "    device='cuda',\n",
    "    epochs=150, # 최대 에포크 증가\n",
    "    patience=15, # 조기 종료 patience 증가\n",
    "    max_grad_norm=1.0\n",
    "):\n",
    "    # 1. 프리징 초기화 (한 번만 실행)\n",
    "    freeze_module(model.encoder)  # 인코더 영구 고정\n",
    "    model.encoder.eval()  # BN/Dropout 비활성화\n",
    "\n",
    "    # 2. 옵티마이저 설정\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.predictor.parameters(),  # 예측기만 등록\n",
    "        lr=5e-6,\n",
    "        weight_decay=1e-6\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        'min',\n",
    "        patience=5, # 스케줄러 patience 조정\n",
    "        factor=0.5\n",
    "    )\n",
    "    criterion = nn.HuberLoss() # HuberLoss 유지\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    print(\"\\n▶ 메인 예측기 학습 시작\")\n",
    "    for epoch in range(epochs):\n",
    "        # --------- 훈련 단계 ---------\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0\n",
    "        for batch_embedding, batch_external, batch_targets in train_loader:\n",
    "            embeddings = batch_embedding.to(device)\n",
    "            external_features = batch_external.to(device)\n",
    "            targets = batch_targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "                preds = model(embeddings, external_features)\n",
    "                loss = criterion(preds, targets)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                model.predictor.parameters(),  # 예측기만 클리핑\n",
    "                max_grad_norm\n",
    "            )\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "\n",
    "        # --------- 검증 단계 ---------\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        all_preds, all_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch_embedding, batch_external, batch_targets in val_loader:\n",
    "                embeddings = batch_embedding.to(device)\n",
    "                external_features = batch_external.to(device)\n",
    "                targets = batch_targets.to(device)\n",
    "\n",
    "                with torch.autocast(device_type=device, dtype=torch.float16):\n",
    "                    preds = model(embeddings, external_features)\n",
    "                    loss = criterion(preds, targets)\n",
    "                    total_val_loss += loss.item()\n",
    "                    all_preds.append(preds.cpu())\n",
    "                    all_targets.append(targets.cpu())\n",
    "\n",
    "        avg_val_loss = total_val_loss / len(val_loader)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "        all_preds_np = torch.cat(all_preds).numpy()\n",
    "        all_targets_np = torch.cat(all_targets).numpy()\n",
    "        preds_inv = target_scaler.inverse_transform(all_preds_np)\n",
    "        targets_inv = target_scaler.inverse_transform(all_targets_np)\n",
    "\n",
    "        mae = nn.L1Loss()(torch.tensor(preds_inv), torch.tensor(targets_inv)).item()\n",
    "        rmse = torch.sqrt(nn.MSELoss()(torch.tensor(preds_inv), torch.tensor(targets_inv))).item()\n",
    "        r2 = r2_score(targets_inv, preds_inv)\n",
    "\n",
    "        print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val Loss: {avg_val_loss:.4f} | MAE: {mae:.2f} | RMSE: {rmse:.2f} | R²: {r2:.4f} | \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "        direction_match = (np.sign(preds_inv) == np.sign(targets_inv))\n",
    "        directional_accuracy = np.mean(direction_match)\n",
    "        print(f\"Directional Accuracy: {directional_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "        scheduler.step(avg_val_loss)\n",
    "\n",
    "        # --------- 조기 종료 ---------\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_epoch = epoch + 1\n",
    "            best_mae = mae\n",
    "            best_r2 = r2\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\" -> 조기 종료 카운터: {patience_counter}/{patience}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(f\" -> epoch {epoch+1}에서 조기 종료!\")\n",
    "                break\n",
    "\n",
    "    print(f\"최적 모델: Epoch {best_epoch} | MAE: {best_mae:.2f} | R²: {best_r2:.4f}\")\n",
    "    return model\n",
    "\n",
    "# 최종 예측기 학습 실행\n",
    "trained_predictor = train_predictor(\n",
    "    predictor,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    target_scaler,\n",
    "    device=device,\n",
    "    epochs=150, # 최대 에포크 증가\n",
    "    patience=15 # 조기 종료 patience 증가\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29815a1b",
   "metadata": {},
   "source": [
    "모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ba18dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import torch.onnx\n",
    "\n",
    "# 입력 특성별 스케일러 저장\n",
    "for idx, scaler in fitted_scalers.items():\n",
    "    joblib.dump(scaler, f\"scaler_group_{idx}.joblib\")\n",
    "\n",
    "# 타겟 스케일러 저장\n",
    "joblib.dump(target_scaler, \"target_scaler.joblib\")\n",
    "\n",
    "\n",
    "# 임베딩 차원 정보\n",
    "dummy_embedding = torch.randn(1, embedding_dim, device=device)\n",
    "\n",
    "# encoder만 ONNX로 저장\n",
    "torch.onnx.export(\n",
    "    ae_model.encoder,\n",
    "    dummy_embedding,\n",
    "    \"ae_encoder.onnx\",\n",
    "    input_names=[\"embedding\"],\n",
    "    output_names=[\"latent\"],\n",
    "    dynamic_axes={\"embedding\": {0: \"batch_size\"}, \"latent\": {0: \"batch_size\"}},\n",
    "    opset_version=17\n",
    ")\n",
    "\n",
    "# 외부 피처 차원 정보\n",
    "external_feature_dim = len(external_cols)\n",
    "dummy_external = torch.randn(1, external_feature_dim, device=device)\n",
    "\n",
    "# predictor 전체 ONNX로 저장\n",
    "torch.onnx.export(\n",
    "    predictor,\n",
    "    (dummy_embedding, dummy_external),\n",
    "    \"predictor.onnx\",\n",
    "    input_names=[\"embedding\", \"external\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"embedding\": {0: \"batch_size\"},\n",
    "        \"external\": {0: \"batch_size\"},\n",
    "        \"output\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=17\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c174f297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13425 entries, 238 to 13748\n",
      "Data columns (total 48 columns):\n",
      " #   Column                      Non-Null Count  Dtype         \n",
      "---  ------                      --------------  -----         \n",
      " 0   news_id                     13425 non-null  object        \n",
      " 1   d_minus_5_date_close        13425 non-null  float64       \n",
      " 2   d_minus_5_date_volume       13425 non-null  float64       \n",
      " 3   d_minus_5_date_foreign      13425 non-null  float64       \n",
      " 4   d_minus_5_date_institution  13425 non-null  float64       \n",
      " 5   d_minus_5_date_individual   13425 non-null  float64       \n",
      " 6   d_minus_4_date_close        13425 non-null  float64       \n",
      " 7   d_minus_4_date_volume       13425 non-null  float64       \n",
      " 8   d_minus_4_date_foreign      13425 non-null  float64       \n",
      " 9   d_minus_4_date_institution  13425 non-null  float64       \n",
      " 10  d_minus_4_date_individual   13425 non-null  float64       \n",
      " 11  d_minus_3_date_close        13425 non-null  float64       \n",
      " 12  d_minus_3_date_volume       13425 non-null  float64       \n",
      " 13  d_minus_3_date_foreign      13425 non-null  float64       \n",
      " 14  d_minus_3_date_institution  13425 non-null  float64       \n",
      " 15  d_minus_3_date_individual   13425 non-null  float64       \n",
      " 16  d_minus_2_date_close        13425 non-null  float64       \n",
      " 17  d_minus_2_date_volume       13425 non-null  float64       \n",
      " 18  d_minus_2_date_foreign      13425 non-null  float64       \n",
      " 19  d_minus_2_date_institution  13425 non-null  float64       \n",
      " 20  d_minus_2_date_individual   13425 non-null  float64       \n",
      " 21  d_minus_1_date_close        13425 non-null  int64         \n",
      " 22  d_minus_1_date_volume       13425 non-null  int64         \n",
      " 23  d_minus_1_date_foreign      13425 non-null  int64         \n",
      " 24  d_minus_1_date_institution  13425 non-null  int64         \n",
      " 25  d_minus_1_date_individual   13425 non-null  int64         \n",
      " 26  d_plus_1_date_close         13425 non-null  float64       \n",
      " 27  d_plus_2_date_close         13425 non-null  float64       \n",
      " 28  d_plus_3_date_close         13425 non-null  float64       \n",
      " 29  d_plus_4_date_close         13425 non-null  float64       \n",
      " 30  d_plus_5_date_close         13425 non-null  float64       \n",
      " 31  fx                          13425 non-null  float64       \n",
      " 32  bond10y                     13425 non-null  float64       \n",
      " 33  base_rate                   13425 non-null  float64       \n",
      " 34  summary                     13425 non-null  object        \n",
      " 35  stock_list                  13425 non-null  object        \n",
      " 36  industry_list               13425 non-null  object        \n",
      " 37  impact_score                13425 non-null  float64       \n",
      " 38  target                      13425 non-null  object        \n",
      " 39  date                        13425 non-null  datetime64[ns]\n",
      " 40  stock_code                  13425 non-null  object        \n",
      " 41  d_minus_1_daily_return      13425 non-null  float64       \n",
      " 42  d_minus_2_daily_return      13425 non-null  float64       \n",
      " 43  d_minus_3_daily_return      13425 non-null  float64       \n",
      " 44  d_minus_4_daily_return      13425 non-null  float64       \n",
      " 45  ma_3_d_minus_1              13425 non-null  float64       \n",
      " 46  ma_5_d_minus_1              13425 non-null  float64       \n",
      " 47  vol_5_d_minus_1             13425 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(36), int64(5), object(6)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a373b0fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238           [0.01, 0.03, 0.03, 0.03, 0.05]\n",
       "239      [-0.05, -0.03, -0.09, -0.02, -0.05]\n",
       "240         [0.02, 0.03, 0.02, -0.01, -0.01]\n",
       "241        [-0.0, 0.03, -0.01, -0.04, -0.04]\n",
       "242           [0.01, 0.04, 0.03, 0.01, 0.02]\n",
       "                        ...                 \n",
       "13744         [0.02, 0.03, 0.05, 0.05, 0.05]\n",
       "13745    [-0.01, -0.03, -0.04, -0.05, -0.06]\n",
       "13746     [-0.4, -0.33, -0.33, -0.38, -0.49]\n",
       "13747         [0.02, 0.03, 0.05, 0.05, 0.05]\n",
       "13748         [0.03, 0.03, 0.04, 0.03, 0.06]\n",
       "Name: target, Length: 13425, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed151cd5",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "taLhJ8GqMdTa",
   "metadata": {
    "executionInfo": {
     "elapsed": 40,
     "status": "ok",
     "timestamp": 1750056693403,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "taLhJ8GqMdTa"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 모델 저장\n",
    "output_dir = './saved_models'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "torch.save(trained_predictor.state_dict(), './saved_models/model_weights.pth')\n",
    "\n",
    "# 1. 타겟 스케일러 (target_scaler) 저장\n",
    "with open(os.path.join(output_dir, 'target_scaler.pkl'), 'wb') as f:\n",
    "    pickle.dump(target_scaler, f)\n",
    "\n",
    "# 2. 외부 특성 스케일러들 (fitted_scalers) 저장\n",
    "with open(os.path.join(output_dir, 'external_fitted_scalers.pkl'), 'wb') as f:\n",
    "    pickle.dump(fitted_scalers, f)\n",
    "\n",
    "# # 토크나이저 저장\n",
    "# trained_predictor.tokenizer.save_pretrained('./saved_models')  # transformers 토크나이저라면\n",
    "# # 이러면 vocab.txt, tokenizer_config.json, special_tokens_map.json 등이 저장됨\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "FNcp_pOxfGXy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2941,
     "status": "ok",
     "timestamp": 1750058685015,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "FNcp_pOxfGXy",
    "outputId": "158bc207-1cd8-436b-80eb-5d894173e0b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 및 스케일러 로드 완료!\n",
      "ONNX 변환 완료: importance_predictor.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. 모델 클래스 재정의 (기존과 동일)\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, latent_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(latent_dim * 2, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, latent_dim * 2),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(latent_dim * 2, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        reconstructed = self.decoder(latent)\n",
    "        return reconstructed, latent\n",
    "\n",
    "class ImportancePredictor(nn.Module):\n",
    "    def __init__(self, ae_encoder, external_feature_dim, fcl_hidden=1024, dropout=0.25):\n",
    "        super().__init__()\n",
    "        self.encoder = ae_encoder\n",
    "        encoder_output_dim = ae_encoder[-1].out_features if isinstance(ae_encoder[-1], nn.Linear) else 128\n",
    "\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Linear(encoder_output_dim + external_feature_dim, fcl_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden, fcl_hidden // 2),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 2),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 2, fcl_hidden // 4),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 4),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 4, fcl_hidden // 8),\n",
    "            nn.GELU(),\n",
    "            nn.BatchNorm1d(fcl_hidden // 8),\n",
    "            nn.Dropout(dropout),\n",
    "\n",
    "            nn.Linear(fcl_hidden // 8, 5)\n",
    "        )\n",
    "\n",
    "    def forward(self, embedding, external):\n",
    "        latent = self.encoder(embedding)\n",
    "        combined = torch.cat([latent, external], dim=1)\n",
    "        return self.predictor(combined)\n",
    "\n",
    "# 2. 모델 설정값 정의 (학습 시와 동일하게)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_emb = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "embedding_dim = model_emb.get_sentence_embedding_dimension()  # 768\n",
    "latent_dim = 128\n",
    "\n",
    "# external_cols 정의 (학습 시와 동일하게)\n",
    "external_cols = [\n",
    "    # 매크로 경제\n",
    "    'fx', 'bond10y', 'base_rate',\n",
    "    # 거래량\n",
    "    'd_minus_5_date_volume', 'd_minus_4_date_volume', 'd_minus_3_date_volume',\n",
    "    'd_minus_2_date_volume', 'd_minus_1_date_volume',\n",
    "    # 외국인\n",
    "    'd_minus_5_date_foreign', 'd_minus_4_date_foreign', 'd_minus_3_date_foreign',\n",
    "    'd_minus_2_date_foreign', 'd_minus_1_date_foreign',\n",
    "    # 기관\n",
    "    'd_minus_5_date_institution', 'd_minus_4_date_institution', 'd_minus_3_date_institution',\n",
    "    'd_minus_2_date_institution', 'd_minus_1_date_institution',\n",
    "    # 개인\n",
    "    'd_minus_5_date_individual', 'd_minus_4_date_individual', 'd_minus_3_date_individual',\n",
    "    'd_minus_2_date_individual', 'd_minus_1_date_individual',\n",
    "    # 종가\n",
    "    'd_minus_5_date_close', 'd_minus_4_date_close', 'd_minus_3_date_close',\n",
    "    'd_minus_2_date_close', 'd_minus_1_date_close',\n",
    "    # 수익률 (실제 데이터에 따라 조정 필요)\n",
    "    'd_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return',\n",
    "    # 이동평균\n",
    "    'ma_3_d_minus_1', 'ma_5_d_minus_1',\n",
    "    # 변동성\n",
    "    'vol_5_d_minus_1'\n",
    "]\n",
    "\n",
    "# 3. 모델 구조 재생성\n",
    "ae_model = Autoencoder(input_dim=embedding_dim, latent_dim=latent_dim).to(device)\n",
    "loaded_predictor = ImportancePredictor(\n",
    "    ae_encoder=ae_model.encoder,\n",
    "    external_feature_dim=len(external_cols)\n",
    ").to(device)\n",
    "\n",
    "# 4. 저장된 가중치 로드\n",
    "model_path = './saved_models/model_weights.pth'\n",
    "loaded_predictor.load_state_dict(torch.load(model_path, map_location=device))\n",
    "loaded_predictor.eval()\n",
    "\n",
    "# 5. 스케일러들 로드\n",
    "with open('./saved_models/target_scaler.pkl', 'rb') as f:\n",
    "    target_scaler = pickle.load(f)\n",
    "\n",
    "with open('./saved_models/external_fitted_scalers.pkl', 'rb') as f:\n",
    "    fitted_scalers = pickle.load(f)\n",
    "\n",
    "print(\"모델 및 스케일러 로드 완료!\")\n",
    "\n",
    "# 6. ONNX 변환\n",
    "dummy_embedding = torch.randn(1, embedding_dim).to(device)\n",
    "dummy_external = torch.randn(1, len(external_cols)).to(device)\n",
    "\n",
    "# 모델을 evaluation 모드로 설정\n",
    "loaded_predictor.eval()\n",
    "\n",
    "torch.onnx.export(\n",
    "    loaded_predictor,\n",
    "    (dummy_embedding, dummy_external),\n",
    "    \"importance_predictor.onnx\",\n",
    "    input_names=[\"embedding\", \"external\"],\n",
    "    output_names=[\"prediction\"],\n",
    "    dynamic_axes={\n",
    "        \"embedding\": {0: \"batch_size\"},\n",
    "        \"external\": {0: \"batch_size\"},\n",
    "        \"prediction\": {0: \"batch_size\"}\n",
    "    },\n",
    "    opset_version=17,\n",
    "    do_constant_folding=True,\n",
    "    export_params=True\n",
    ")\n",
    "\n",
    "print(\"ONNX 변환 완료: importance_predictor.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V3TUMQUCoPz5",
   "metadata": {
    "id": "V3TUMQUCoPz5"
   },
   "source": [
    "사용예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "EXEZYV5Kob0s",
   "metadata": {
    "executionInfo": {
     "elapsed": 1144,
     "status": "ok",
     "timestamp": 1750063461908,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "EXEZYV5Kob0s"
   },
   "outputs": [],
   "source": [
    "# 1. 데이터 준비 및 타겟 생성\n",
    "df1 = pd.read_csv(\"news_2023_2025_external.csv\")\n",
    "df2 = pd.read_csv(\"news_2023_2025_metadata.csv\")\n",
    "\n",
    "df2 = df1.merge(df2, on=\"news_id\")\n",
    "df2.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "Or6D9hib3C0K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1750062610533,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "Or6D9hib3C0K",
    "outputId": "979c968f-ce49-4007-8cb8-29df628341b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13425 entries, 238 to 13748\n",
      "Data columns (total 38 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   news_id                     13425 non-null  object \n",
      " 1   d_minus_5_date_close        13425 non-null  float64\n",
      " 2   d_minus_5_date_volume       13425 non-null  float64\n",
      " 3   d_minus_5_date_foreign      13425 non-null  float64\n",
      " 4   d_minus_5_date_institution  13425 non-null  float64\n",
      " 5   d_minus_5_date_individual   13425 non-null  float64\n",
      " 6   d_minus_4_date_close        13425 non-null  float64\n",
      " 7   d_minus_4_date_volume       13425 non-null  float64\n",
      " 8   d_minus_4_date_foreign      13425 non-null  float64\n",
      " 9   d_minus_4_date_institution  13425 non-null  float64\n",
      " 10  d_minus_4_date_individual   13425 non-null  float64\n",
      " 11  d_minus_3_date_close        13425 non-null  float64\n",
      " 12  d_minus_3_date_volume       13425 non-null  float64\n",
      " 13  d_minus_3_date_foreign      13425 non-null  float64\n",
      " 14  d_minus_3_date_institution  13425 non-null  float64\n",
      " 15  d_minus_3_date_individual   13425 non-null  float64\n",
      " 16  d_minus_2_date_close        13425 non-null  float64\n",
      " 17  d_minus_2_date_volume       13425 non-null  float64\n",
      " 18  d_minus_2_date_foreign      13425 non-null  float64\n",
      " 19  d_minus_2_date_institution  13425 non-null  float64\n",
      " 20  d_minus_2_date_individual   13425 non-null  float64\n",
      " 21  d_minus_1_date_close        13425 non-null  int64  \n",
      " 22  d_minus_1_date_volume       13425 non-null  int64  \n",
      " 23  d_minus_1_date_foreign      13425 non-null  int64  \n",
      " 24  d_minus_1_date_institution  13425 non-null  int64  \n",
      " 25  d_minus_1_date_individual   13425 non-null  int64  \n",
      " 26  d_plus_1_date_close         13425 non-null  float64\n",
      " 27  d_plus_2_date_close         13425 non-null  float64\n",
      " 28  d_plus_3_date_close         13425 non-null  float64\n",
      " 29  d_plus_4_date_close         13425 non-null  float64\n",
      " 30  d_plus_5_date_close         13425 non-null  float64\n",
      " 31  fx                          13425 non-null  float64\n",
      " 32  bond10y                     13425 non-null  float64\n",
      " 33  base_rate                   13425 non-null  float64\n",
      " 34  summary                     13425 non-null  object \n",
      " 35  stock_list                  13425 non-null  object \n",
      " 36  industry_list               13425 non-null  object \n",
      " 37  impact_score                13425 non-null  float64\n",
      "dtypes: float64(29), int64(5), object(4)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "L_Ggka-o21fK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2007,
     "status": "ok",
     "timestamp": 1750062915257,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "L_Ggka-o21fK",
    "outputId": "96f7b0af-f832-4d1f-9eb2-3f6fdb962b77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 완전한 ONNX 디버깅 시작 ===\n",
      "샘플 데이터 크기: (10, 38)\n",
      "샘플 인덱스: [4838, 4839, 4840, 4841, 4842, 4843, 4844, 4845, 4846, 4847]\n",
      "\n",
      "=== 특성공학 적용 ===\n",
      "특성공학 시작...\n",
      "특성공학 전 컬럼 수: 38\n",
      "  생성: d_minus_1_daily_return\n",
      "  생성: d_minus_2_daily_return\n",
      "  생성: d_minus_3_daily_return\n",
      "  생성: d_minus_4_daily_return\n",
      "  생성: ma_3_d_minus_1\n",
      "  생성: ma_5_d_minus_1\n",
      "  생성: vol_5_d_minus_1\n",
      "특성공학 후 컬럼 수: 45\n",
      "새로 생성된 컬럼: ['d_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return', 'ma_3_d_minus_1', 'ma_5_d_minus_1', 'vol_5_d_minus_1']\n",
      "\n",
      "=== 스케일링 적용 ===\n",
      "스케일링 시작... 기대 컬럼 수: 35\n",
      "그룹 0: 3/3개 컬럼 스케일링 완료\n",
      "그룹 1: 5/5개 컬럼 스케일링 완료\n",
      "그룹 2: 5/5개 컬럼 스케일링 완료\n",
      "그룹 3: 5/5개 컬럼 스케일링 완료\n",
      "그룹 4: 5/5개 컬럼 스케일링 완료\n",
      "그룹 5: 5/5개 컬럼 스케일링 완료\n",
      "그룹 6: 4/4개 컬럼 스케일링 완료\n",
      "그룹 7: 2/2개 컬럼 스케일링 완료\n",
      "그룹 8: 1/1개 컬럼 스케일링 완료\n",
      "최종 external_cols 수: 35\n",
      "external_cols: ['fx', 'bond10y', 'base_rate', 'd_minus_5_date_volume', 'd_minus_4_date_volume', 'd_minus_3_date_volume', 'd_minus_2_date_volume', 'd_minus_1_date_volume', 'd_minus_5_date_foreign', 'd_minus_4_date_foreign', 'd_minus_3_date_foreign', 'd_minus_2_date_foreign', 'd_minus_1_date_foreign', 'd_minus_5_date_institution', 'd_minus_4_date_institution', 'd_minus_3_date_institution', 'd_minus_2_date_institution', 'd_minus_1_date_institution', 'd_minus_5_date_individual', 'd_minus_4_date_individual', 'd_minus_3_date_individual', 'd_minus_2_date_individual', 'd_minus_1_date_individual', 'd_minus_5_date_close', 'd_minus_4_date_close', 'd_minus_3_date_close', 'd_minus_2_date_close', 'd_minus_1_date_close', 'd_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return', 'ma_3_d_minus_1', 'ma_5_d_minus_1', 'vol_5_d_minus_1']\n",
      "\n",
      "=== 샘플 4838 디버깅 ===\n",
      "뉴스: 예실차에서는 여타 보험사와 유사하게 예상 이상의 발생보험금 증가가 나타났다고 짚으며 삼성생명의 올해 3분기 말 지급여력비율이 190%대로 하락한 것으로 추정하고 연말 계리가정 가이...\n",
      "임베딩 형태: (1, 768)\n",
      "외부 특성 형태: (1, 35)\n",
      "외부 특성 값 범위: -2.500000 ~ 1.320818\n",
      "\n",
      "=== ONNX 추론 실행 ===\n",
      "ONNX 원시 출력: [[ 0.02992271 -0.09087054 -0.02781912 -0.01335211  0.05585632]]\n",
      "각 값별 상세: ['0.02992271', '-0.09087054', '-0.02781912', '-0.01335211', '0.05585632']\n",
      "역변환 후 출력: [[-0.00611749 -0.01493353 -0.01008039 -0.00900689 -0.00403707]]\n",
      "역변환 후 상세: ['-0.00611749', '-0.01493353', '-0.01008039', '-0.00900689', '-0.00403707']\n",
      "실제 값: [np.float64(-0.07), np.float64(-0.08), np.float64(-0.07), np.float64(-0.09), np.float64(-0.09)]\n",
      "\n",
      "=== 예측 결과 vs 실제 값 ===\n",
      "D+1 - 예측: -0.006117, 실제: -0.070000\n",
      "D+2 - 예측: -0.014934, 실제: -0.080000\n",
      "D+3 - 예측: -0.010080, 실제: -0.070000\n",
      "D+4 - 예측: -0.009007, 실제: -0.090000\n",
      "D+5 - 예측: -0.004037, 실제: -0.090000\n",
      "\n",
      "=== 디버깅 완료 ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. ONNX 모델 로드\n",
    "sess = ort.InferenceSession(\n",
    "    \"importance_predictor.onnx\",\n",
    "    providers=['CPUExecutionProvider']  # CUDA 없으니 CPU만 사용\n",
    ")\n",
    "\n",
    "# 2. 스케일러들 로드\n",
    "with open('./saved_models/target_scaler.pkl', 'rb') as f:\n",
    "    target_scaler = pickle.load(f)\n",
    "\n",
    "with open('./saved_models/external_fitted_scalers.pkl', 'rb') as f:\n",
    "    fitted_scalers = pickle.load(f)\n",
    "\n",
    "# 3. 임베딩 모델 로드\n",
    "model_emb = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "\n",
    "# 4. 특성공학 함수 (학습 코드와 동일하게 구현)\n",
    "def create_engineered_features_complete(df):\n",
    "    \"\"\"학습 시와 정확히 동일한 특성공학\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    print(\"특성공학 시작...\")\n",
    "    print(f\"특성공학 전 컬럼 수: {len(df.columns)}\")\n",
    "\n",
    "    # 1. 일별 수익률 계산\n",
    "    daily_return_cols = []\n",
    "    for i in range(1, 5):\n",
    "        current_close_key = f'd_minus_{i}_date_close'\n",
    "        prev_close_key = f'd_minus_{i+1}_date_close'\n",
    "        return_key = f'd_minus_{i}_daily_return'\n",
    "\n",
    "        if current_close_key in df.columns and prev_close_key in df.columns:\n",
    "            df[return_key] = (df[current_close_key] - df[prev_close_key]) / df[prev_close_key].replace(0, np.nan)\n",
    "            df[return_key] = df[return_key].fillna(0)\n",
    "            daily_return_cols.append(return_key)\n",
    "            print(f\"  생성: {return_key}\")\n",
    "\n",
    "    # 2. 이동평균 계산\n",
    "    moving_average_cols = []\n",
    "    if all(col in df.columns for col in ['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close']):\n",
    "        df['ma_3_d_minus_1'] = df[['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close']].mean(axis=1)\n",
    "        moving_average_cols.append('ma_3_d_minus_1')\n",
    "        print(f\"  생성: ma_3_d_minus_1\")\n",
    "\n",
    "    if all(col in df.columns for col in ['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close', 'd_minus_4_date_close', 'd_minus_5_date_close']):\n",
    "        df['ma_5_d_minus_1'] = df[['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close', 'd_minus_4_date_close', 'd_minus_5_date_close']].mean(axis=1)\n",
    "        moving_average_cols.append('ma_5_d_minus_1')\n",
    "        print(f\"  생성: ma_5_d_minus_1\")\n",
    "\n",
    "    # 3. 변동성 계산\n",
    "    volatility_cols = []\n",
    "    if len(daily_return_cols) >= 2:\n",
    "        df['vol_5_d_minus_1'] = df[daily_return_cols].std(axis=1)\n",
    "        df['vol_5_d_minus_1'] = df['vol_5_d_minus_1'].fillna(0)\n",
    "        volatility_cols.append('vol_5_d_minus_1')\n",
    "        print(f\"  생성: vol_5_d_minus_1\")\n",
    "\n",
    "    print(f\"특성공학 후 컬럼 수: {len(df.columns)}\")\n",
    "    print(f\"새로 생성된 컬럼: {daily_return_cols + moving_average_cols + volatility_cols}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_complete_external_cols():\n",
    "    \"\"\"학습 시와 정확히 동일한 external_cols 순서\"\"\"\n",
    "    # 학습 코드와 정확히 동일한 그룹 순서\n",
    "    group_macro = ['fx', 'bond10y', 'base_rate']  # 3개\n",
    "    group_volume = ['d_minus_5_date_volume', 'd_minus_4_date_volume', 'd_minus_3_date_volume', 'd_minus_2_date_volume', 'd_minus_1_date_volume']  # 5개\n",
    "    group_foreign = ['d_minus_5_date_foreign', 'd_minus_4_date_foreign', 'd_minus_3_date_foreign', 'd_minus_2_date_foreign', 'd_minus_1_date_foreign']  # 5개\n",
    "    group_institution = ['d_minus_5_date_institution', 'd_minus_4_date_institution', 'd_minus_3_date_institution', 'd_minus_2_date_institution', 'd_minus_1_date_institution']  # 5개\n",
    "    group_individual = ['d_minus_5_date_individual', 'd_minus_4_date_individual', 'd_minus_3_date_individual', 'd_minus_2_date_individual', 'd_minus_1_date_individual']  # 5개\n",
    "    group_price_close = ['d_minus_5_date_close', 'd_minus_4_date_close', 'd_minus_3_date_close', 'd_minus_2_date_close', 'd_minus_1_date_close']  # 5개\n",
    "    daily_return_cols = ['d_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return']  # 4개\n",
    "    moving_average_cols = ['ma_3_d_minus_1', 'ma_5_d_minus_1']  # 2개\n",
    "    volatility_cols = ['vol_5_d_minus_1']  # 1개\n",
    "\n",
    "    # 학습 시와 동일한 순서\n",
    "    groups = [\n",
    "        group_macro,           # 0\n",
    "        group_volume,          # 1\n",
    "        group_foreign,         # 2\n",
    "        group_institution,     # 3\n",
    "        group_individual,      # 4\n",
    "        group_price_close,     # 5\n",
    "        daily_return_cols,     # 6\n",
    "        moving_average_cols,   # 7\n",
    "        volatility_cols        # 8\n",
    "    ]\n",
    "\n",
    "    external_cols = []\n",
    "    for group in groups:\n",
    "        external_cols.extend(group)\n",
    "\n",
    "    return external_cols, groups\n",
    "\n",
    "def apply_scaling_complete(df, fitted_scalers):\n",
    "    \"\"\"학습 시와 정확히 동일한 스케일링\"\"\"\n",
    "    df_scaled = df.copy()\n",
    "    external_cols, groups = get_complete_external_cols()\n",
    "\n",
    "    print(f\"스케일링 시작... 기대 컬럼 수: {len(external_cols)}\")\n",
    "\n",
    "    for group_idx, group_cols in enumerate(groups):\n",
    "        if group_idx in fitted_scalers:\n",
    "            scaler = fitted_scalers[group_idx]\n",
    "            valid_cols = [col for col in group_cols if col in df.columns]\n",
    "            missing_cols = [col for col in group_cols if col not in df.columns]\n",
    "\n",
    "            if missing_cols:\n",
    "                print(f\"그룹 {group_idx} 누락 컬럼: {missing_cols}\")\n",
    "\n",
    "            if valid_cols:\n",
    "                df_scaled[valid_cols] = scaler.transform(df[valid_cols])\n",
    "                print(f\"그룹 {group_idx}: {len(valid_cols)}/{len(group_cols)}개 컬럼 스케일링 완료\")\n",
    "            else:\n",
    "                print(f\"그룹 {group_idx}: 유효한 컬럼 없음\")\n",
    "\n",
    "    return df_scaled, external_cols\n",
    "\n",
    "def debug_onnx_complete():\n",
    "    print(\"=== 완전한 ONNX 디버깅 시작 ===\")\n",
    "\n",
    "    # 데이터 로드\n",
    "    sample_df = df2.iloc[4567:4577].copy()\n",
    "    print(f\"샘플 데이터 크기: {sample_df.shape}\")\n",
    "    print(f\"샘플 인덱스: {sample_df.index.tolist()}\")\n",
    "\n",
    "    # 1. 특성공학 적용 (누락된 파생 특성들 생성)\n",
    "    print(\"\\n=== 특성공학 적용 ===\")\n",
    "    sample_df_engineered = create_engineered_features_complete(sample_df)\n",
    "\n",
    "    # 2. 스케일링 적용\n",
    "    print(\"\\n=== 스케일링 적용 ===\")\n",
    "    sample_df_scaled, external_cols = apply_scaling_complete(sample_df_engineered, fitted_scalers)\n",
    "\n",
    "    print(f\"최종 external_cols 수: {len(external_cols)}\")\n",
    "    print(f\"external_cols: {external_cols}\")\n",
    "\n",
    "    # 3. 첫 번째 샘플로 디버깅\n",
    "    idx = sample_df_scaled.index[0]\n",
    "    row = sample_df_scaled.loc[idx]\n",
    "\n",
    "    print(f\"\\n=== 샘플 {idx} 디버깅 ===\")\n",
    "    print(f\"뉴스: {row['summary'][:100]}...\")\n",
    "\n",
    "    # 임베딩 생성\n",
    "    embedding = model_emb.encode([row['summary']])\n",
    "    embedding = embedding.astype(np.float32)\n",
    "    print(f\"임베딩 형태: {embedding.shape}\")\n",
    "\n",
    "    # 외부 특성 벡터 생성 (35개 컬럼 모두 포함)\n",
    "    external_vector = []\n",
    "    missing_cols = []\n",
    "    for col in external_cols:\n",
    "        if col in row.index:\n",
    "            external_vector.append(row[col])\n",
    "        else:\n",
    "            external_vector.append(0.0)  # 누락된 컬럼은 0으로 채움\n",
    "            missing_cols.append(col)\n",
    "\n",
    "    if missing_cols:\n",
    "        print(f\"누락된 컬럼들 (0으로 채움): {missing_cols}\")\n",
    "\n",
    "    external_array = np.array([external_vector], dtype=np.float32)\n",
    "    print(f\"외부 특성 형태: {external_array.shape}\")\n",
    "    print(f\"외부 특성 값 범위: {external_array.min():.6f} ~ {external_array.max():.6f}\")\n",
    "\n",
    "    # ONNX 추론 실행\n",
    "    inputs = {\"embedding\": embedding, \"external\": external_array}\n",
    "\n",
    "    print(f\"\\n=== ONNX 추론 실행 ===\")\n",
    "    try:\n",
    "        raw_predictions = sess.run(None, inputs)[0]\n",
    "\n",
    "        print(f\"ONNX 원시 출력: {raw_predictions}\")\n",
    "        print(f\"각 값별 상세: {[f'{x:.8f}' for x in raw_predictions[0]]}\")\n",
    "\n",
    "        # 타겟 스케일러 역변환\n",
    "        predictions_original = target_scaler.inverse_transform(raw_predictions)\n",
    "        print(f\"역변환 후 출력: {predictions_original}\")\n",
    "        print(f\"역변환 후 상세: {[f'{x:.8f}' for x in predictions_original[0]]}\")\n",
    "\n",
    "        # 실제 값과 비교\n",
    "        actual_values = [\n",
    "            sample_df.loc[idx, 'd_plus_1_date_close'],\n",
    "            sample_df.loc[idx, 'd_plus_2_date_close'],\n",
    "            sample_df.loc[idx, 'd_plus_3_date_close'],\n",
    "            sample_df.loc[idx, 'd_plus_4_date_close'],\n",
    "            sample_df.loc[idx, 'd_plus_5_date_close']\n",
    "        ]\n",
    "        print(f\"실제 값: {actual_values}\")\n",
    "\n",
    "        print(\"\\n=== 예측 결과 vs 실제 값 ===\")\n",
    "        for i in range(5):\n",
    "            print(f\"D+{i+1} - 예측: {predictions_original[0][i]:.6f}, 실제: {actual_values[i]:.6f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ONNX 추론 중 오류: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "    print(\"\\n=== 디버깅 완료 ===\")\n",
    "\n",
    "# 실행\n",
    "debug_onnx_complete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rMJntF355RyZ",
   "metadata": {
    "id": "rMJntF355RyZ"
   },
   "source": [
    "최종 이용코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eSgGdBLE3cdJ",
   "metadata": {
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1750063467702,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "eSgGdBLE3cdJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "class NewsImpactPredictor:\n",
    "    def __init__(self):\n",
    "        \"\"\"ONNX 모델과 스케일러들을 한 번에 로드\"\"\"\n",
    "        print(\"=== 모델 초기화 중 ===\")\n",
    "\n",
    "        # ONNX 모델 로드\n",
    "        self.sess = ort.InferenceSession(\n",
    "            \"importance_predictor.onnx\",\n",
    "            providers=['CPUExecutionProvider']\n",
    "        )\n",
    "\n",
    "        # 스케일러들 로드\n",
    "        with open('./saved_models/target_scaler.pkl', 'rb') as f:\n",
    "            self.target_scaler = pickle.load(f)\n",
    "\n",
    "        with open('./saved_models/external_fitted_scalers.pkl', 'rb') as f:\n",
    "            self.fitted_scalers = pickle.load(f)\n",
    "\n",
    "        # 임베딩 모델 로드\n",
    "        self.model_emb = SentenceTransformer(\"snunlp/KR-SBERT-V40K-klueNLI-augSTS\")\n",
    "\n",
    "        print(\"모델 초기화 완료!\")\n",
    "\n",
    "    def create_engineered_features(self, df):\n",
    "        \"\"\"특성공학 적용\"\"\"\n",
    "        df = df.copy()\n",
    "\n",
    "        # 1. 일별 수익률 계산\n",
    "        for i in range(1, 5):\n",
    "            current_close_key = f'd_minus_{i}_date_close'\n",
    "            prev_close_key = f'd_minus_{i+1}_date_close'\n",
    "            return_key = f'd_minus_{i}_daily_return'\n",
    "\n",
    "            if current_close_key in df.columns and prev_close_key in df.columns:\n",
    "                df[return_key] = (df[current_close_key] - df[prev_close_key]) / df[prev_close_key].replace(0, np.nan)\n",
    "                df[return_key] = df[return_key].fillna(0)\n",
    "\n",
    "        # 2. 이동평균 계산\n",
    "        if all(col in df.columns for col in ['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close']):\n",
    "            df['ma_3_d_minus_1'] = df[['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close']].mean(axis=1)\n",
    "\n",
    "        if all(col in df.columns for col in ['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close', 'd_minus_4_date_close', 'd_minus_5_date_close']):\n",
    "            df['ma_5_d_minus_1'] = df[['d_minus_1_date_close', 'd_minus_2_date_close', 'd_minus_3_date_close', 'd_minus_4_date_close', 'd_minus_5_date_close']].mean(axis=1)\n",
    "\n",
    "        # 3. 변동성 계산\n",
    "        return_cols = [f'd_minus_{i}_daily_return' for i in range(1, 5)]\n",
    "        existing_return_cols = [col for col in return_cols if col in df.columns]\n",
    "        if len(existing_return_cols) >= 2:\n",
    "            df['vol_5_d_minus_1'] = df[existing_return_cols].std(axis=1)\n",
    "            df['vol_5_d_minus_1'] = df['vol_5_d_minus_1'].fillna(0)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def apply_scaling(self, df):\n",
    "        \"\"\"스케일링 적용\"\"\"\n",
    "        df_scaled = df.copy()\n",
    "\n",
    "        # 학습 시와 동일한 그룹 정의\n",
    "        group_macro = ['fx', 'bond10y', 'base_rate']\n",
    "        group_volume = ['d_minus_5_date_volume', 'd_minus_4_date_volume', 'd_minus_3_date_volume', 'd_minus_2_date_volume', 'd_minus_1_date_volume']\n",
    "        group_foreign = ['d_minus_5_date_foreign', 'd_minus_4_date_foreign', 'd_minus_3_date_foreign', 'd_minus_2_date_foreign', 'd_minus_1_date_foreign']\n",
    "        group_institution = ['d_minus_5_date_institution', 'd_minus_4_date_institution', 'd_minus_3_date_institution', 'd_minus_2_date_institution', 'd_minus_1_date_institution']\n",
    "        group_individual = ['d_minus_5_date_individual', 'd_minus_4_date_individual', 'd_minus_3_date_individual', 'd_minus_2_date_individual', 'd_minus_1_date_individual']\n",
    "        group_price_close = ['d_minus_5_date_close', 'd_minus_4_date_close', 'd_minus_3_date_close', 'd_minus_2_date_close', 'd_minus_1_date_close']\n",
    "        daily_return_cols = ['d_minus_1_daily_return', 'd_minus_2_daily_return', 'd_minus_3_daily_return', 'd_minus_4_daily_return']\n",
    "        moving_average_cols = ['ma_3_d_minus_1', 'ma_5_d_minus_1']\n",
    "        volatility_cols = ['vol_5_d_minus_1']\n",
    "\n",
    "        groups = [\n",
    "            group_macro,           # 0 - StandardScaler\n",
    "            group_volume,          # 1 - RobustScaler\n",
    "            group_foreign,         # 2 - MinMaxScaler\n",
    "            group_institution,     # 3 - MinMaxScaler\n",
    "            group_individual,      # 4 - MinMaxScaler\n",
    "            group_price_close,     # 5 - StandardScaler\n",
    "            daily_return_cols,     # 6 - RobustScaler\n",
    "            moving_average_cols,   # 7 - StandardScaler\n",
    "            volatility_cols        # 8 - RobustScaler\n",
    "        ]\n",
    "\n",
    "        for group_idx, group_cols in enumerate(groups):\n",
    "            if group_idx in self.fitted_scalers:\n",
    "                scaler = self.fitted_scalers[group_idx]\n",
    "                valid_cols = [col for col in group_cols if col in df.columns]\n",
    "\n",
    "                if valid_cols:\n",
    "                    df_scaled[valid_cols] = scaler.transform(df[valid_cols])\n",
    "\n",
    "        return df_scaled, groups\n",
    "\n",
    "    def predict_impact_score(self, df_row):\n",
    "        \"\"\"단일 행에 대해 impact_score 예측\"\"\"\n",
    "        # DataFrame으로 변환 (단일 행 처리를 위해)\n",
    "        if isinstance(df_row, pd.Series):\n",
    "            df_single = df_row.to_frame().T\n",
    "        else:\n",
    "            df_single = df_row.copy()\n",
    "\n",
    "        # 1. 특성공학 적용\n",
    "        df_engineered = self.create_engineered_features(df_single)\n",
    "\n",
    "        # 2. 스케일링 적용\n",
    "        df_scaled, groups = self.apply_scaling(df_engineered)\n",
    "\n",
    "        # 3. external_cols 생성\n",
    "        external_cols = []\n",
    "        for group in groups:\n",
    "            for col in group:\n",
    "                if col in df_scaled.columns:\n",
    "                    external_cols.append(col)\n",
    "\n",
    "        # 4. 뉴스 임베딩 생성\n",
    "        news_text = df_scaled.iloc[0]['summary']\n",
    "        embedding = self.model_emb.encode([news_text])\n",
    "        embedding = embedding.astype(np.float32)\n",
    "\n",
    "        # 5. 외부 특성 벡터 생성\n",
    "        row = df_scaled.iloc[0]\n",
    "        external_vector = []\n",
    "        for col in external_cols:\n",
    "            if col in row.index:\n",
    "                external_vector.append(row[col])\n",
    "            else:\n",
    "                external_vector.append(0.0)\n",
    "\n",
    "        external_array = np.array([external_vector], dtype=np.float32)\n",
    "\n",
    "        # 6. ONNX 추론 실행\n",
    "        inputs = {\"embedding\": embedding, \"external\": external_array}\n",
    "        raw_predictions = self.sess.run(None, inputs)[0]\n",
    "\n",
    "        # 7. 역변환\n",
    "        predictions_original = self.target_scaler.inverse_transform(raw_predictions)\n",
    "\n",
    "        # 8. impact_score 계산 (5일 평균 변화율의 절댓값)\n",
    "        impact_score = np.mean(np.abs(predictions_original[0]))\n",
    "\n",
    "        return impact_score\n",
    "\n",
    "    def update_impact_score(self, df, index=None):\n",
    "        \"\"\"\n",
    "        DataFrame의 특정 행 또는 전체 행에 대해 impact_score 업데이트\n",
    "\n",
    "        Args:\n",
    "            df (DataFrame): 업데이트할 DataFrame\n",
    "            index (int/list/None): 업데이트할 행 인덱스. None이면 전체 업데이트\n",
    "\n",
    "        Returns:\n",
    "            DataFrame: impact_score가 업데이트된 DataFrame\n",
    "        \"\"\"\n",
    "        df_updated = df.copy()\n",
    "\n",
    "        # impact_score 컬럼이 없으면 생성\n",
    "        if 'impact_score' not in df_updated.columns:\n",
    "            df_updated['impact_score'] = 0.0\n",
    "\n",
    "        # 업데이트할 인덱스 결정\n",
    "        if index is None:\n",
    "            indices_to_update = df_updated.index\n",
    "        elif isinstance(index, (int, np.integer)):\n",
    "            indices_to_update = [index]\n",
    "        else:\n",
    "            indices_to_update = index\n",
    "\n",
    "        print(f\"=== {len(indices_to_update)}개 행의 impact_score 업데이트 중 ===\")\n",
    "\n",
    "        for i, idx in enumerate(indices_to_update):\n",
    "            try:\n",
    "                row = df_updated.loc[idx]\n",
    "                impact_score = self.predict_impact_score(row)\n",
    "                df_updated.loc[idx, 'impact_score'] = impact_score\n",
    "\n",
    "                print(f\"[{i+1}/{len(indices_to_update)}] 인덱스 {idx}: impact_score = {impact_score:.6f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"인덱스 {idx} 처리 중 오류: {e}\")\n",
    "                df_updated.loc[idx, 'impact_score'] = 0.0\n",
    "\n",
    "        print(\"=== impact_score 업데이트 완료 ===\")\n",
    "        return df_updated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C1TMcD1S5q_e",
   "metadata": {
    "id": "C1TMcD1S5q_e"
   },
   "outputs": [],
   "source": [
    "# # 사용법\n",
    "# def quick_update_impact_score(df, index=None):\n",
    "#     \"\"\"\n",
    "#     빠른 impact_score 업데이트 함수\n",
    "\n",
    "#     사용 예시:\n",
    "#     - 전체 업데이트: df = quick_update_impact_score(df)\n",
    "#     - 특정 행 업데이트: df = quick_update_impact_score(df, 100)\n",
    "#     - 여러 행 업데이트: df = quick_update_impact_score(df, [100, 101, 102])\n",
    "#     \"\"\"\n",
    "#     global _predictor\n",
    "\n",
    "#     # 전역 predictor가 없으면 생성\n",
    "#     if '_predictor' not in globals():\n",
    "#         _predictor = NewsImpactPredictor()\n",
    "\n",
    "#     return _predictor.update_impact_score(df, index)\n",
    "\n",
    "# # 사용 예시들\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 1. 전체 DataFrame 업데이트\n",
    "#     print(\"=== 사용 예시 1: 전체 DataFrame 업데이트 ===\")\n",
    "#     # df_updated = quick_update_impact_score(df2)\n",
    "\n",
    "#     # 2. 특정 행 하나만 업데이트\n",
    "#     print(\"=== 사용 예시 2: 특정 행 업데이트 ===\")\n",
    "#     # df_updated = quick_update_impact_score(df2, 4838)\n",
    "\n",
    "#     # 3. 여러 행 업데이트\n",
    "#     print(\"=== 사용 예시 3: 여러 행 업데이트 ===\")\n",
    "#     df_updated = quick_update_impact_score(df2.iloc[4567:4577], None)  # 10개 행만\n",
    "\n",
    "#     print(\"\\n업데이트된 결과:\")\n",
    "#     print(df_updated[['news_id', 'summary', 'impact_score']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6o7HA2RL6QLg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1721,
     "status": "ok",
     "timestamp": 1750063488505,
     "user": {
      "displayName": "정혜진",
      "userId": "03430931862188743018"
     },
     "user_tz": -540
    },
    "id": "6o7HA2RL6QLg",
    "outputId": "0bd7f8dd-5324-4c00-957f-f5b49ccab7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== df2 랜덤 행 impact_score 예측 데모 ===\n",
      "\n",
      "=== 모델 초기화 중 ===\n",
      "모델 초기화 완료!\n",
      "선택된 랜덤 인덱스: 10701\n",
      "뉴스 ID: 20240418_0100\n",
      "뉴스 요약: 한미반도체는 주주가치 제고를 위해 이달 26일까지 발행주식의 0.36%에 해당하는 34만5668주를 소각한다고 공시했으며 전날 종가 기준으로 470억원 규모의 자사주 소각 대상 주식은 한미반도체가 지난해 10월17일 300억원 규모 자사주 신탁계약 체결을 통해 취득한 ...\n",
      "주식 리스트: [\"한미반도체\"]\n",
      "현재 impact_score: 0.4750190391253094\n",
      "\n",
      "실제 미래 5일 변화율: ['-0.0000', '0.0700', '0.0400', '-0.0500', '-0.0000']\n",
      "\n",
      "=== 예측 수행 중 ===\n",
      "예측 중 오류 발생: cannot unpack non-iterable numpy.float32 object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-4233191722>:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[return_key] = df[return_key].fillna(0)\n",
      "<ipython-input-59-4233191722>:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[return_key] = df[return_key].fillna(0)\n",
      "<ipython-input-59-4233191722>:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[return_key] = df[return_key].fillna(0)\n",
      "<ipython-input-59-4233191722>:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df[return_key] = df[return_key].fillna(0)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-61-2302667321>\", line 39, in demo_random_prediction\n",
      "    impact_score, predictions = predictor.predict_impact_score(selected_row)\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: cannot unpack non-iterable numpy.float32 object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import random\n",
    "\n",
    "# 랜덤 행 선택 및 실행\n",
    "def demo_random_prediction():\n",
    "    print(\"=== df2 랜덤 행 impact_score 예측 데모 ===\\n\")\n",
    "\n",
    "    # 1. 예측기 초기화\n",
    "    predictor = NewsImpactPredictor()\n",
    "\n",
    "    # 2. df2에서 랜덤 행 선택\n",
    "    random_index = random.choice(df2.index)\n",
    "    print(f\"선택된 랜덤 인덱스: {random_index}\")\n",
    "\n",
    "    # 3. 선택된 행 정보 출력\n",
    "    selected_row = df2.loc[random_index]\n",
    "    print(f\"뉴스 ID: {selected_row['news_id']}\")\n",
    "    print(f\"뉴스 요약: {selected_row['summary'][:150]}...\")\n",
    "    print(f\"주식 리스트: {selected_row['stock_list']}\")\n",
    "    print(f\"현재 impact_score: {selected_row.get('impact_score', 'N/A')}\")\n",
    "\n",
    "    # 4. 실제 미래 종가 정보\n",
    "    actual_values = [\n",
    "        selected_row['d_plus_1_date_close'],\n",
    "        selected_row['d_plus_2_date_close'],\n",
    "        selected_row['d_plus_3_date_close'],\n",
    "        selected_row['d_plus_4_date_close'],\n",
    "        selected_row['d_plus_5_date_close']\n",
    "    ]\n",
    "    print(f\"\\n실제 미래 5일 변화율: {[f'{x:.4f}' for x in actual_values]}\")\n",
    "\n",
    "    # 5. impact_score 예측\n",
    "    print(f\"\\n=== 예측 수행 중 ===\")\n",
    "    try:\n",
    "        impact_score, predictions = predictor.predict_impact_score(selected_row)\n",
    "\n",
    "        print(f\"\\n=== 예측 결과 ===\")\n",
    "        print(f\"예측된 impact_score: {impact_score:.6f}\")\n",
    "        print(f\"예측된 5일 변화율: {[f'{x:.4f}' for x in predictions]}\")\n",
    "\n",
    "        print(f\"\\n=== 실제 vs 예측 비교 ===\")\n",
    "        for i in range(5):\n",
    "            diff = abs(predictions[i] - actual_values[i])\n",
    "            print(f\"D+{i+1}: 예측 {predictions[i]:.4f} vs 실제 {actual_values[i]:.4f} (차이: {diff:.4f})\")\n",
    "\n",
    "        # 6. 방향성 정확도 계산\n",
    "        pred_signs = np.sign(predictions)\n",
    "        actual_signs = np.sign(actual_values)\n",
    "        direction_match = np.sum(pred_signs == actual_signs)\n",
    "        print(f\"\\n방향성 정확도: {direction_match}/5 ({direction_match/5*100:.1f}%)\")\n",
    "\n",
    "        # 7. df2 업데이트 (옵션)\n",
    "        print(f\"\\n=== DataFrame 업데이트 ===\")\n",
    "        df2.loc[random_index, 'impact_score'] = impact_score\n",
    "        print(f\"인덱스 {random_index}의 impact_score가 {impact_score:.6f}로 업데이트되었습니다!\")\n",
    "\n",
    "        # 8. 업데이트된 정보 확인\n",
    "        updated_row = df2.loc[random_index]\n",
    "        print(f\"업데이트된 impact_score: {updated_row['impact_score']:.6f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"예측 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# 실행\n",
    "demo_random_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SrXQJr1S6VX9",
   "metadata": {
    "id": "SrXQJr1S6VX9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [
    {
     "file_id": "1Uv-AoINxSsdYMxwsFNvlD3kVf3MDoD3x",
     "timestamp": 1750053685734
    },
    {
     "file_id": "1DZR9Z2etxsfpzXCWCfFdFtoJ0_ko4x9E",
     "timestamp": 1749971008887
    },
    {
     "file_id": "1484BZ7aMomAsmNClOj3Gs2iVwH8B_wFk",
     "timestamp": 1749811125422
    }
   ]
  },
  "kernelspec": {
   "display_name": "test-0602",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "086bd873c70444ccae24607d81ab90e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "21a8bcdd6597486db635aac5f2dd97ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2fef822f442d4f3d8e03814c7e496ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b7d14897fa24011af6b6d099698bd1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fa9b53374d85472da0a1644e8f79f86f",
       "IPY_MODEL_fd419b488eb445e782996e64ee5494be",
       "IPY_MODEL_83382077d7cf4b8dbeb58a5d68adaf93"
      ],
      "layout": "IPY_MODEL_836dc1e7bcfc4e0aa95c9faea66d3fa3"
     }
    },
    "54dedc7ea78b4fca9cd4d4f3e524d1f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57db0ce6d1f14f9c93b3809f36b82a90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e6b30239d9b461ca351af04202f247e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a32a4d2e0874adc8982b2000f9b5f22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f2ef81b3e5e249f9a0478c1d381c73c0",
       "IPY_MODEL_b5197080d49c4506b2051ff4985ddd80",
       "IPY_MODEL_ae633c6a2c2748a995fe55cca1b52b93"
      ],
      "layout": "IPY_MODEL_54dedc7ea78b4fca9cd4d4f3e524d1f6"
     }
    },
    "7d9cb465e9d24422ad5074c4796ad935": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83382077d7cf4b8dbeb58a5d68adaf93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2fef822f442d4f3d8e03814c7e496ce8",
      "placeholder": "​",
      "style": "IPY_MODEL_21a8bcdd6597486db635aac5f2dd97ba",
      "value": " 336/336 [00:37&lt;00:00, 14.71it/s]"
     }
    },
    "836dc1e7bcfc4e0aa95c9faea66d3fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ae59b895584037b599857bf9d0c0bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95ec754902be45159350b218ae3a1728": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a3fe48525cb54d788e143e661376c95d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ae633c6a2c2748a995fe55cca1b52b93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_086bd873c70444ccae24607d81ab90e6",
      "placeholder": "​",
      "style": "IPY_MODEL_f528505a611042359507d3948d467209",
      "value": " 84/84 [00:09&lt;00:00, 12.67it/s]"
     }
    },
    "b5197080d49c4506b2051ff4985ddd80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88ae59b895584037b599857bf9d0c0bc",
      "max": 84,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95ec754902be45159350b218ae3a1728",
      "value": 84
     }
    },
    "c0ac2b64b88e46ad8bc8037e9fccbcf1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2ef81b3e5e249f9a0478c1d381c73c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57db0ce6d1f14f9c93b3809f36b82a90",
      "placeholder": "​",
      "style": "IPY_MODEL_7d9cb465e9d24422ad5074c4796ad935",
      "value": "Batches: 100%"
     }
    },
    "f528505a611042359507d3948d467209": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa9b53374d85472da0a1644e8f79f86f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e6b30239d9b461ca351af04202f247e",
      "placeholder": "​",
      "style": "IPY_MODEL_a3fe48525cb54d788e143e661376c95d",
      "value": "Batches: 100%"
     }
    },
    "fbdca1d6956a406bbc7549a193deb038": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fd419b488eb445e782996e64ee5494be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0ac2b64b88e46ad8bc8037e9fccbcf1",
      "max": 336,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbdca1d6956a406bbc7549a193deb038",
      "value": 336
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
