{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e2039b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18952\\1145999947.py:19: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  Base = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "# db.py\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# 환경변수에서 DATABASE_URL 가져오고, 없으면 로컬 기본값 사용\n",
    "DATABASE_URL = os.getenv(\n",
    "    \"DATABASE_URL\", \"postgresql://postgres:password@3.37.207.16:5432/postgres\"\n",
    ")\n",
    "\n",
    "# SQLAlchemy 엔진 생성\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# 세션 팩토리\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "\n",
    "# Base 클래스\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa12355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# fastapi 폴더가 있는 디렉토리 절대경로를 sys.path에 추가\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))  # notebooks의 상위\n",
    "sys.path.append(BASE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d727afee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 연결된 DB URL: postgresql://postgres:***@3.37.207.16:5432/postgres\n"
     ]
    }
   ],
   "source": [
    "from fastapi.models.news import NewsModel_v2, NewsModel_v2_Metadata\n",
    "\n",
    "# main.py 또는 Jupyter Notebook에서 실행\n",
    "\n",
    "# ✅ DB URL 확인\n",
    "print(\"🔗 연결된 DB URL:\", engine.url)\n",
    "\n",
    "# ✅ 세션 생성\n",
    "db = SessionLocal()\n",
    "\n",
    "# ✅ 뉴스 5건 조회\n",
    "results = (\n",
    "    db.query(NewsModel_v2.news_id, NewsModel_v2.wdate, NewsModel_v2_Metadata.stock_list)\n",
    "    .join(NewsModel_v2, NewsModel_v2.news_id == NewsModel_v2_Metadata.news_id)\n",
    "    .all()\n",
    ")\n",
    "\n",
    "# ✅ 결과 출력\n",
    "# for row in results:\n",
    "    # print(f\"{row.news_id} | {row.wdate} |{row.stock_list[0]}\")\n",
    "\n",
    "# ✅ 세션 종료\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efd58fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20250523_0002', datetime.datetime(2025, 5, 23, 18, 52), [{'stock_id': '377300', 'stock_name': '카카오페이'}]),\n",
       " ('20250523_0004', datetime.datetime(2025, 5, 23, 18, 33), [{'stock_id': '005930', 'stock_name': '삼성전자'}])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59c6510b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import os\n",
    "from pykrx import stock\n",
    "import requests\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55cefa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsMarketPipeline:\n",
    "\n",
    "    def __init__(self, news_list, df_base_rate):\n",
    "        self.api_key = os.getenv(\"KOREA_BANK_API_KEY\")\n",
    "\n",
    "        self.df = pd.DataFrame(news_list)\n",
    "        self.ticker_name_map = None\n",
    "        self.trading_days = None\n",
    "        self.ohlcv_dict = {}\n",
    "        self.trading_dict = {}\n",
    "        self.fx_df = None\n",
    "        self.bond_df = None\n",
    "        self.rate_df = df_base_rate\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.df\n",
    "\n",
    "    def extract_stock_name(self):\n",
    "        if \"stock_list\" not in self.df.columns:\n",
    "            raise Exception(\n",
    "                \"stock_list 컬럼이 없습니다. 실제 컬럼: \"\n",
    "                + str(self.df.columns.tolist())\n",
    "            )\n",
    "\n",
    "        def get_last_stock_name(x):\n",
    "            try:\n",
    "                items = ast.literal_eval(x) if isinstance(x, str) else x\n",
    "                return items[-1][\"stock_name\"] if items else None\n",
    "            except:\n",
    "                return None\n",
    "\n",
    "        self.df[\"stock_name\"] = self.df[\"stock_list\"].apply(get_last_stock_name)\n",
    "\n",
    "    def add_news_date(self):\n",
    "        if \"wdate\" in self.df.columns:\n",
    "            self.df[\"wdate\"] = pd.to_datetime(self.df[\"wdate\"])\n",
    "            self.df[\"news_date\"] = self.df[\"wdate\"].dt.normalize()\n",
    "        elif \"news_date\" in self.df.columns:\n",
    "            self.df[\"news_date\"] = pd.to_datetime(self.df[\"news_date\"])\n",
    "        else:\n",
    "            raise Exception(\n",
    "                \"wdate/news_date 컬럼이 없습니다. 실제 컬럼: \"\n",
    "                + str(self.df.columns.tolist())\n",
    "            )\n",
    "\n",
    "    def get_ticker_name_map(self, recent_date=\"2025-05-30\"):\n",
    "        kospi_tickers = stock.get_market_ticker_list(date=recent_date, market=\"KOSPI\")\n",
    "        return {\n",
    "            stock.get_market_ticker_name(ticker): ticker for ticker in kospi_tickers\n",
    "        }\n",
    "\n",
    "    def add_ticker(self):\n",
    "        if self.ticker_name_map is None:\n",
    "            self.ticker_name_map = self.get_ticker_name_map()\n",
    "\n",
    "        self.df[\"ticker\"] = self.df[\"stock_name\"].apply(\n",
    "            lambda name: self.ticker_name_map.get(name) if pd.notna(name) else None\n",
    "        )\n",
    "\n",
    "    def get_trading_days(self, start_year=2022, end_year=2026):\n",
    "        days = []\n",
    "        for y in range(start_year, end_year + 1):\n",
    "            for m in range(1, 13):\n",
    "                try:\n",
    "                    days_this_month = stock.get_previous_business_days(year=y, month=m)\n",
    "                    days.extend(days_this_month)\n",
    "                except:\n",
    "                    pass\n",
    "        return pd.to_datetime(sorted(set(days)))\n",
    "\n",
    "    def adjust_to_nearest_trading_day(self, date):\n",
    "        idx = self.trading_days.searchsorted(date, side=\"right\") - 1\n",
    "        if idx >= 0:\n",
    "            return self.trading_days[idx]\n",
    "        return pd.NaT\n",
    "\n",
    "    def add_trading_dates(self):\n",
    "        if self.trading_days is None:\n",
    "            self.trading_days = self.get_trading_days()\n",
    "\n",
    "        self.df[\"d_day_date\"] = self.df[\"news_date\"].apply(\n",
    "            self.adjust_to_nearest_trading_day\n",
    "        )\n",
    "\n",
    "        offsets = {\n",
    "            \"d_minus_5_date\": -5,\n",
    "            \"d_minus_4_date\": -4,\n",
    "            \"d_minus_3_date\": -3,\n",
    "            \"d_minus_2_date\": -2,\n",
    "            \"d_minus_1_date\": -1,\n",
    "            \"d_day_date\": 0,\n",
    "        }\n",
    "\n",
    "        def fill_offsets(row):\n",
    "            d_day = row[\"d_day_date\"]\n",
    "            if not pd.isna(d_day):\n",
    "                weekday = d_day.weekday()\n",
    "                if weekday == 5:\n",
    "                    d_day = self.adjust_to_nearest_trading_day(\n",
    "                        d_day - timedelta(days=1)\n",
    "                    )\n",
    "                elif weekday == 6:\n",
    "                    d_day = self.adjust_to_nearest_trading_day(\n",
    "                        d_day - timedelta(days=2)\n",
    "                    )\n",
    "\n",
    "            res = {}\n",
    "            if pd.isna(d_day):\n",
    "                for k in offsets:\n",
    "                    res[k] = pd.NaT\n",
    "                return pd.Series(res)\n",
    "\n",
    "            idx = self.trading_days.searchsorted(d_day)\n",
    "            for k, v in offsets.items():\n",
    "                i = idx + v\n",
    "                res[k] = (\n",
    "                    self.trading_days[i] if 0 <= i < len(self.trading_days) else pd.NaT\n",
    "                )\n",
    "            return pd.Series(res)\n",
    "\n",
    "        df_offsets = self.df.apply(fill_offsets, axis=1)\n",
    "        self.df = pd.concat(\n",
    "            [self.df.reset_index(drop=True), df_offsets.reset_index(drop=True)], axis=1\n",
    "        )\n",
    "\n",
    "    def fetch_ohlcv_and_trading(self):\n",
    "        offsets = [f\"d_minus_{i}_date\" for i in range(1, 6)]\n",
    "        all_dates = (\n",
    "            pd.concat([self.df[col] for col in offsets], ignore_index=True)\n",
    "            .dropna()\n",
    "            .unique()\n",
    "        )\n",
    "        all_dates_str = sorted(\n",
    "            [pd.to_datetime(d).strftime(\"%Y%m%d\") for d in all_dates]\n",
    "        )\n",
    "        tickers = self.df[\"ticker\"].dropna().unique().tolist()\n",
    "\n",
    "        for ticker in tickers:\n",
    "            try:\n",
    "                self.ohlcv_dict[ticker] = stock.get_market_ohlcv_by_date(\n",
    "                    min(all_dates_str), max(all_dates_str), ticker\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                self.trading_dict[ticker] = stock.get_market_trading_value_by_date(\n",
    "                    min(all_dates_str), max(all_dates_str), ticker\n",
    "                )\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def add_ohlcv_and_trading(self):\n",
    "        offsets = [f\"d_minus_{i}_date\" for i in range(1, 6)]\n",
    "\n",
    "        all_ohlcv_rows = []\n",
    "        for ticker, df in self.ohlcv_dict.items():\n",
    "            df = df.reset_index().rename(columns={\"날짜\": \"date\"})\n",
    "            df[\"ticker\"] = ticker\n",
    "            all_ohlcv_rows.append(df[[\"date\", \"ticker\", \"종가\", \"거래량\"]])\n",
    "        df_ohlcv_all = pd.concat(all_ohlcv_rows) if all_ohlcv_rows else pd.DataFrame()\n",
    "\n",
    "        all_trading_rows = []\n",
    "        for ticker, df in self.trading_dict.items():\n",
    "            df = df.reset_index().rename(columns={\"날짜\": \"date\"})\n",
    "            df[\"ticker\"] = ticker\n",
    "            df = df[[\"date\", \"ticker\", \"외국인합계\", \"기관합계\", \"개인\"]]\n",
    "            all_trading_rows.append(df)\n",
    "        df_trading_all = (\n",
    "            pd.concat(all_trading_rows) if all_trading_rows else pd.DataFrame()\n",
    "        )\n",
    "\n",
    "        for col in offsets:\n",
    "            self.df = (\n",
    "                self.df.merge(\n",
    "                    df_ohlcv_all,\n",
    "                    how=\"left\",\n",
    "                    left_on=[col, \"ticker\"],\n",
    "                    right_on=[\"date\", \"ticker\"],\n",
    "                )\n",
    "                .rename(columns={\"종가\": f\"{col}_close\", \"거래량\": f\"{col}_volume\"})\n",
    "                .drop(columns=\"date\")\n",
    "            )\n",
    "            self.df = (\n",
    "                self.df.merge(\n",
    "                    df_trading_all,\n",
    "                    how=\"left\",\n",
    "                    left_on=[col, \"ticker\"],\n",
    "                    right_on=[\"date\", \"ticker\"],\n",
    "                )\n",
    "                .rename(\n",
    "                    columns={\n",
    "                        \"외국인합계\": f\"{col}_foreign\",\n",
    "                        \"기관합계\": f\"{col}_institution\",\n",
    "                        \"개인\": f\"{col}_individual\",\n",
    "                    }\n",
    "                )\n",
    "                .drop(columns=\"date\")\n",
    "            )\n",
    "\n",
    "    def fetch_fx(self, start_date, end_date):\n",
    "        if self.fx_df is not None:\n",
    "            return self.fx_df\n",
    "        url = f\"https://ecos.bok.or.kr/api/StatisticSearch/{self.api_key}/json/kr/1/1000/731Y001/D/{start_date}/{end_date}/0000001/\"\n",
    "        resp = requests.get(url).json()\n",
    "        if \"StatisticSearch\" not in resp or \"row\" not in resp[\"StatisticSearch\"]:\n",
    "            return pd.DataFrame()\n",
    "        df = pd.DataFrame(resp[\"StatisticSearch\"][\"row\"])\n",
    "        df[\"date\"] = pd.to_datetime(df[\"TIME\"], format=\"%Y%m%d\")\n",
    "        df[\"usdkrw\"] = pd.to_numeric(df[\"DATA_VALUE\"], errors=\"coerce\")\n",
    "        self.fx_df = df[[\"date\", \"usdkrw\"]].sort_values(\"date\")\n",
    "        return self.fx_df\n",
    "\n",
    "    def fetch_bond10y(self, start_date, end_date):\n",
    "        if self.bond_df is not None:\n",
    "            return self.bond_df\n",
    "        url = f\"https://ecos.bok.or.kr/api/StatisticSearch/{self.api_key}/json/kr/1/1000/817Y002/D/{start_date}/{end_date}/010200000/\"\n",
    "        resp = requests.get(url).json()\n",
    "        if \"StatisticSearch\" not in resp or \"row\" not in resp[\"StatisticSearch\"]:\n",
    "            return pd.DataFrame()\n",
    "        df = pd.DataFrame(resp[\"StatisticSearch\"][\"row\"])\n",
    "        df[\"date\"] = pd.to_datetime(df[\"TIME\"], format=\"%Y%m%d\")\n",
    "        df[\"bond10y\"] = pd.to_numeric(df[\"DATA_VALUE\"], errors=\"coerce\")\n",
    "        self.bond_df = df[[\"date\", \"bond10y\"]].sort_values(\"date\")\n",
    "        return self.bond_df\n",
    "\n",
    "    def add_external_vars(self):\n",
    "        self.df = self.df.sort_values(\"news_date\")\n",
    "        if self.trading_days is None:\n",
    "            self.trading_days = self.get_trading_days()\n",
    "        raw_start = self.df[\"news_date\"].min() - timedelta(days=1)\n",
    "        raw_end = self.df[\"news_date\"].max() - timedelta(days=1)\n",
    "        start_date = self.adjust_to_nearest_trading_day(raw_start)\n",
    "        end_date = self.adjust_to_nearest_trading_day(raw_end)\n",
    "        if pd.isna(start_date) or pd.isna(end_date):\n",
    "            return\n",
    "\n",
    "        start_str, end_str = start_date.strftime(\"%Y%m%d\"), end_date.strftime(\"%Y%m%d\")\n",
    "        fx_df = self.fetch_fx(start_str, end_str)\n",
    "        bond_df = self.fetch_bond10y(start_str, end_str)\n",
    "\n",
    "        if not fx_df.empty:\n",
    "            self.df = pd.merge_asof(\n",
    "                self.df,\n",
    "                fx_df.rename(columns={\"date\": \"news_date\", \"usdkrw\": \"fx\"}),\n",
    "                on=\"news_date\",\n",
    "                direction=\"backward\",\n",
    "            )\n",
    "        if not bond_df.empty:\n",
    "            self.df = pd.merge_asof(\n",
    "                self.df,\n",
    "                bond_df.rename(columns={\"date\": \"news_date\"}),\n",
    "                on=\"news_date\",\n",
    "                direction=\"backward\",\n",
    "            )\n",
    "        if self.rate_df is not None and not self.rate_df.empty:\n",
    "            self.df = pd.merge_asof(\n",
    "                self.df,\n",
    "                self.rate_df.rename(columns={\"date\": \"news_date\", \"rate\": \"base_rate\"}),\n",
    "                on=\"news_date\",\n",
    "                direction=\"backward\",\n",
    "            )\n",
    "\n",
    "    def run(self):\n",
    "        steps = [\n",
    "            (\"extract_stock_name\", self.extract_stock_name),\n",
    "            (\"add_news_date\", self.add_news_date),\n",
    "            (\"add_ticker\", self.add_ticker),\n",
    "            (\"add_trading_dates\", self.add_trading_dates),\n",
    "            (\"fetch_ohlcv_and_trading\", self.fetch_ohlcv_and_trading),\n",
    "            (\"add_ohlcv_and_trading\", self.add_ohlcv_and_trading),\n",
    "            (\"add_external_vars\", self.add_external_vars),\n",
    "        ]\n",
    "\n",
    "        for step_name, func in steps:\n",
    "            try:\n",
    "                func()\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Step '{step_name}' failed: {e}\")\n",
    "\n",
    "        try:\n",
    "            self.df = self.df.drop(\n",
    "                columns=[\"wdate\", \"stock_list\", \"stock_name\", \"news_date\", \"ticker\"]\n",
    "                + [f\"d_minus_{i}_date\" for i in range(1, 6)]\n",
    "                + [\"d_day_date\"],\n",
    "                errors=\"ignore\",\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Drop columns failed: {e}\")\n",
    "\n",
    "        return self.df.to_dict(orient=\"records\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2a7d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list = results.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd79e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13886"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbb3f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_rate = pd.read_csv(\"../../automation/db/korea_base_rate_daily.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbd1f468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6361 entries, 0 to 6360\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   date    6361 non-null   object \n",
      " 1   rate    6361 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 99.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df_base_rate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bffe1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_rate[\"date\"] = pd.to_datetime(df_base_rate[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a51a5c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('20250523_0002', datetime.datetime(2025, 5, 23, 18, 52), [{'stock_id': '377300', 'stock_name': '카카오페이'}]),\n",
       " ('20250523_0004', datetime.datetime(2025, 5, 23, 18, 33), [{'stock_id': '005930', 'stock_name': '삼성전자'}])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e64daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list_converted = [\n",
    "    {\n",
    "        \"news_id\": news_id,\n",
    "        \"wdate\": wdate.strftime(\"%Y-%m-%d %H:%M:%S\"),  # ✅ datetime → str\n",
    "        \"stock_list\": stock_list,\n",
    "    }\n",
    "    for news_id, wdate, stock_list in news_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d674c2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_id': '20250523_0002',\n",
       " 'wdate': '2025-05-23 18:52:00',\n",
       " 'stock_list': [{'stock_id': '377300', 'stock_name': '카카오페이'}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_list_converted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "a824bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "pipeline = NewsMarketPipeline(news_list_converted[:1], df_base_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "52295ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c3164ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8b3fffa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtest\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d7eeb49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf1\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df1' is not defined"
     ]
    }
   ],
   "source": [
    "df1.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b78978a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mtest\u001b[49m[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "df2 = pd.DataFrame(test[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f38382db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf2\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df2' is not defined"
     ]
    }
   ],
   "source": [
    "df2.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b8b9a4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\n\u001b[0;32m      2\u001b[0m     [\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnews_id\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_5_date_close\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_5_date_volume\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_5_date_foreign\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_5_date_institution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_5_date_individual\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_4_date_close\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_4_date_volume\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_4_date_foreign\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_4_date_institution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_4_date_individual\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_3_date_close\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_3_date_volume\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_3_date_foreign\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_3_date_institution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_3_date_individual\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_2_date_close\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_2_date_volume\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     21\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_2_date_foreign\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_2_date_institution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_2_date_individual\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_1_date_close\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_1_date_volume\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_1_date_foreign\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_1_date_institution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md_minus_1_date_individual\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfx\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbond10y\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     32\u001b[0m     ]\n\u001b[0;32m     33\u001b[0m ]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df[\n",
    "    [\n",
    "        \"news_id\",\n",
    "        \"d_minus_5_date_close\",\n",
    "        \"d_minus_5_date_volume\",\n",
    "        \"d_minus_5_date_foreign\",\n",
    "        \"d_minus_5_date_institution\",\n",
    "        \"d_minus_5_date_individual\",\n",
    "        \"d_minus_4_date_close\",\n",
    "        \"d_minus_4_date_volume\",\n",
    "        \"d_minus_4_date_foreign\",\n",
    "        \"d_minus_4_date_institution\",\n",
    "        \"d_minus_4_date_individual\",\n",
    "        \"d_minus_3_date_close\",\n",
    "        \"d_minus_3_date_volume\",\n",
    "        \"d_minus_3_date_foreign\",\n",
    "        \"d_minus_3_date_institution\",\n",
    "        \"d_minus_3_date_individual\",\n",
    "        \"d_minus_2_date_close\",\n",
    "        \"d_minus_2_date_volume\",\n",
    "        \"d_minus_2_date_foreign\",\n",
    "        \"d_minus_2_date_institution\",\n",
    "        \"d_minus_2_date_individual\",\n",
    "        \"d_minus_1_date_close\",\n",
    "        \"d_minus_1_date_volume\",\n",
    "        \"d_minus_1_date_foreign\",\n",
    "        \"d_minus_1_date_institution\",\n",
    "        \"d_minus_1_date_individual\",\n",
    "        \"fx\",\n",
    "        \"bond10y\",\n",
    "        \"base_rate\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "845ed856",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6315efd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1951995059.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[24], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    df[]\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242a52b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_d_minus_1_info_single(news: dict) -> dict:\n",
    "    from pykrx import stock\n",
    "    import pandas as pd\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    # 날짜 처리\n",
    "    news_date = pd.to_datetime(news[\"wdate\"]).normalize()\n",
    "    year, month = news_date.year, news_date.month\n",
    "\n",
    "    # 전달 계산\n",
    "    if month == 1:\n",
    "        prev_year, prev_month = year - 1, 12\n",
    "    else:\n",
    "        prev_year, prev_month = year, month - 1\n",
    "\n",
    "    # 거래일 수집 (해당 월 + 전달)\n",
    "    trading_days = []\n",
    "    for y, m in [(prev_year, prev_month), (year, month)]:\n",
    "        try:\n",
    "            days = stock.get_previous_business_days(year=y, month=m)\n",
    "            trading_days.extend(days)\n",
    "        except:\n",
    "            continue\n",
    "    trading_days = pd.to_datetime(sorted(set(trading_days)))\n",
    "\n",
    "    # D-day (뉴스일 기준 가장 가까운 거래일)\n",
    "    d_day_idx = trading_days.searchsorted(news_date, side=\"right\") - 1\n",
    "    if d_day_idx < 0:\n",
    "        return {}\n",
    "\n",
    "    d_day = trading_days[d_day_idx]\n",
    "    d_minus_1_idx = d_day_idx - 1\n",
    "    if d_minus_1_idx < 0:\n",
    "        return {}\n",
    "\n",
    "    d_minus_1 = trading_days[d_minus_1_idx]\n",
    "\n",
    "    # Ticker 추출\n",
    "    stock_list = news.get(\"stock_list\", [])\n",
    "    if not stock_list or not isinstance(stock_list, list):\n",
    "        return {}\n",
    "\n",
    "    ticker = str(stock_list[-1][\"stock_id\"]).zfill(6)\n",
    "\n",
    "    # d-1 및 fallback 날짜 문자열 생성\n",
    "    fallback_dates = [d_minus_1 - timedelta(days=i) for i in range(0, 10)]\n",
    "    fallback_dates_str = [d.strftime(\"%Y%m%d\") for d in fallback_dates]\n",
    "\n",
    "    # OHLCV 수집\n",
    "    try:\n",
    "        ohlcv = stock.get_market_ohlcv_by_date(\n",
    "            min(fallback_dates_str), max(fallback_dates_str), ticker\n",
    "        ).reset_index()\n",
    "        ohlcv.rename(columns={\"날짜\": \"date\"}, inplace=True)\n",
    "        ohlcv[\"ticker\"] = ticker\n",
    "    except:\n",
    "        ohlcv = pd.DataFrame()\n",
    "\n",
    "    # 수급 데이터 수집\n",
    "    try:\n",
    "        trade = stock.get_market_trading_value_by_date(\n",
    "            min(fallback_dates_str), max(fallback_dates_str), ticker\n",
    "        ).reset_index()\n",
    "        trade.rename(columns={\"날짜\": \"date\"}, inplace=True)\n",
    "        trade[\"ticker\"] = ticker\n",
    "    except:\n",
    "        trade = pd.DataFrame()\n",
    "\n",
    "    # fallback: 가장 가까운 날짜의 값\n",
    "    def get_latest(source_df, cols):\n",
    "        for d in fallback_dates:\n",
    "            row = source_df[(source_df[\"date\"] == d) & (source_df[\"ticker\"] == ticker)]\n",
    "            if not row.empty:\n",
    "                return row.iloc[0][cols].to_dict()\n",
    "        return {col: None for col in cols}\n",
    "\n",
    "    ohlcv_vals = get_latest(ohlcv, [\"종가\", \"거래량\"])\n",
    "    trade_vals = get_latest(trade, [\"개인\", \"기관합계\", \"외국인합계\"])\n",
    "\n",
    "    return {\n",
    "        \"news_id\": news[\"news_id\"],\n",
    "        \"d_minus_1_close\": ohlcv_vals[\"종가\"],\n",
    "        \"d_minus_1_volume\": ohlcv_vals[\"거래량\"],\n",
    "        \"d_minus_1_individual\": trade_vals[\"개인\"],\n",
    "        \"d_minus_1_institution\": trade_vals[\"기관합계\"],\n",
    "        \"d_minus_1_foreign\": trade_vals[\"외국인합계\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7824a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "news = {\n",
    "    \"news_id\": \"20250523_0002\",\n",
    "    \"wdate\": \"2025-05-23 18:52:00\",\n",
    "    \"stock_list\": [{\"stock_id\": \"377300\", \"stock_name\": \"카카오페이\"}],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45b32037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_id': '20250523_0002',\n",
       " 'd_minus_1_date': '2025-05-22',\n",
       " 'd_minus_1_close': 30300,\n",
       " 'd_minus_1_volume': 197238,\n",
       " 'd_minus_1_individual': -1916639300,\n",
       " 'd_minus_1_institution': 1166288875,\n",
       " 'd_minus_1_foreign': 574800375}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_d_minus_1_info_single(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d62539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-0602",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
