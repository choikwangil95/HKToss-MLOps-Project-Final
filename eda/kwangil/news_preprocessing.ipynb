{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf643670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from label_map import label2id, id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342e643a",
   "metadata": {},
   "source": [
    "## 1 ë‰´ìŠ¤ ë³¸ë¬¸ ì „ì²˜ë¦¬, ìš”ì•½, ì¢…ëª©ëª…, ì—…ì¢…ëª…, ì„ë² ë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2da6a4",
   "metadata": {},
   "source": [
    "### 1 ë‰´ìŠ¤ ë³¸ë¬¸ ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e71a93df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../db/news_2023_2025.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "999e1adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news_id</th>\n",
       "      <th>wdate</th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>press</th>\n",
       "      <th>url</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20250523_0001</td>\n",
       "      <td>2025-05-23 19:11</td>\n",
       "      <td>[ë§ˆì¼“ì¸]ëª¨íƒœí€ë“œ ì¡´ì† ë¶ˆí™•ì‹¤ì„± í•´ì†Œë ê¹Œâ€¦ì´ì¬ëª… ê³µì•½ì— ì—…ê³„ ì£¼ëª©</td>\n",
       "      <td>2035ë…„ ì¢…ë£Œ ì•ë‘¬, ì¡´ì† ê³µì•½ì— ê¸°ëŒ€ê°\\nì°½ì—… ì´ˆê¸°ìê¸ˆ ê³µë°± ì™„í™” ê°€ëŠ¥ì„±ì— ì—…ê³„...</td>\n",
       "      <td>ì´ë°ì¼ë¦¬</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/018/000...</td>\n",
       "      <td>https://imgnews.pstatic.net/image/018/2025/05/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20250523_0002</td>\n",
       "      <td>2025-05-23 18:52</td>\n",
       "      <td>[ë‹¨ë…] ì¹´ì¹´ì˜¤í˜ì´, 2500ë§Œ íšŒì› ì“±Â·ìŠ¤ë§ˆì¼í˜ì´ í’ˆë‚˜â€¦ê°„í¸ê²°ì œ ì‹œì¥ ë¹…3 ê²½ìŸ í›„ëˆ</td>\n",
       "      <td>ë§¤ê°ê°€ 5000ì–µ ì•ˆíŒ ë‹¬í• ë“¯\\nê²°ì œì‹œì¥ ë‚´ ì…ì§€ê°•í™” í¬ì„\\nì¹´ì¹´ì˜¤í˜ì´ [ì‚¬ì§„ = ...</td>\n",
       "      <td>ë§¤ì¼ê²½ì œ</td>\n",
       "      <td>https://n.news.naver.com/mnews/article/009/000...</td>\n",
       "      <td>https://imgnews.pstatic.net/image/009/2025/05/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         news_id             wdate  \\\n",
       "0  20250523_0001  2025-05-23 19:11   \n",
       "1  20250523_0002  2025-05-23 18:52   \n",
       "\n",
       "                                              title  \\\n",
       "0              [ë§ˆì¼“ì¸]ëª¨íƒœí€ë“œ ì¡´ì† ë¶ˆí™•ì‹¤ì„± í•´ì†Œë ê¹Œâ€¦ì´ì¬ëª… ê³µì•½ì— ì—…ê³„ ì£¼ëª©   \n",
       "1  [ë‹¨ë…] ì¹´ì¹´ì˜¤í˜ì´, 2500ë§Œ íšŒì› ì“±Â·ìŠ¤ë§ˆì¼í˜ì´ í’ˆë‚˜â€¦ê°„í¸ê²°ì œ ì‹œì¥ ë¹…3 ê²½ìŸ í›„ëˆ   \n",
       "\n",
       "                                             article press  \\\n",
       "0  2035ë…„ ì¢…ë£Œ ì•ë‘¬, ì¡´ì† ê³µì•½ì— ê¸°ëŒ€ê°\\nì°½ì—… ì´ˆê¸°ìê¸ˆ ê³µë°± ì™„í™” ê°€ëŠ¥ì„±ì— ì—…ê³„...  ì´ë°ì¼ë¦¬   \n",
       "1  ë§¤ê°ê°€ 5000ì–µ ì•ˆíŒ ë‹¬í• ë“¯\\nê²°ì œì‹œì¥ ë‚´ ì…ì§€ê°•í™” í¬ì„\\nì¹´ì¹´ì˜¤í˜ì´ [ì‚¬ì§„ = ...  ë§¤ì¼ê²½ì œ   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://n.news.naver.com/mnews/article/018/000...   \n",
       "1  https://n.news.naver.com/mnews/article/009/000...   \n",
       "\n",
       "                                               image  \n",
       "0  https://imgnews.pstatic.net/image/018/2025/05/...  \n",
       "1  https://imgnews.pstatic.net/image/009/2025/05/...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dc0deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from kss import split_sentences\n",
    "\n",
    "def remove_market_related_sentences(text: str) -> str:\n",
    "    # ì¤„ë°”ê¿ˆ ì œê±°\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # ëŒ€ê´„í˜¸ í¬í•¨ í…ìŠ¤íŠ¸ ì œê±°: [íŒŒì´ë‚¸ì…œë‰´ìŠ¤], [ì‚¬ì§„] ë“±\n",
    "    text = re.sub(r\"\\[[^\\]]*\\]\", \"\", text)\n",
    "\n",
    "    # '/ì‚¬ì§„', '/ì‚¬ì§„ì œê³µ' ì œê±°\n",
    "    text = re.sub(r\"/ì‚¬ì§„(ì œê³µ)?\", \"\", text)\n",
    "\n",
    "    # ì´ë©”ì¼ ì£¼ì†Œ ì œê±° (ì˜ˆ: josh@yna.co.kr)\n",
    "    text = re.sub(r\"\\b[\\w.-]+@[\\w.-]+\\.\\w+\\b\", \"\", text)\n",
    "\n",
    "    # ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬ (ê°„ë‹¨í•˜ê²Œ ë§ˆì¹¨í‘œ ê¸°ì¤€, í•„ìš”ì‹œ KSS ë“± ì ìš© ê°€ëŠ¥)\n",
    "    sentences = split_sentences(text)\n",
    "\n",
    "    # ì œê±°í•  íŒ¨í„´ë“¤ (ë‰´ìŠ¤ ë¬¸ì¥ì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” íŒ¨í„´)\n",
    "    patterns = [\n",
    "        r\"(ìì„¸í•œ ë‚´ìš©|ìì„¸í•œ ì‚¬í•­)\",  # ë‰´ìŠ¤ ê¸°ë³¸ í‘œí˜„\n",
    "        r\"\\d{4}[.-]\\d{1,2}[.-]\\d{1,2}\",  # ë‚ ì§œ (ì˜ˆ: 2025.03.26, 2024-12-01)\n",
    "        r\"([0-9,]+(?:ë§Œ)?[0-9,]*\\s?(?:ì›|ë§Œì›))\",  # ê°€ê²© (ì˜ˆ: 3,500ì›, 12000ì›)\n",
    "        r\"(ê°•ì„¸|í€ë“œ|ì‹œê°€ì´ì•¡|ë“±ë½ë¥ |í•œêµ­ê±°ë˜ì†Œ)\",  # ì¦ì‹œ ìš©ì–´\n",
    "        r\"\\([+-]?[0-9.,]+%\\)\",  # ê´„í˜¸ ì•ˆ í¼ì„¼íŠ¸ ë“±ë½ë¥ \n",
    "        r\"(íˆ¬ìì˜ê²¬|ì—°êµ¬ì›|í‰ê°€|ì˜ˆìƒì¹˜|ì¦ê¶Œê°€|ë¦¬í¬íŠ¸|íŒ€ì¥)\",  # ì• ë„ë¦¬ìŠ¤íŠ¸ ìš©ì–´\n",
    "        r\"(ìˆœì´ìµ|ì „ë…„|ë§¤ì¶œ|ì˜ì—…ì´ìµ|ì˜ì—…ì ì|ì¦ì‹œ|ì½”ìŠ¤í”¼|ì½”ìŠ¤ë‹¥|ë‹¤ìš°|ë‚˜ìŠ¤ë‹¥|ë§¤ì¶œì•¡|ê±°ë˜ì¼|í˜¸ì¡°ì„¸|ë ˆë²„ë¦¬ì§€|íˆ¬ìì|ì¡°ì •|ìì‚°|ìˆ˜ìµë¥ |ì´ìµë¥ |ìˆ˜ìµì„±|ë‚´ë¦¬ë§‰|ë¶€ì§„í•œ|ë‚™í­|ê¸°ëŒ€ì¹˜|ì‹¤ì ë°œí‘œ|ê¸°ì—… ê°€ì¹˜)\",  # ì‹œì¥ ìš©ì–´\n",
    "    ]\n",
    "\n",
    "    # í•˜ë‚˜ì˜ í†µí•© íŒ¨í„´ìœ¼ë¡œ ì»´íŒŒì¼\n",
    "    combined_pattern = re.compile(\"|\".join(patterns))\n",
    "\n",
    "    # í•„í„°ë§ëœ ë¬¸ì¥ë§Œ ìœ ì§€\n",
    "    filtered = [s for s in sentences if not combined_pattern.search(s)]\n",
    "\n",
    "    text_preprocessed = \" \".join(filtered)\n",
    "\n",
    "    # print(f\"ì›ë¬¸:{sentences}\\n|\\nì „ì²˜ë¦¬ ëœ ë¬¸ì¥: {text_preprocessed}\\n\\n\")\n",
    "\n",
    "    return text_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1970973a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58405/58405 [28:07<00:00, 34.61it/s]  \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()  # ì´ê±° ë°˜ë“œì‹œ í˜¸ì¶œí•´ì•¼ í•¨\n",
    "\n",
    "df[\"article_preprocessed\"] = df[\n",
    "    \"article\"\n",
    "].progress_apply(remove_market_related_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e1795f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_article_preprocessed(df):\n",
    "    # ì „ì²˜ë¦¬ëœ ë¬¸ì¥ ê¸¸ì´ êµ¬í•˜ê¸°\n",
    "    df[\"article_preprocessed_len\"] = df[\n",
    "        \"article_preprocessed\"\n",
    "    ].apply(lambda x: len(x))\n",
    "\n",
    "    # ì „ì²˜ë¦¬ëœ ë¬¸ì¥ ê¸¸ì´ê°€ 70 ì´ìƒì¸ ê²ƒë§Œ í•„í„°ë§\n",
    "    df = df[\n",
    "        df[\"article_preprocessed_len\"] > 70\n",
    "    ]\n",
    "\n",
    "    df = df.drop(columns=[\"article_preprocessed_len\"])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e16b4fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_article_preprocessed(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80f61e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 53202 entries, 0 to 58404\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   news_id               53202 non-null  object\n",
      " 1   wdate                 53202 non-null  object\n",
      " 2   title                 53202 non-null  object\n",
      " 3   article               53202 non-null  object\n",
      " 4   press                 53202 non-null  object\n",
      " 5   url                   53202 non-null  object\n",
      " 6   image                 53202 non-null  object\n",
      " 7   article_preprocessed  53202 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b86993",
   "metadata": {},
   "source": [
    "### 2 ë‰´ìŠ¤ ë³¸ë¬¸ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff0282d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels will be overwritten to 2.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(30000, 768, padding_idx=3)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1028, 768)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# ëª¨ë¸ ì´ë¦„\n",
    "model_summarize_name1 = \"digit82/kobart-summarization\"\n",
    "\n",
    "# í† í¬ë‚˜ì´ì € & ëª¨ë¸ ë¡œë“œ\n",
    "tokenizer_summarize1 = AutoTokenizer.from_pretrained(model_summarize_name1)\n",
    "model_summarize1 = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_summarize_name1, use_safetensors=True\n",
    ")\n",
    "\n",
    "# GPU ì‚¬ìš© ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_summarize1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "be546d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_event_focused(text):\n",
    "    # í† í¬ë‚˜ì´ì§• ë° í…ì„œ ë³€í™˜ (GPUë¡œ ì˜¬ë¦¬ê¸°)\n",
    "    inputs = tokenizer_summarize1(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "\n",
    "    text_length = len(text)\n",
    "\n",
    "    # 1. ìµœì†Œ ê¸¸ì´ëŠ” ì§§ì€ ë³¸ë¬¸ì€ ê³ ì •, ê¸´ ë³¸ë¬¸ì€ ì ì§„ì ìœ¼ë¡œ ì¦ê°€\n",
    "    def compute_min_length(text_length: int) -> int:\n",
    "        if text_length < 300:\n",
    "            return 30\n",
    "        else:\n",
    "            return 50\n",
    "\n",
    "    min_len = compute_min_length(text_length)\n",
    "    max_len = round(text_length * 0.5) + 50  # ë” ì—¬ìœ ë¥¼ ì£¼ë˜ max ê¸¸ì´ ì œí•œ\n",
    "\n",
    "    # 2. generate ìµœì  ì„¤ì •\n",
    "    summary_ids = model_summarize1.generate(\n",
    "        input_ids,\n",
    "        min_length=min_len,\n",
    "        max_new_tokens=max_len,\n",
    "        num_beams=4,  # 4ë³´ë‹¤ ë¹ ë¦„. í’ˆì§ˆë„ ë¹„ìŠ·\n",
    "        length_penalty=1.0,  # ê¸¸ì´ íŒ¨ë„í‹° ì™„í™”\n",
    "        repetition_penalty=1.3,  # ë°˜ë³µ ì–µì œ ê°•í™”\n",
    "        no_repeat_ngram_size=3,  # ë°˜ë³µ ë¬¸ì¥ ë°©ì§€\n",
    "        early_stopping=True,\n",
    "        do_sample=False,  # ì¼ê´€ëœ ìš”ì•½\n",
    "    )\n",
    "\n",
    "    return tokenizer_summarize1.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "def print_summary(df, max_tokens=128):\n",
    "    for i, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            text = row[\"article_preprocessed\"]\n",
    "            summary = summarize_event_focused(text)\n",
    "            print(f\"\\nğŸ“ ë‰´ìŠ¤ {i}\\n\\në³¸ë¬¸: {text} \\n\\nìš”ì•½: {summary}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ìš”ì•½ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0b09664",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|â–ˆâ–ˆâ–ˆâ–      | 1/3 [00:04<00:09,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ë‰´ìŠ¤ 0\n",
      "\n",
      "ë³¸ë¬¸: 2035ë…„ ì¢…ë£Œ ì•ë‘¬, ì¡´ì† ê³µì•½ì— ê¸°ëŒ€ê° ì°½ì—… ì´ˆê¸°ìê¸ˆ ê³µë°± ì™„í™” ê°€ëŠ¥ì„±ì— ì—…ê³„ ì•ˆë„ VC, \"ì •ì±… ì—°ì†ì„± ì¤‘ìš”â€¦ë¶ˆí™•ì‹¤ì„± ì¤„ì–´ì•¼\" í‡´ì§ì—°ê¸ˆë„ ë²¤ì²˜ë¡œâ€¦BDC ë“± í™œì„±í™” ë°©ì•ˆ í¬í•¨ ì´ ê¸°ì‚¬ëŠ” 2025ë…„05ì›”23ì¼ 17ì‹œ10ë¶„ì— ë§ˆì¼“ì¸ í”„ë¦¬ë¯¸ì—„ ì½˜í…ì¸  ë¡œ ì„ ê³µê°œ ë˜ì—ˆìŠµë‹ˆë‹¤. 23ì¼ ê´€ë ¨ì—…ê³„ì— ë”°ë¥´ë©´ ì´ í›„ë³´ëŠ” í•´ë‹¹ ê³µì•½ì„ â€˜ë²¤ì²˜Â·ìŠ¤íƒ€íŠ¸ì—… 10ëŒ€ ê³µì•½â€™ì˜ í•˜ë‚˜ë¡œ í¬í•¨ì‹œí‚¤ë©°, ë²¤ì²˜ íˆ¬ì ì¸í”„ë¼ë¥¼ ì œë„ì ìœ¼ë¡œ ë³´ì™„í•˜ê² ë‹¤ëŠ” ì˜ì§€ë¥¼ ë‚´ë¹„ì³¤ë‹¤. ì—…ê³„ì—ì„œëŠ” ë‹¨ê¸° ì˜ˆì‚° ë³µì›ì´ ì•„ë‹Œ, ì •ì±… ì—°ì†ì„±ì— ë¬´ê²Œë¥¼ ë‘” ì ì— ì£¼ëª©í•˜ê³  ìˆë‹¤. ê¸€ë¡œë²Œ ëŒ€ë¹„ ë¯¼ê°„ ìë³¸ì˜ íˆ¬ì ì—¬ë ¥ì´ ì œí•œì ì¸ í•œêµ­ ë²¤ì²˜ ì‹œì¥ íŠ¹ì„±ìƒ, ì •ë¶€ ì¶œìì˜ ì¡´ì¬ê°ì€ ê·¸ë§Œí¼ ì ˆëŒ€ì ì´ë‹¤. ì´ì— ë”°ë¼ ë²¤ì²˜ìºí”¼í„¸(VC) ì—…ê³„ì—ì„œëŠ” ì´ì¬ëª… í›„ë³´ì˜ ê³µì•½ì´ ë‹¨ìˆœí•œ ì˜ˆì‚° ë³µì›ì„ ë„˜ì–´ êµ¬ì¡°ì ì¸ ë¶ˆí™•ì‹¤ì„± í•´ì†Œì— ë°©ì ì„ ë‘ê³  ìˆë‹¤ëŠ” ì ì—ì„œ ê¸ì •ì ìœ¼ë¡œ ë°›ì•„ë“¤ì´ëŠ” ë¶„ìœ„ê¸°ë‹¤. ì´ í›„ë³´ëŠ” ì´ì™¸ì—ë„ í‡´ì§ì—°ê¸ˆì˜ ë²¤ì²˜íˆ¬ì í—ˆìš©, ì—°ê¸°ê¸ˆ íˆ¬ìí’€ì˜ ë²¤ì²˜íˆ¬ì í™•ëŒ€, ê¸°ì—… ì„±ì¥ì§‘í•©íˆ¬ìê¸°êµ¬(BDC) ë„ì… ë“± ë‹¤ì–‘í•œ ë²¤ì²˜íˆ¬ì í™œì„±í™” ë°©ì•ˆì„ í•¨ê»˜ ì œì‹œí•˜ë©° íˆ¬ì ìƒíƒœê³„ ì „ë°˜ì˜ êµ¬ì¡° ê°œí¸ ì˜ì§€ë¥¼ ë°í˜”ë‹¤. \n",
      "\n",
      "ìš”ì•½: ì´ì¬ëª… í›„ë³´ì˜ ë²¤ì²˜íˆ¬ì í—ˆìš©, ì—°ê¸°ê¸ˆ íˆ¬ìí’€ì˜ ë²¤ì²˜íˆ¬ì í™•ëŒ€, ê¸°ì—… ì„±ì¥ì§‘í•©íˆ¬ìê¸°êµ¬(BDC) ë„ì… ë“± ë‹¤ì–‘í•œ ë²¤ì²˜íˆ¬ì í™œì„±í™” ë°©ì•ˆì„ í•¨ê»˜ ì œì‹œí•˜ë©° íˆ¬ì ìƒíƒœê³„ ì „ë°˜ì˜ êµ¬ì¡° ê°œí¸ ì˜ì§€ë¥¼ ë‚´ë¹„ì³¤ë‹¤.   \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:06<00:02,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ë‰´ìŠ¤ 1\n",
      "\n",
      "ë³¸ë¬¸: ë§¤ê°ê°€ 5000ì–µ ì•ˆíŒ ë‹¬í• ë“¯ ê²°ì œì‹œì¥ ë‚´ ì…ì§€ê°•í™” í¬ì„ ì¹´ì¹´ì˜¤í˜ì´  êµ­ë‚´ ëŒ€í‘œ ì „ìê²°ì œì‚¬ì—…ìì¸ ì¹´ì¹´ì˜¤í˜ì´ê°€ ì‹ ì„¸ê³„ì´ë§ˆíŠ¸ ì‚°í•˜ ê°„í¸ê²°ì œì‚¬ì—…ë¶€ ì¸ìˆ˜ì— ë‚˜ì„°ë‹¤. ë„¤ì´ë²„í˜ì´Â·í† ìŠ¤í˜ì´ì— ëŒ€í•­í•´ ì‹œì¥ ì ìœ ìœ¨ì„ ëŠ˜ë¦¬ë ¤ëŠ” í¬ì„ìœ¼ë¡œ í•´ì„ëœë‹¤. 23ì¼ ì •ë³´ê¸°ìˆ (IT)Â·íˆ¬ìì€í–‰(IB) ì—…ê³„ì— ë”°ë¥´ë©´ ì¹´ì¹´ì˜¤í˜ì´ê°€ SSGë‹·ì»´ ì“±í˜ì´ì™€ Gë§ˆì¼“ ìŠ¤ë§ˆì¼í˜ì´ ì¸ìˆ˜ë¥¼ ìœ„í•´ ì‹ ì„¸ê³„ì´ë§ˆíŠ¸ ì¸¡ê³¼ í˜‘ìƒì„ ì§„í–‰ ì¤‘ì¸ ê²ƒìœ¼ë¡œ íŒŒì•…ëë‹¤. ì—…ê³„ì—ì„œëŠ” ë§¤ê°ê°€ê°€ 5000ì–µì› ì•ˆíŒì— ë‹¬í•  ê²ƒìœ¼ë¡œ ì „ë§í–ˆë‹¤. ì¹´ì¹´ì˜¤í˜ì´ëŠ” ì•½ 2500ë§Œëª…ì˜ ì´ìš©ìë¥¼ ë³´ìœ í•œ ì“±í˜ì´Â·ìŠ¤ë§ˆì¼í˜ì´ë¥¼ ì¸ìˆ˜í•  ê²½ìš° ì‚¬ì—… ì™¸ì—°ì„ í™•ëŒ€í•  ìˆ˜ ìˆë‹¤. ë§¤ê° ì‘ì—…ì— ì •í†µí•œ ì—…ê³„ ê³ ìœ„ ê´€ê³„ìëŠ” â€œì¹´ì¹´ì˜¤í˜ì´ê°€ ê²°ì œì‹œì¥ ë‚´ ì…ì§€ ê°•í™”ë¥¼ ìœ„í•´ ì‹ ì„¸ê³„ì´ë§ˆíŠ¸ì™€ ê²°ì œì‚¬ì—… ë¶€ë¬¸ ì¸ìˆ˜ ë“± ë‹¤ì–‘í•œ ë°©ì•ˆì— ëŒ€í•´ ë…¼ì˜ ì¤‘ì¸ ê²ƒìœ¼ë¡œ ì•ˆë‹¤â€ê³  ì „í–ˆë‹¤. ì‹ ì„¸ê³„ì´ë§ˆíŠ¸ ì¸¡ì€ â€œë§¤ê°ì„ ì¬ì¶”ì§„ì¤‘ì¸ ê±´ ë§ì§€ë§Œ ì•„ì§ ì •í•´ì§„ ê²ƒì€ ì—†ë‹¤â€ê³  ë°í˜”ë‹¤. ì‹ ì„¸ê³„ì´ë§ˆíŠ¸ëŠ” ì§€ë‚œ í•´ í† ìŠ¤ì™€ ê²°ì œì‚¬ì—… ë§¤ê°ì„ ë…¼ì˜í•˜ë‹¤ ê²°ë ¬ëœ ë°” ìˆë‹¤. \n",
      "\n",
      "ìš”ì•½: 23ì¼ ì •ë³´ê¸°ìˆ (IT)Â·íˆ¬ìì€í–‰(IB) ì—…ê³„ì— ë”°ë¥´ë©´ êµ­ë‚´ ëŒ€í‘œ ì „ìê²°ì œì‚¬ì—…ìì¸ ì¹´ì¹´ì˜¤í˜ì´ê°€ SSGë‹·ì»´ ì“±í˜ì´ì™€ Gë§ˆì¼“ ìŠ¤ë§ˆì¼í˜ì´ ì¸ìˆ˜ë¥¼ ìœ„í•´ ì‹ ì„¸ê³„ì´ë§ˆíŠ¸ ì¸¡ê³¼ í˜‘ìƒì„ ì§„í–‰ ì¤‘ì¸ ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œë‹¤.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:07<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ ë‰´ìŠ¤ 2\n",
      "\n",
      "ë³¸ë¬¸: ì´ 2166ëŒ€1ì˜ ê²½ìŸë¥ ì„ ê¸°ë¡, ì²­ì•½ ì¦ê±°ê¸ˆ 6ì¡°ì›ì„ ëª¨ìœ¼ëŠ” ë° ì„±ê³µí–ˆë‹¤. ì§€ë‚œ 22ì¼ë¶€í„° ì´ë‚ ê¹Œì§€ ì–‘ê°„ ì¼ë°˜ ì²­ì•½ì„ ì§„í–‰í•œ ê²°ê³¼ ìµœì¢… ê²½ìŸë¥ ì€ ì´ 2166.01ëŒ€1ë¡œ  ì§‘ê³„ëë‹¤. ì²­ì•½ ê±´ìˆ˜ëŠ” 19ë§Œ1049ê±´ìœ¼ë¡œ, ì²­ì•½ ê¸ˆì•¡ì˜ ì ˆë°˜ì„ ë¯¸ë¦¬ ë‚´ëŠ” ì²­ì•½ì¦ê±°ê¸ˆì€ ì•½ 6ì¡°1400ì–µì›ì´ ëª¨ì˜€ë‹¤. í‚¤ìŠ¤íŠ¸ë¡ ì€ ê³ ë ¤ì œê°•ê·¸ë£¹ ê³„ì—´ì‚¬ë¡œ 1992ë…„ ì„¤ë¦½ëë‹¤. ì² ì„ ì— êµ¬ë¦¬ë¥¼ ë„ê¸ˆí•œ ë™ë³µê°•ì„  ë¦¬ë“œ ì™€ì´ì–´ê°€ í•µì‹¬ ì œí’ˆìœ¼ë¡œ, ê¸€ë¡œë²Œ ì‹œì¥ì—ì„œ ì•½ 18% ì ìœ ìœ¨ì„ ê°–ì·„ë‹¤. ì´ë²ˆ ê³µëª¨ë¥¼ í†µí•´ 226ì–µ ì›ì„ ì¡°ë‹¬í•œë‹¤. ì£¼ê´€ì‚¬ëŠ” ì‹ í•œíˆ¬ìì¦ê¶Œì´ ë§¡ì•˜ë‹¤. \n",
      "\n",
      "ìš”ì•½: ê³ ë ¤ì œê°•ê·¸ë£¹ ê³„ì—´ì‚¬ë¡œ 1992ë…„ ì„¤ë¦½ëœ í‚¤ìŠ¤íŠ¸ë¡ ì€ ì§€ë‚œ 22ì¼ë¶€í„° ì–‘ê°„ ì¼ë°˜ ì²­ì•½ì„ ì§„í–‰í•œ ê²°ê³¼ ìµœì¢… ê²½ìŸë¥ ì€ ì´ 2166.01ëŒ€1ë¡œ ì§‘ê³„ëë‹¤.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print_summary(df[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ef8ba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6e504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 49/20000 [01:11<8:19:21,  1.50s/it] "
     ]
    }
   ],
   "source": [
    "df[\"summary\"] = df[\n",
    "    \"article_preprocessed\"\n",
    "].progress_apply(summarize_event_focused)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafa3b83",
   "metadata": {},
   "source": [
    "### 3 ë‰´ìŠ¤ ì¢…ëª© ë§¤ì¹­í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af7e1aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from label_map import label2id, id2label\n",
    "\n",
    "model_name = \"KPF/KPF-BERT-NER\"\n",
    "\n",
    "# í† í¬ë‚˜ì´ì €ì™€ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "tokenizer_ner = AutoTokenizer.from_pretrained(model_name)\n",
    "model_ner = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, use_safetensors=True\n",
    ")\n",
    "\n",
    "# ë¼ë²¨ ë§¤í•‘ ë°˜ì˜\n",
    "model_ner.config.label2id = label2id\n",
    "model_ner.config.id2label = id2label\n",
    "\n",
    "tokenizer_ner.model_max_length = 512\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# NER íŒŒì´í”„ë¼ì¸ ìƒì„± (GPU ì‚¬ìš©)\n",
    "ner_pipeline = pipeline(\n",
    "    task=\"ner\",\n",
    "    model=model_ner,\n",
    "    tokenizer=tokenizer_ner,\n",
    "    aggregation_strategy=\"simple\",\n",
    "    framework=\"pt\",\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61d891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ner(text):\n",
    "    entities = ner_pipeline(text)\n",
    "    results = []\n",
    "    seen = set()\n",
    "\n",
    "    for ent in entities:\n",
    "        word = ent[\"word\"].replace(\"##\", \"\").strip()\n",
    "        tag = ent[\"entity_group\"]\n",
    "\n",
    "        score = ent[\"score\"]\n",
    "\n",
    "        if word and score >= 0.95 and (word, tag) not in seen:\n",
    "            results.append((word, tag))\n",
    "            seen.add((word, tag))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_stock_names(text):\n",
    "    ner_list = extract_ner(text)\n",
    "\n",
    "    # OGG_ECONOMYë§Œ í•„í„°ë§í•˜ì—¬ ì¢…ëª©ëª…ë§Œ ë¦¬ìŠ¤íŠ¸ë¡œ ì¶”ì¶œ\n",
    "    stock_names = [ent[0] for ent in ner_list if ent[1] == \"OGG_ECONOMY\"]\n",
    "\n",
    "    return stock_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df616db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stock_list\"] = df[\"summary\"].progress_apply(\n",
    "    get_stock_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32455c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¢…ëª©ëª…ì´ 1ê°œ ì´ìƒ, 4ê°œ ì´í•˜ì¸ ë‰´ìŠ¤ë§Œ í•„í„°ë§í•˜ê¸°\n",
    "\n",
    "df[\"stock_list_len\"] = df[\"stock_list\"].apply(lambda x: len(x))\n",
    "\n",
    "df = df[(df[\"stock_list_len\"] >= 1) & (df[\"stock_list_len\"] <= 4)]\n",
    "\n",
    "df = df.drop(columns=[\"stock_list_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3bc0c0",
   "metadata": {},
   "source": [
    "### 4 ë‰´ìŠ¤ ì—…ì¢…ëª… ë§¤ì¹­í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a73c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_krx_desc = pd.read_csv(\"../../db/kospi_description.csv\", encoding=\"cp949\")\n",
    "df_krx_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¢…ëª©ëª… â†’ ì—…ì¢…ëª… ë§¤í•‘ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "stock_to_industry = dict(zip(df_krx_desc[\"ì¢…ëª©ëª…\"], df_krx_desc[\"ì—…ì¢…ëª…\"]))\n",
    "\n",
    "# ì—…ì¢…ëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë§¤í•‘\n",
    "def get_industry_list(stock_list):\n",
    "    return [\n",
    "        stock_to_industry.get(stock, \"\")\n",
    "        for stock in stock_list\n",
    "        if stock_to_industry.get(stock, \"\") != \"\"\n",
    "    ]\n",
    "\n",
    "# ìƒˆë¡œìš´ ì»¬ëŸ¼ì— ì €ì¥\n",
    "df[\"industry_list\"] = df[\"stock_list\"].apply(get_industry_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feab71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—…ì¢…ëª…ì´ 1ê°œ ì´ìƒì¸ ë‰´ìŠ¤ë§Œ í•„í„°ë§í•˜ê¸°\n",
    "\n",
    "df[\"industry_list_len\"] = df[\"industry_list\"].apply(lambda x: len(x))\n",
    "\n",
    "df = df[df[\"industry_list_len\"] >= 1]\n",
    "\n",
    "df = df.drop(columns=[\"industry_list_len\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd6ff7",
   "metadata": {},
   "source": [
    "### 5 ë‰´ìŠ¤ ìš”ì•½ë¬¸ ì„ë² ë”©í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "947de2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "model_name = \"snunlp/KR-SBERT-V40K-klueNLI-augSTS\"\n",
    "\n",
    "# GPUê°€ ìˆìœ¼ë©´ GPU, ì—†ìœ¼ë©´ CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ëª¨ë¸ ë¡œë”© í›„ ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "model_emb = SentenceTransformer(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75513db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model_emb.encode(\n",
    "    df[\"summary\"].tolist(), show_progress_bar=True\n",
    ")\n",
    "\n",
    "df[\"summary_embedding\"] = embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../db/news_2023_2025_summarized.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad511eb",
   "metadata": {},
   "source": [
    "## 2 ë‰´ìŠ¤ ê²½ì œ ë° í–‰ë™ ì§€í‘œ í”¼ì³ ì¶”ê°€\n",
    "- ì£¼ê°€ D+1~D+30 ë³€ë™ë¥ , ê¸ˆë¦¬, í™˜ìœ¨, ê¸°ê´€ ë§¤ë§¤ë™í–¥, ìœ ê°€ ë“±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5657ae3c",
   "metadata": {},
   "source": [
    "## 3 ë‰´ìŠ¤ ì‹œë©˜í‹± í”¼ì³ ì¶”ê°€\n",
    "-  topicë³„ ë¶„í¬ê°’, í´ëŸ¬ìŠ¤í„° ë™ì¼ ì—¬ë¶€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aadeb97",
   "metadata": {},
   "source": [
    "## 4 ë‰´ìŠ¤ ê´€ê³„ í”¼ì³ ì¶”ê°€\n",
    "- cosine ìœ ì‚¬ë„, ë™ì¼ ì¢…ëª©, ë™ì¼ í‚¤ì›Œë“œ ì—¬ë¶€ ë“±"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-0602",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
