{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562b7004",
   "metadata": {},
   "source": [
    "## 파일 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f147e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14087 entries, 0 to 14086\n",
      "Data columns (total 87 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   news_id                      14087 non-null  object \n",
      " 1   wdate                        14087 non-null  object \n",
      " 2   title                        14087 non-null  object \n",
      " 3   article                      14087 non-null  object \n",
      " 4   press                        14087 non-null  object \n",
      " 5   url                          14087 non-null  object \n",
      " 6   image                        14087 non-null  object \n",
      " 7   article_preprocessed         14087 non-null  object \n",
      " 8   summary                      14087 non-null  object \n",
      " 9   stock_list                   14087 non-null  object \n",
      " 10  industry_list                14087 non-null  object \n",
      " 11  summary_embedding            14087 non-null  object \n",
      " 12  stock_name                   14087 non-null  object \n",
      " 13  ticker                       14040 non-null  float64\n",
      " 14  D_day_date                   14087 non-null  object \n",
      " 15  D_minus_14_date              14087 non-null  object \n",
      " 16  D_minus_7_date               14087 non-null  object \n",
      " 17  D_minus_3_date               14087 non-null  object \n",
      " 18  D_minus_2_date               14087 non-null  object \n",
      " 19  D_minus_1_date               14087 non-null  object \n",
      " 20  D_plus_1_date                14087 non-null  object \n",
      " 21  D_plus_2_date                14087 non-null  object \n",
      " 22  D_plus_3_date                14087 non-null  object \n",
      " 23  D_plus_7_date                14087 non-null  object \n",
      " 24  D_plus_14_date               13843 non-null  object \n",
      " 25  news_date                    14087 non-null  object \n",
      " 26  D_minus_14_date_close        13824 non-null  float64\n",
      " 27  D_minus_14_date_volume       13824 non-null  float64\n",
      " 28  D_minus_14_date_foreign      13755 non-null  float64\n",
      " 29  D_minus_14_date_institution  13755 non-null  float64\n",
      " 30  D_minus_14_date_individual   13755 non-null  float64\n",
      " 31  D_minus_7_date_close         13830 non-null  float64\n",
      " 32  D_minus_7_date_volume        13830 non-null  float64\n",
      " 33  D_minus_7_date_foreign       13766 non-null  float64\n",
      " 34  D_minus_7_date_institution   13766 non-null  float64\n",
      " 35  D_minus_7_date_individual    13766 non-null  float64\n",
      " 36  D_minus_3_date_close         13838 non-null  float64\n",
      " 37  D_minus_3_date_volume        13838 non-null  float64\n",
      " 38  D_minus_3_date_foreign       13774 non-null  float64\n",
      " 39  D_minus_3_date_institution   13774 non-null  float64\n",
      " 40  D_minus_3_date_individual    13774 non-null  float64\n",
      " 41  D_minus_2_date_close         13843 non-null  float64\n",
      " 42  D_minus_2_date_volume        13843 non-null  float64\n",
      " 43  D_minus_2_date_foreign       13780 non-null  float64\n",
      " 44  D_minus_2_date_institution   13780 non-null  float64\n",
      " 45  D_minus_2_date_individual    13780 non-null  float64\n",
      " 46  D_minus_1_date_close         13852 non-null  float64\n",
      " 47  D_minus_1_date_volume        13852 non-null  float64\n",
      " 48  D_minus_1_date_foreign       13790 non-null  float64\n",
      " 49  D_minus_1_date_institution   13790 non-null  float64\n",
      " 50  D_minus_1_date_individual    13790 non-null  float64\n",
      " 51  D_day_date_close             13896 non-null  float64\n",
      " 52  D_day_date_volume            13896 non-null  float64\n",
      " 53  D_day_date_foreign           13841 non-null  float64\n",
      " 54  D_day_date_institution       13841 non-null  float64\n",
      " 55  D_day_date_individual        13841 non-null  float64\n",
      " 56  D_plus_1_date_close          13901 non-null  float64\n",
      " 57  D_plus_1_date_volume         13901 non-null  float64\n",
      " 58  D_plus_1_date_foreign        13843 non-null  float64\n",
      " 59  D_plus_1_date_institution    13843 non-null  float64\n",
      " 60  D_plus_1_date_individual     13843 non-null  float64\n",
      " 61  D_plus_2_date_close          13903 non-null  float64\n",
      " 62  D_plus_2_date_volume         13903 non-null  float64\n",
      " 63  D_plus_2_date_foreign        13844 non-null  float64\n",
      " 64  D_plus_2_date_institution    13844 non-null  float64\n",
      " 65  D_plus_2_date_individual     13844 non-null  float64\n",
      " 66  D_plus_3_date_close          13904 non-null  float64\n",
      " 67  D_plus_3_date_volume         13904 non-null  float64\n",
      " 68  D_plus_3_date_foreign        13847 non-null  float64\n",
      " 69  D_plus_3_date_institution    13847 non-null  float64\n",
      " 70  D_plus_3_date_individual     13847 non-null  float64\n",
      " 71  D_plus_7_date_close          13934 non-null  float64\n",
      " 72  D_plus_7_date_volume         13934 non-null  float64\n",
      " 73  D_plus_7_date_foreign        13878 non-null  float64\n",
      " 74  D_plus_7_date_institution    13878 non-null  float64\n",
      " 75  D_plus_7_date_individual     13878 non-null  float64\n",
      " 76  D_plus_14_date_close         13739 non-null  float64\n",
      " 77  D_plus_14_date_volume        13739 non-null  float64\n",
      " 78  D_plus_14_date_foreign       13675 non-null  float64\n",
      " 79  D_plus_14_date_institution   13675 non-null  float64\n",
      " 80  D_plus_14_date_individual    13675 non-null  float64\n",
      " 81  D_day_date_open              13896 non-null  float64\n",
      " 82  D-day_change_open            13896 non-null  float64\n",
      " 83  D-day_change                 13852 non-null  float64\n",
      " 84  fx                           14087 non-null  float64\n",
      " 85  bond10y                      14087 non-null  float64\n",
      " 86  base_rate                    14087 non-null  float64\n",
      "dtypes: float64(62), object(25)\n",
      "memory usage: 9.4+ MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/JooAnLee/final_project/db/news(23-25)_summarized_external.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28de66e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(628)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_nan_rows = df.isna().any(axis=1).sum()\n",
    "num_nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7079c1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aefc4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv(\"news(23-25)_summarized_external_clean.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ceac5",
   "metadata": {},
   "source": [
    "## 외부변수 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23c287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 종목명/티커 추출 함수\n",
    "import ast\n",
    "def extract_last_company_name(labels):\n",
    "    if pd.isna(labels) or labels == '[]' or labels == '':\n",
    "        return None\n",
    "    if isinstance(labels, str):\n",
    "        try:\n",
    "            labels_list = ast.literal_eval(labels)\n",
    "        except Exception:\n",
    "            return None\n",
    "    elif isinstance(labels, list):\n",
    "        labels_list = labels\n",
    "    else:\n",
    "        return None\n",
    "    if not labels_list:\n",
    "        return None\n",
    "    return labels_list[-1]\n",
    "\n",
    "def get_ticker_from_name(name, ticker_name_map):\n",
    "    if pd.isna(name):\n",
    "        return None\n",
    "    return ticker_name_map.get(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 거래일, 기준일 생성 함수\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_trading_days(start_year=2022, end_year=2025):\n",
    "    from pykrx import stock\n",
    "    trading_days = []\n",
    "    for year in range(start_year, end_year+1):\n",
    "        for month in range(1, 13):\n",
    "            try:\n",
    "                days = stock.get_business_days(year, month)\n",
    "                trading_days.extend(days)\n",
    "            except:\n",
    "                continue\n",
    "    trading_days = pd.to_datetime(sorted(set(trading_days)))\n",
    "    return trading_days\n",
    "\n",
    "def find_nearest_trading_day(date, trading_days):\n",
    "    after = trading_days[trading_days >= date]\n",
    "    if len(after) > 0:\n",
    "        return after[0]\n",
    "    else:\n",
    "        return pd.NaT\n",
    "\n",
    "def get_trading_day_offsets(d_day, trading_days, offsets):\n",
    "    result = {}\n",
    "    if pd.isna(d_day) or d_day not in trading_days.values:\n",
    "        for col in offsets:\n",
    "            result[col] = pd.NaT\n",
    "        return result\n",
    "    d_idx = np.where(trading_days == d_day)[0][0]\n",
    "    for col, offset in offsets.items():\n",
    "        idx = d_idx + offset\n",
    "        result[col] = trading_days[idx] if 0 <= idx < len(trading_days) else pd.NaT\n",
    "    return result\n",
    "\n",
    "def fill_all_trading_dates(row, trading_days, offsets):\n",
    "    d_day = row['D_day_date']\n",
    "    dates = get_trading_day_offsets(d_day, trading_days, offsets)\n",
    "    for col, val in dates.items():\n",
    "        row[col] = val\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b888653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. PyKRX - OHLCV/투자자 데이터 수집\n",
    "def get_ohlcv_dict(all_tickers, all_dates):\n",
    "    from pykrx import stock\n",
    "    ohlcv_dict = {}\n",
    "    for ticker in all_tickers:\n",
    "        try:\n",
    "            ohlcv = stock.get_market_ohlcv_by_date(\n",
    "                fromdate=min(all_dates),\n",
    "                todate=max(all_dates),\n",
    "                ticker=ticker\n",
    "            )\n",
    "            ohlcv_dict[ticker] = ohlcv\n",
    "        except:\n",
    "            continue\n",
    "    return ohlcv_dict\n",
    "\n",
    "def get_trading_dict(all_tickers, all_dates):\n",
    "    from pykrx import stock\n",
    "    trading_dict = {}\n",
    "    for ticker in all_tickers:\n",
    "        try:\n",
    "            tv_df = stock.get_market_trading_value_by_date(\n",
    "                fromdate=min(all_dates),\n",
    "                todate=max(all_dates),\n",
    "                ticker=ticker\n",
    "            )\n",
    "            trading_dict[ticker] = tv_df\n",
    "        except:\n",
    "            continue\n",
    "    return trading_dict\n",
    "\n",
    "def get_ohlcv_val(ticker, date, col, ohlcv_dict):\n",
    "    import numpy as np\n",
    "    if pd.isna(ticker) or pd.isna(date):\n",
    "        return np.nan\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    if ticker not in ohlcv_dict:\n",
    "        return np.nan\n",
    "    df_ticker = ohlcv_dict[ticker]\n",
    "    if date_str not in df_ticker.index:\n",
    "        return np.nan\n",
    "    return df_ticker.loc[date_str, col]\n",
    "\n",
    "def fast_trading_value(ticker, date, investor, trading_dict):\n",
    "    import numpy as np\n",
    "    if pd.isna(ticker) or pd.isna(date):\n",
    "        return np.nan\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    if ticker not in trading_dict:\n",
    "        return np.nan\n",
    "    tv_df = trading_dict[ticker]\n",
    "    if date_str not in tv_df.index:\n",
    "        return np.nan\n",
    "    col_map = {\n",
    "        '외국인': '외국인합계',\n",
    "        '기관': '기관합계',\n",
    "        '개인': '개인'\n",
    "    }\n",
    "    return tv_df.loc[date_str, col_map[investor]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805107a7",
   "metadata": {},
   "source": [
    "### 한국은행 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7346b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# 한국은행 ECON API 키\n",
    "api_key = \"BFKGNG1KJWZR9DVAIN6K\"\n",
    "start_date = \"20221010\"\n",
    "end_date = \"20250530\"\n",
    "\n",
    "def get_bond10y(api_key, start_date, end_date):\n",
    "    stat_code = \"817Y002\"\n",
    "    item_code = \"010200000\"  # 국고채 10년\n",
    "    url = f\"https://ecos.bok.or.kr/api/StatisticSearch/{api_key}/json/kr/1/1000/{stat_code}/D/{start_date}/{end_date}/{item_code}/\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if \"StatisticSearch\" not in data or \"row\" not in data[\"StatisticSearch\"]:\n",
    "        print(\"국고채 10년 데이터 없음:\", data)\n",
    "        return pd.DataFrame()\n",
    "    rows = data[\"StatisticSearch\"][\"row\"]\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['date'] = pd.to_datetime(df['TIME'], format='%Y%m%d')\n",
    "    df['bond10y'] = pd.to_numeric(df['DATA_VALUE'], errors='coerce')\n",
    "    return df[['date', 'bond10y']]\n",
    "\n",
    "def get_fx(api_key, start_date, end_date, item_code=\"0000001\"):\n",
    "    # item_code: 0002 = 미국 달러 (주요국 통화의 대원화 환율)\n",
    "    stat_code = \"731Y001\"\n",
    "    url = f\"https://ecos.bok.or.kr/api/StatisticSearch/{api_key}/json/kr/1/1000/{stat_code}/D/{start_date}/{end_date}/{item_code}/\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    if \"StatisticSearch\" not in data or \"row\" not in data[\"StatisticSearch\"]:\n",
    "        print(\"환율 데이터 없음:\", data)\n",
    "        return pd.DataFrame()\n",
    "    rows = data[\"StatisticSearch\"][\"row\"]\n",
    "    df = pd.DataFrame(rows)\n",
    "    df['date'] = pd.to_datetime(df['TIME'], format='%Y%m%d')\n",
    "    df['usdkrw'] = pd.to_numeric(df['DATA_VALUE'], errors='coerce')\n",
    "    return df[['date', 'usdkrw']]\n",
    "\n",
    "df_bond = get_bond10y(api_key, start_date, end_date)\n",
    "df_fx = get_fx(api_key, start_date, end_date, item_code=\"0000001\")  # 미국 달러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b63815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 외부변수 병합 (환율, 국채10년수익률, 기준금리)\n",
    "# 환율, 국채10년수익률 - 한국은행 API\n",
    "# 기준금리 - korea_base_rate_daily.csv\n",
    "def merge_external_variables(df, df_fx, df_bond, rate_csv_path):\n",
    "    # 날짜 정렬\n",
    "    df = df.sort_values('news_date')\n",
    "    df_fx = df_fx.sort_values('date')\n",
    "    df_bond = df_bond.sort_values('date')\n",
    "    # 환율\n",
    "    df = pd.merge_asof(df, df_fx.rename(columns={'date': 'news_date', 'usdkrw': 'fx'}), on='news_date', direction='backward')\n",
    "    # 국채10년\n",
    "    df = pd.merge_asof(df, df_bond.rename(columns={'date': 'news_date'}), on='news_date', direction='backward')\n",
    "    # 기준금리\n",
    "    rate_df = pd.read_csv(rate_csv_path) # 기준금리 \n",
    "    rate_df['date'] = pd.to_datetime(rate_df['date'])\n",
    "    rate_df = rate_df.sort_values('date')\n",
    "    df = pd.merge_asof(df, rate_df.rename(columns={'date': 'news_date', 'rate': 'base_rate'}), on='news_date', direction='backward')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb08611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 전체 실시간 처리 파이프라인\n",
    "def process_news_row(row, trading_days, offsets, ohlcv_dict, trading_dict):\n",
    "    # 기준일 채우기\n",
    "    row = fill_all_trading_dates(row, trading_days, offsets)\n",
    "    # OHLCV/투자자 데이터 채우기 (예시: D_day_date_close 등)\n",
    "    for col in offsets.keys():\n",
    "        row[f'{col}_close'] = get_ohlcv_val(row['ticker'], row[col], '종가', ohlcv_dict)\n",
    "        row[f'{col}_volume'] = get_ohlcv_val(row['ticker'], row[col], '거래량', ohlcv_dict)\n",
    "        row[f'{col}_foreign'] = fast_trading_value(row['ticker'], row[col], '외국인', trading_dict)\n",
    "        row[f'{col}_institution'] = fast_trading_value(row['ticker'], row[col], '기관', trading_dict)\n",
    "        row[f'{col}_individual'] = fast_trading_value(row['ticker'], row[col], '개인', trading_dict)\n",
    "    # 등락률등 추가 연산도 여기에\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f007f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 실시간 뉴스 데이터 처리 전체 예시\n",
    "def process_news_df(df, ticker_name_map, trading_days, offsets, ohlcv_dict, trading_dict, df_fx, df_bond, rate_csv_path):\n",
    "    # 종목명/티커 추출\n",
    "    df['stock_name'] = df['stock_list'].apply(extract_last_company_name)\n",
    "    df['ticker'] = df['stock_name'].apply(lambda x: get_ticker_from_name(x, ticker_name_map))\n",
    "    df['news_date'] = pd.to_datetime(df['news_date'])\n",
    "    # D_day_date 생성\n",
    "    df['D_day_date'] = df['news_date'].apply(lambda x: find_nearest_trading_day(x, trading_days))\n",
    "    # 기준일별 날짜 생성\n",
    "    df = df.apply(lambda row: fill_all_trading_dates(row, trading_days, offsets), axis=1)\n",
    "    # OHLCV/투자자/등락률 등 추가\n",
    "    df = df.apply(lambda row: process_news_row(row, trading_days, offsets, ohlcv_dict, trading_dict), axis=1)\n",
    "    # 외부 변수(환율, 국채10년, 기준금리) 병합\n",
    "    df = merge_external_variables(df, df_fx, df_bond, rate_csv_path)\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_jn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
