{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b3c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'C:\\Users\\user\\developments\\hk-final\\db\\news_v2_vector_202506122113.csv' 로드 완료. 행 수: 14087, 컬럼: ['news_id', 'embedding']\n",
      "'C:\\\\Users\\\\user\\\\developments\\\\hk-final\\\\db\\\\news_2023_2025_raw.csv' 로드 완료. 행 수: 14087, 컬럼: ['news_id', 'wdate', 'title', 'article', 'press', 'url', 'image']\n",
      "\n",
      "데이터 병합 완료. 최종 행 수: 14087, 컬럼: ['news_id', 'embedding', 'wdate', 'title', 'article', 'press', 'url', 'image']\n",
      "\n",
      "병합된 데이터의 상위 5개 행:\n",
      "         news_id                                          embedding  \\\n",
      "0  20240812_0049  [-0.6289959,-0.41044942,-0.21019596,-0.2123955...   \n",
      "1  20240812_0051  [0.35456046,-0.9542539,-0.41639727,-0.02229850...   \n",
      "2  20240610_0241  [-1.1654333,-0.32814464,-0.3500396,-0.22474843...   \n",
      "3  20240610_0245  [0.7812012,-0.8581933,0.033431143,0.5623036,0....   \n",
      "4  20240610_0246  [-0.16374397,-0.6875845,0.10508025,-0.567515,0...   \n",
      "\n",
      "                 wdate                                   title  \\\n",
      "0  2024-08-12 16:22:00                NH·미래에셋, 증권사 시총 1위 놓고 접전   \n",
      "1  2024-08-12 16:21:00  “주가는 언제 오르나”…‘네카오’ 2Q 호실적에도 엇갈린 증권가 전망   \n",
      "2  2024-06-10 08:18:00                 국민연금, 밸류업 1호 키움증권 더 담았다   \n",
      "3  2024-06-10 08:14:00         SK하이닉스, HBM 시장 우위 지속... 목표가↑-한투   \n",
      "4  2024-06-10 08:14:00             “LG전자, B2B 사업 확대로 수요 둔화 극복”   \n",
      "\n",
      "                                             article   press  \\\n",
      "0  [촬영 임은진]\\n[파이낸셜뉴스] 증권업계 시가총액 1위 자리를 놓고 미래에셋증권과...  파이낸셜뉴스   \n",
      "1  네이버·카카오 2분기 호실적에도 목표가 줄하향\\n“네이버, 저평가 구간” vs “카...    매일경제   \n",
      "2  서울 서대문구 국민연금공단 서울북부지역본부의 모습. 사진=뉴스1\\n자본시장 '큰 손...    한국경제   \n",
      "3  /사진=뉴스1 /사진=뉴스1\\n한국투자증권은 SK하이닉스가 HBM(고대역폭메모리) ...   머니투데이   \n",
      "4  원본보기\\nLG전자. [사진 출처 = LG전자]\\nLS증권은 10일 LG전자에 대해...    매일경제   \n",
      "\n",
      "                                                 url  \\\n",
      "0  https://n.news.naver.com/mnews/article/014/000...   \n",
      "1  https://n.news.naver.com/mnews/article/009/000...   \n",
      "2  https://n.news.naver.com/mnews/article/015/000...   \n",
      "3  https://n.news.naver.com/mnews/article/008/000...   \n",
      "4  https://n.news.naver.com/mnews/article/009/000...   \n",
      "\n",
      "                                               image  \n",
      "0  https://imgnews.pstatic.net/image/014/2024/08/...  \n",
      "1  https://imgnews.pstatic.net/image/009/2024/08/...  \n",
      "2  https://imgnews.pstatic.net/image/015/2024/06/...  \n",
      "3  https://imgnews.pstatic.net/image/008/2024/06/...  \n",
      "4  https://imgnews.pstatic.net/image/009/2024/06/...  \n",
      "\n",
      "병합된 데이터가 'C:\\\\Users\\\\user\\\\developments\\\\hk-final\\\\db\\\\merged_news_data.csv'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 임베딩 + 데이터 결합\n",
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 정의\n",
    "VECTOR_CSV_PATH = r\"C:\\Users\\user\\developments\\hk-final\\db\\news_v2_vector_202506122113.csv\"\n",
    "RAW_CSV_PATH = r\"C:\\\\Users\\\\user\\\\developments\\\\hk-final\\\\db\\\\news_2023_2025_raw.csv\"\n",
    "OUTPUT_CSV_PATH = r\"C:\\\\Users\\\\user\\\\developments\\\\hk-final\\\\db\\\\merged_news_data.csv\" # 병합된 데이터를 저장할 파일 경로\n",
    "\n",
    "# 1. 뉴스 데이터 로드\n",
    "try:\n",
    "    df_vector = pd.read_csv(VECTOR_CSV_PATH)\n",
    "    df_raw = pd.read_csv(RAW_CSV_PATH)\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"오류: 파일을 찾을 수 없습니다. 경로를 확인해주세요: {e}\")\n",
    "    exit() # 파일이 없으면 스크립트 종료\n",
    "\n",
    "print(f\"'{VECTOR_CSV_PATH}' 로드 완료. 행 수: {len(df_vector)}, 컬럼: {df_vector.columns.tolist()}\")\n",
    "print(f\"'{RAW_CSV_PATH}' 로드 완료. 행 수: {len(df_raw)}, 컬럼: {df_raw.columns.tolist()}\")\n",
    "\n",
    "# 2. news_id를 기준으로 두 데이터프레임 병합\n",
    "# df_vector: news_id, embedding 컬럼\n",
    "# df_raw: news_id, wdate, title, article, press, url, image 컬럼\n",
    "# 'inner' 조인을 사용하여 양쪽에 모두 존재하는 news_id만 병합합니다.\n",
    "merged_df = pd.merge(df_vector, df_raw, on='news_id', how='inner')\n",
    "\n",
    "print(f\"\\n데이터 병합 완료. 최종 행 수: {len(merged_df)}, 컬럼: {merged_df.columns.tolist()}\")\n",
    "print(\"\\n병합된 데이터의 상위 5개 행:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# 3. 병합된 데이터를 CSV 파일로 저장 (선택 사항)\n",
    "# 다음 단계에서 이 병합된 파일을 바로 사용할 것이라면 굳이 저장할 필요는 없습니다.\n",
    "# 하지만 중간 결과를 확인하거나 재사용해야 한다면 저장하는 것이 좋습니다.\n",
    "try:\n",
    "    merged_df.to_csv(OUTPUT_CSV_PATH, index=False, encoding='utf-8-sig')\n",
    "    print(f\"\\n병합된 데이터가 '{OUTPUT_CSV_PATH}'에 저장되었습니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"오류: 병합된 데이터 저장 중 문제가 발생했습니다: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8600f12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14087 entries, 0 to 14086\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   news_id    14087 non-null  object\n",
      " 1   embedding  14087 non-null  object\n",
      " 2   wdate      14087 non-null  object\n",
      " 3   title      14087 non-null  object\n",
      " 4   article    14087 non-null  object\n",
      " 5   press      14087 non-null  object\n",
      " 6   url        14087 non-null  object\n",
      " 7   image      14087 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 880.6+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98d72bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.drop(\"image\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac78c44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14087 entries, 0 to 14086\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   news_id    14087 non-null  object\n",
      " 1   embedding  14087 non-null  object\n",
      " 2   wdate      14087 non-null  object\n",
      " 3   title      14087 non-null  object\n",
      " 4   article    14087 non-null  object\n",
      " 5   press      14087 non-null  object\n",
      " 6   url        14087 non-null  object\n",
      "dtypes: object(7)\n",
      "memory usage: 770.5+ KB\n"
     ]
    }
   ],
   "source": [
    "merged_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "215d6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"C:\\\\Users\\\\user\\\\developments\\\\hk-final\\\\db\\\\merged_news_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eadf1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings # 또는 사용하시는 임베딩 모델\n",
    "\n",
    "# 1. 데이터 로드 (예시 CSV 파일, 실제 경로로 변경 필요)\n",
    "df = pd.read_csv(\"db\\merged_news_data.csv\") # 여기에 실제 CSV 파일 경로를 넣어주세요.\n",
    "\n",
    "# 2. Document 객체 생성\n",
    "documents = []\n",
    "for _, row in df.iterrows():\n",
    "    doc = Document(\n",
    "        page_content=row['article'],  # 임베딩할 실제 텍스트\n",
    "        metadata={\n",
    "            \"wdate\": row['wdate'],\n",
    "            \"title\": row['title'],\n",
    "            \"press\": row['press'],\n",
    "            \"url\": row['url']\n",
    "        }\n",
    "    )\n",
    "    documents.append(doc)\n",
    "\n",
    "# 3. 임베딩 모델 로드 (FAISS 저장 시 필요)\n",
    "# 임베딩 모델을 직접 로드해야 FAISS가 문서를 임베딩하여 저장할 수 있습니다.\n",
    "# 예시: HuggingFaceEmbeddings\n",
    "# model_name = \"BAAI/bge-small-en-v1.5\" # 사용하실 임베딩 모델 명\n",
    "# embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "# ⭐️ 중요: 여기서는 외부 API를 통해 임베딩을 수행한다고 하셨으므로,\n",
    "# 실제 FAISS를 생성할 때는 해당 임베딩 API를 호출하여 벡터를 미리 생성한 후\n",
    "# FAISS.from_embeddings()를 사용하는 것이 효율적입니다.\n",
    "# 만약 FAISS.from_documents()를 사용한다면, FAISS 내부적으로 embedding_model을 사용하여 임베딩합니다.\n",
    "# 여기서는 편의상 FAISS.from_documents()와 로컬 임베딩 모델을 사용한다고 가정합니다.\n",
    "# 실제 운영 환경에서는 아래 FAISS.from_documents() 대신,\n",
    "# 외부 임베딩 API로 문서들을 미리 임베딩하여 (text, vector) 튜플 리스트를 만든 후\n",
    "# FAISS.from_embeddings(text_embeddings=your_pre_embedded_data, embedding=None)\n",
    "# 와 같이 사용하는 것을 고려해보세요.\n",
    "\n",
    "# 현재 코드는 FAISS.from_documents()를 사용하며, 이 경우 embedding_model이 필수입니다.\n",
    "# 실제 임베딩 API 호출을 통해 벡터를 미리 생성하는 방식으로 변경하려면 추가적인 코드 수정이 필요합니다.\n",
    "# 여기서는 FAISS가 임베딩 모델을 사용하여 저장할 수 있도록 embedding_model을 전달합니다.\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"BAAI/bge-small-en-v1.5\") # 예시 임베딩 모델\n",
    "\n",
    "# 4. 벡터 DB (FAISS) 생성 및 저장\n",
    "vector_db = FAISS.from_documents(documents, embedding_model)\n",
    "\n",
    "# 5. 벡터 DB 저장\n",
    "vector_db_path = \"vectorstore/news_db\"\n",
    "vector_db.save_local(vector_db_path)\n",
    "print(f\"FAISS 벡터 DB가 '{vector_db_path}'에 성공적으로 저장되었습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
