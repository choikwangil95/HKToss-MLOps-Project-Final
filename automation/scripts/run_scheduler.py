from news_pipeline import (
    NewsMarketPipeline,
    fetch_latest_news,
    get_article_summary,
    get_stock_list,
    load_rate_df,
    remove_market_related_sentences,
    load_official_stock_list,
    filter_official_stocks_from_list,
    load_stock_to_industry_map,
    get_industry_list_from_stocks,
    save_to_db_external,
    save_to_db_metadata,
    get_news_deduplicate_by_title,
    save_to_db,
    send_to_redis,
)
import schedule
import time
import logging
import os
from dotenv import load_dotenv

load_dotenv()

log = logging.getLogger("news_logger")


def job(official_stock_set, stock_to_industry, df_base_rate):
    log.info("ğŸ•’ [ìŠ¤ì¼€ì¤„ëŸ¬] ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤í–‰")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 1 ë‰´ìŠ¤ ì‹¤ì‹œê°„ ìˆ˜ì§‘
    # - 1ë¶„ë§ˆë‹¤ ìˆ˜ì§‘
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # 1 ë‰´ìŠ¤ ì‹¤ì‹œê°„ ìˆ˜ì§‘ ì‹¤í–‰ í•¨ìˆ˜
    news_crawled = fetch_latest_news()

    if len(news_crawled) != 0:
        # title ì¤‘ë³µ ì œê±°
        news_crawled = get_news_deduplicate_by_title(news_crawled)

        save_to_db(news_crawled)

        send_to_redis(news_crawled)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 2 ë‰´ìŠ¤ ì „ì²˜ë¦¬
    # - ë³¸ë¬¸ ì „ì²˜ë¦¬ ë° ìš”ì•½, ì¢…ëª©ê³¼ ì—…ì¢…ëª… ë§¤ì¹­
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # 1 ë‰´ìŠ¤ ë³¸ë¬¸ ì „ì²˜ë¦¬ ì‹¤í–‰ í•¨ìˆ˜
    filtered_news = []

    if len(news_crawled) != 0:
        for news in news_crawled:
            news_article = news["article"]
            news_article_preprocessed = remove_market_related_sentences(news_article)

            if len(news_article_preprocessed) < 70:
                continue  # ë³¸ë¬¸ ê¸¸ì´ ì§§ìœ¼ë©´ ì œì™¸

            news["article_preprocessed"] = news_article_preprocessed
            filtered_news.append(news)

    print(f"\ní•„í„°ë§ëœ ë‰´ìŠ¤ {filtered_news}\n")

    # 2 ë‰´ìŠ¤ ë³¸ë¬¸ ìš”ì•… í•¨ìˆ˜
    summarzied_news = []

    if len(filtered_news) != 0:
        for news in filtered_news:
            news_article = news["article_preprocessed"]
            summary = get_article_summary(news_article)

            if len(summary) < 70:
                continue  # ë³¸ë¬¸ ê¸¸ì´ ì§§ìœ¼ë©´ ì œì™¸

            news["summary"] = summary
            summarzied_news.append(news)

    print(f"\nìš”ì•½ëœ ë‰´ìŠ¤  {summarzied_news}\n")

    ner_news = []

    # 3 ë‰´ìŠ¤ ì¢…ëª©, ì—…ì¢…ëª… ë§¤ì¹­ í•¨ìˆ˜
    if len(summarzied_news) != 0:
        for news in summarzied_news:
            news_summary = news["summary"]
            stock_list = get_stock_list(news_summary)

            # ì—¬ê¸°ì„œ í•„í„°ë§
            stock_list = filter_official_stocks_from_list(
                stock_list, official_stock_set
            )
            news["stock_list"] = stock_list

            # ì¢…ëª© ì—†ê±°ë‚˜ ë„ˆë¬´ ë§ìœ¼ë©´ ì œì™¸
            if len(stock_list) > 4 or len(stock_list) < 1:
                news["stock_list"] = None

            industry_list = get_industry_list_from_stocks(stock_list, stock_to_industry)
            news["industry_list"] = industry_list

            if len(industry_list) < 1:
                news["industry_list"] = None

            ner_news.append(news)

            # ì¤‘ë³µ ë‰´ìŠ¤ ì œê±°
            ner_news = get_news_deduplicate_by_title(ner_news)

    print(f"\nì¢…ëª©, ì—…ì¢…ëª… ë§¤ì¹­ ë‰´ìŠ¤ {ner_news}\n")

    save_to_db_metadata(ner_news)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3 ë‰´ìŠ¤ ê²½ì œ ë° í–‰ë™ ì§€í‘œ í”¼ì³ ì¶”ê°€
    # - ì£¼ê°€ D+1~D+30 ë³€ë™ë¥ , ê¸ˆë¦¬, í™˜ìœ¨, ê¸°ê´€ ë§¤ë§¤ë™í–¥, ìœ ê°€ ë“±
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    if len(ner_news) != 0:
        news_list = ner_news
        pipeline = NewsMarketPipeline(news_list=news_list, df_base_rate=df_base_rate)

        market_datas = pipeline.run()

        if market_datas:
            pass

    market_datas = [
        {
            "news_id": "2023555_11",
            "d_minus_5_date_close": 56800.0,
            "d_minus_5_date_volume": 12870515.0,
            "d_minus_5_date_foreign": 49110828550,
            "d_minus_5_date_institution": -33974732600,
            "d_minus_5_date_individual": -13745996750,
            "d_minus_4_date_close": 57800.0,
            "d_minus_4_date_volume": 19649983.0,
            "d_minus_4_date_foreign": 119775101650,
            "d_minus_4_date_institution": 67064831850,
            "d_minus_4_date_individual": -176290654250,
            "d_minus_3_date_close": 59100.0,
            "d_minus_3_date_volume": 23266027.0,
            "d_minus_3_date_foreign": 281318315200,
            "d_minus_3_date_institution": 137802524700,
            "d_minus_3_date_individual": -414294844450,
            "d_minus_2_date_close": 59800.0,
            "d_minus_2_date_volume": 19609659.0,
            "d_minus_2_date_foreign": 309135095150,
            "d_minus_2_date_institution": -129336955150,
            "d_minus_2_date_individual": -159736050350,
            "d_minus_1_date_close": 59200.0,
            "d_minus_1_date_volume": 15305760.0,
            "d_minus_1_date_foreign": -54533069200,
            "d_minus_1_date_institution": -17931077300,
            "d_minus_1_date_individual": 71865041600,
            "fx": 1359.9,
            "bond10y": 2.419,
            "base_rate": 2.5,
        },
        {
            "news_id": "2023555_11",
            "d_minus_5_date_close": 57800.0,
            "d_minus_5_date_volume": 19649983.0,
            "d_minus_5_date_foreign": 119775101650,
            "d_minus_5_date_institution": 67064831850,
            "d_minus_5_date_individual": -176290654250,
            "d_minus_4_date_close": 59100.0,
            "d_minus_4_date_volume": 23266027.0,
            "d_minus_4_date_foreign": 281318315200,
            "d_minus_4_date_institution": 137802524700,
            "d_minus_4_date_individual": -414294844450,
            "d_minus_3_date_close": 59800.0,
            "d_minus_3_date_volume": 19609659.0,
            "d_minus_3_date_foreign": 309135095150,
            "d_minus_3_date_institution": -129336955150,
            "d_minus_3_date_individual": -159736050350,
            "d_minus_2_date_close": 59200.0,
            "d_minus_2_date_volume": 15305760.0,
            "d_minus_2_date_foreign": -54533069200,
            "d_minus_2_date_institution": -17931077300,
            "d_minus_2_date_individual": 71865041600,
            "d_minus_1_date_close": 59900.0,
            "d_minus_1_date_volume": 13610734.0,
            "d_minus_1_date_foreign": 133535624000,
            "d_minus_1_date_institution": 24499766250,
            "d_minus_1_date_individual": -148212988300,
            "fx": 1359.9,
            "bond10y": 2.419,
            "base_rate": 2.5,
        },
    ]
    save_to_db_external(market_datas)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4 ë‰´ìŠ¤ ì‹œë©˜í‹± í”¼ì³ ì¶”ê°€
    # - topicë³„ ë¶„í¬ê°’, í´ëŸ¬ìŠ¤í„° ë™ì¼ ì—¬ë¶€
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    # ìœ¼ì•…


if __name__ == "__main__":
    # ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    # í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€ ë””ë ‰í† ë¦¬ (automation/scripts/)
    BASE_DIR = os.path.dirname(os.path.abspath(__file__))

    official_stock_path = os.path.abspath(
        os.path.join(BASE_DIR, "../db/KRX_KOSPI_STOCK.csv")
    )
    official_stock_set = load_official_stock_list(official_stock_path)

    industry_map_path = os.path.abspath(
        os.path.join(BASE_DIR, "../db/KRX_KOSPI_DESCRIPTION.csv")
    )
    stock_to_industry = load_stock_to_industry_map(industry_map_path)

    korea_base_rate_daily_path = os.path.abspath(
        os.path.join(BASE_DIR, "../db/korea_base_rate_daily.csv")
    )
    df_base_rate = load_rate_df(korea_base_rate_daily_path)

    log.info("âœ… run_scheduler.py ì‹œì‘ë¨")

    # ì²« ì‹¤í–‰ ì¦‰ì‹œ
    job(official_stock_set, stock_to_industry, df_base_rate)

    # ì´í›„ ë§¤ 1ë¶„ë§ˆë‹¤ ì‹¤í–‰
    schedule.every(1).minutes.do(
        lambda: job(official_stock_set, stock_to_industry, df_base_rate)
    )

    while True:
        schedule.run_pending()
        time.sleep(1)
