from fastapi import (
    APIRouter,
    Depends,
    HTTPException,
    Query,
    Path,
    Request,
    Body,
    Response,
)
from sqlalchemy.orm import Session
from db.postgresql import get_db
from schemas.model import (
    ChatIn,
    ChatOut,
    LdaTopicsIn,
    LdaTopicsOut,
    RecommendIn,
    RecommendOut,
    SimilarNewsIn,
    SimilarNewsOut,
    SimilarityRequest,
    SimilarityResponse,
    SimilarityResult,
)
from services.model import (
    get_lda_topic,
    get_news_embeddings,
    get_news_recommended,
    get_news_similar_list,
    get_stream_response,
    compute_similarity,
)
import requests

from services.custom import get_news_impact_score_service

from schemas.custom import SimpleImpactResponse

import numpy as np

from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel
import openai
import os
import json
from load_models import get_similarity_model
import asyncio
from sqlalchemy.orm import Session
from db.postgresql import get_db
from models.custom import (
    NewsModel_v2_Metadata,
    NewsModel_v2_External,
    NewsModel_v2_Topic,
)


router = APIRouter(
    prefix="/news",
    tags=["Custom Model"],
    responses={404: {"description": "Not found"}},
)


@router.post(
    "/similar",
    response_model=SimilarNewsOut,
    summary="ìœ ì‚¬ ë‰´ìŠ¤ top-k",
    description="ìœ ì‚¬ ë‰´ìŠ¤ top-k",
)
async def get_news_embedding_router(request: Request, payload: SimilarNewsIn):
    """
    ìœ ì‚¬ ë‰´ìŠ¤ top-k
    """
    article = payload.article
    if not article:
        raise HTTPException(
            status_code=400,
            detail="ê¸°ì‚¬ ë³¸ë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë³¸ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
        )

    similar_news_list = get_news_similar_list(payload, request)
    if similar_news_list is None:
        raise HTTPException(
            status_code=500,
            detail="ìœ ì‚¬ ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
        )

    return {"similar_news_list": similar_news_list}


@router.post(
    "/topics",
    response_model=LdaTopicsOut,
    summary="ë‰´ìŠ¤ ìš”ì•½ë¬¸ LDA topic",
    description="ë‰´ìŠ¤ ìš”ì•½ë¬¸ LDA topic",
)
async def get_news_summary_router(request: Request, payload: LdaTopicsIn):
    """
    ë‰´ìŠ¤ ìš”ì•½ë¬¸ LDA topic
    """
    article = payload.article
    if not article:
        raise HTTPException(
            status_code=400,
            detail="ê¸°ì‚¬ ìš”ì•½ë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì˜¬ë°”ë¥¸ ë³¸ë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.",
        )

    lda_topics = get_lda_topic(article, request)

    return {"lda_topics": lda_topics}


@router.post(
    "/chat/stream",
    # response_model=ChatOut,
    summary="ë‰´ìŠ¤ GPT ì±—ë´‡",
    description="ë‰´ìŠ¤ GPT ì±—ë´‡",
)
async def chat_stream_endpoint(request: Request, payload: ChatIn):
    return await get_stream_response(request, payload)


@router.post(
    "/similarity",
    response_model=SimilarityResponse,
    summary="íšŒê·€ ëª¨ë¸ ê¸°ë°˜ ë‰´ìŠ¤ ìœ ì‚¬ë„ ì˜ˆì¸¡",
    description="ê¸°ì¤€ ë‰´ìŠ¤ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ íšŒê·€ ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ìœ ì‚¬ë„ ìƒìœ„ 5ê°œ ë‰´ìŠ¤ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
)
async def get_similarity_scores(
    request: Request, payload: SimilarityRequest, db: Session = Depends(get_db)
):
    # ë¡œë“œëœ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°
    scalers = request.app.state.scalers
    ae_sess = request.app.state.ae_sess
    regressor_sess = request.app.state.regressor_sess

    async def embedding_api_func(texts):
        embeddings = await get_news_embeddings(texts, request)

        print("ğŸŸ¡ ì„ë² ë”© ê²°ê³¼:", embeddings)

        return embeddings

    news_id = payload.news_id
    news_topk_ids = payload.news_topk_ids or []

    # ê³µí†µ ì™¸ë¶€ë³€ìˆ˜ ì»¬ëŸ¼ ì •ì˜ (news_id ì œì™¸ ì „ë¶€)
    ext_cols = [
        col.name
        for col in NewsModel_v2_External.__table__.columns
        if col.name != "news_id"
    ]

    # ê¸°ì¤€ ë‰´ìŠ¤ ì •ë³´ ì¡°íšŒ
    ref_news_raw = (
        db.query(NewsModel_v2_Metadata)
        .filter(NewsModel_v2_Metadata.news_id == news_id)
        .first()
    )
    if not ref_news_raw:
        raise HTTPException(
            status_code=404, detail="ê¸°ì¤€ ë‰´ìŠ¤ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    summary = ref_news_raw.summary

    ref_news_external = (
        db.query(NewsModel_v2_External)
        .filter(NewsModel_v2_External.news_id == news_id)
        .first()
    )
    if not ref_news_external:
        raise HTTPException(
            status_code=404, detail="ê¸°ì¤€ ë‰´ìŠ¤ ì™¸ë¶€ ë³€ìˆ˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    extA = [getattr(ref_news_external, col) for col in ext_cols]

    ref_news_topic = (
        db.query(NewsModel_v2_Topic)
        .filter(NewsModel_v2_Topic.news_id == news_id)
        .first()
    )
    if not ref_news_topic:
        raise HTTPException(
            status_code=404, detail="ê¸°ì¤€ ë‰´ìŠ¤ í† í”½ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        )
    topic_cols = [
        col.name
        for col in ref_news_topic.__table__.columns
        if col.name.startswith("topic_")
    ]
    topicA = [getattr(ref_news_topic, col) for col in topic_cols]

    extA_total = extA + topicA

    # ìœ ì‚¬ ë‰´ìŠ¤ ì •ë³´ ì¡°íšŒ
    topk_news_raw = (
        db.query(NewsModel_v2_Metadata)
        .filter(NewsModel_v2_Metadata.news_id.in_(news_topk_ids))
        .all()
    )
    summary_map = {news.news_id: news.summary for news in topk_news_raw}
    try:
        similar_summaries = [summary_map[nid] for nid in news_topk_ids]
    except KeyError as e:
        raise HTTPException(
            status_code=400, detail=f"ìœ ì‚¬ ë‰´ìŠ¤ ID {str(e)}ê°€ DBì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
        )

    topk_exts = (
        db.query(NewsModel_v2_External)
        .filter(NewsModel_v2_External.news_id.in_(news_topk_ids))
        .all()
    )
    ext_map = {ext.news_id: ext for ext in topk_exts}
    extBs = [[getattr(ext_map[nid], col) for col in ext_cols] for nid in news_topk_ids]

    topk_topics = (
        db.query(NewsModel_v2_Topic)
        .filter(NewsModel_v2_Topic.news_id.in_(news_topk_ids))
        .all()
    )
    topic_map = {topic.news_id: topic for topic in topk_topics}
    topicB_cols = [
        col.name
        for col in NewsModel_v2_Topic.__table__.columns
        if col.name.startswith("topic_")
    ]
    topicBs = [
        [getattr(topic_map[nid], col) for col in topicB_cols] for nid in news_topk_ids
    ]

    extB_total = [ext + topic for ext, topic in zip(extBs, topicBs)]

    missing_ext_ids = [nid for nid in news_topk_ids if nid not in ext_map]
    missing_topic_ids = [nid for nid in news_topk_ids if nid not in topic_map]

    if missing_ext_ids:
        raise HTTPException(
            status_code=400, detail=f"ì™¸ë¶€ ë³€ìˆ˜ ì—†ëŠ” ë‰´ìŠ¤ ID: {missing_ext_ids}"
        )
    if missing_topic_ids:
        raise HTTPException(
            status_code=400, detail=f"í† í”½ ë³€ìˆ˜ ì—†ëŠ” ë‰´ìŠ¤ ID: {missing_topic_ids}"
        )

    # ìœ ì‚¬ë„ ì ìˆ˜ ê³„ì‚°
    results = await compute_similarity(
        db=db,
        summary=summary,
        extA=extA,
        topicA=topicA,
        similar_summaries=similar_summaries,
        extBs=extBs,
        topicBs=topicBs,
        scalers=scalers,
        ae_sess=ae_sess,
        regressor_sess=regressor_sess,
        embedding_api_func=embedding_api_func,
        ext_col_names=ext_cols,
        topic_col_names=topic_cols,
        news_topk_ids=news_topk_ids,
    )

    # news_id ë§¤í•‘
    news_id_map = dict(zip(similar_summaries, news_topk_ids))
    for r in results:
        r["news_id"] = news_id_map.get(r["summary"], "unknown")

    # ìœ ì‚¬ë„ score ê¸°ì¤€ ì •ë ¬
    results.sort(key=lambda x: x["score"], reverse=True)

    return SimilarityResponse(results=[SimilarityResult(**r) for r in results])


@router.post(
    "/recommend",
    response_model=RecommendOut,
    summary="ë‰´ìŠ¤ ì¶”ì²œ í›„ë³´êµ°",
    description="ë‰´ìŠ¤ ì¶”ì²œ í›„ë³´êµ°",
)
async def get_news_recommend(request: Request, payload: RecommendIn):
    return JSONResponse(
        status_code=200,
        content={"message": "ğŸš§ í˜„ì¬ ì¶”ì²œ APIëŠ” ê°œë°œ ì¤‘ì…ë‹ˆë‹¤. ê³§ ì œê³µë  ì˜ˆì •ì´ì—ìš”!"},
    )

    # return await get_news_recommended(payload, request)


@router.get(
    "/{news_id}/impact_score",
    response_model=SimpleImpactResponse,
    summary="ë‰´ìŠ¤ IDë¡œ ë‰´ìŠ¤ ì„íŒ©íŠ¸ ìŠ¤ì½”ì–´ ê³„ì‚°",
    description="ë‰´ìŠ¤ IDë§Œ ì…ë ¥í•˜ë©´ í•´ë‹¹ ë‰´ìŠ¤ì˜ ì„íŒ©íŠ¸ ìŠ¤ì½”ì–´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.",
)
async def get_news_impact_score(
    request: Request,
    response: Response,  # âœ… ì¶”ê°€
    news_id: str = Path(..., description="ë‰´ìŠ¤ ê³ ìœ  ID", min_length=1),
    db: Session = Depends(get_db),
):
    """
    íŠ¹ì • ë‰´ìŠ¤ì˜ ì„íŒ©íŠ¸ ìŠ¤ì½”ì–´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    d_plus, d_minus, impact_score, z_scores = await get_news_impact_score_service(
        news_id, db, request
    )  # request ì „ë‹¬

    # âœ… z_scoresë¥¼ í—¤ë”ì— JSON í˜•ì‹ìœ¼ë¡œ ì¶”ê°€
    z_score_mean = float(np.mean(z_scores))
    response.headers["X-model-score"] = str(z_score_mean)  # Prometheusìš© í—¤ë” ì¶”ê°€

    return SimpleImpactResponse(
        d_plus=d_plus, d_minus=d_minus, impact_score=impact_score
    )
